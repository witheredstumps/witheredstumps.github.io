[
  
  
    {
      "title": "Taut foliations and minimal surfaces",
      "url": "/2024/03/18/taut-foliations-minimal-surfaces/",
      "date": "2024-03-18",
      "content": "The goal of this post is to prove the following theorem of Hansklaus Rummler and Dennis Sullivan. The references I used are “Foliations and the Geometry of 3-Manifolds” by Danny Calegari and “Combinatorial volume preserving flows and taut foliations” by David Gabai. Theorem. Let \\(\\mathcal{F}\\) be a co-orientable codimension one foliation of an oriented closed smooth \\(n\\)-manifold \\(M\\). Then the following are equivalent: \\(\\mathcal{F}\\) is taut, There is a positive volume form on \\(M\\) and a volume-preserving flow on \\(M\\) transverse to \\(\\mathcal{F}\\), There is a Riemannian metric on \\(M\\) such that the leaves are locally area-minimizing. Proof. Suppose \\(\\mathcal{F}\\) is taut. Then for any \\(p \\in M\\), we can find an embedded loop \\(\\phi : S^1 \\to M\\) transverse to \\(\\mathcal{F}\\) passing through \\(p\\). Take a slight thickening to \\(\\phi : S^1 \\times D^{n-1} \\to M\\). We arrange \\(\\phi\\) by a small homotopy so that \\(\\phi^{-1}(\\mathcal{F})\\) is the natural product foliation on \\(S^1 \\times D^{n-1}\\) by \\(\\{pt\\} \\times D^{n-1}\\). Since \\(M\\) is compact, we may cover it by finitely many such embedded tori \\(\\phi_i : S^1 \\times D^{n-1} \\to M\\). Let \\(\\theta_i\\) denote a \\((n-1)\\)-form on \\(S^1 \\times D^{n-1}\\) which on the leaves \\(\\{pt\\} \\times D^{n-1}\\) restrict to a positive volume form on the interior of the disk and vanishes near the boundary \\(\\{pt\\} \\times \\partial D^{n-1}\\). Define: \\[\\displaystyle \\theta_{\\mathcal{F}} = \\sum_i (\\phi_i)_* \\theta_i\\] By construction, \\(\\theta_{\\mathcal{F}}\\) is a leafwise positive volume form on \\(M\\). Let \\(\\alpha\\) be the \\(1\\)-form on \\(M\\) such that \\(\\ker \\alpha = T\\mathcal{F}\\) is the distribution given by tangent spaces to the leaves of the foliation. Define \\(\\omega = \\alpha \\wedge \\theta_{\\mathcal{F}}\\). Let \\(X\\) be the unique vector field such that \\(\\theta_{\\mathcal{F}}(X) = 0\\) and \\(\\alpha(X) = 1\\). Then, \\[\\mathcal{L}_X \\omega = i_X d\\omega + di_X \\omega = d i_X \\omega = d\\theta_{\\mathcal{F}} = 0\\] Therefore, \\(X\\) is a volume-preserving flow transverse to \\(\\mathcal{F}\\). This proves (1) implies (2). Suppose we have a positive volume form \\(\\omega\\) on \\(M\\) and a volume-preserving flow \\(X\\) transverse to \\(\\mathcal{F}\\). Let \\(\\theta = i_X \\omega\\), which must be a positive volume form on the leaves of \\(\\mathcal{F}\\). Let \\(K = \\ker(\\theta)\\), so that we have \\(TM = T\\mathcal{F} \\oplus K\\). Define a Riemannian metric on \\(M\\) by \\(g = g_l \\oplus g_k\\) where \\(g_l\\) is a metric on the distribution \\(T\\mathcal{F}\\) so that \\(\\theta\\) is the Riemannian volume form on the leaves of \\(\\mathcal{F}\\) with respect to \\(g_l\\), and \\(g_k\\) is a positive definite metric on \\(K\\). The important property that \\(\\theta\\) has is as follows. Clearly, for any orthonormal \\((n-1)\\)-frame in \\(T \\mathcal{F}\\), \\(\\theta\\) evaluates to \\(1\\) on it. For an orthonormal \\((n-1)\\)-frame in \\(TM\\), \\(\\theta\\) completely ignores the components of all the vectors in the direction of \\(K\\). Therefore, it evaluates to at most \\(1\\) on such a frame, with equality only if the frame is tangential to the leaves of \\(\\mathcal{F}\\). One says \\(\\theta\\) is a calibration for the leaves of \\(\\mathcal{F}\\). Let \\(L\\) be a leaf of \\(\\mathcal{F}\\). For any compact codimension zero submanifold-with-boundary \\((\\Omega, \\partial \\Omega) \\subset L\\) and a perturbed copy of it \\(\\Omega' \\subset M\\) with \\(\\partial \\Omega = \\partial \\Omega'\\) representing \\([\\Omega] \\subset H_2(M, \\partial \\Omega; \\Bbb R)\\), we must have the following: \\[\\displaystyle \\mathrm{vol}_g(\\Omega) = \\int_{\\Omega} \\theta = \\int_{\\Omega'} \\theta \\leq \\int_{\\Omega'} \\mathrm{vol}_g = \\mathrm{vol}_g(\\Omega')\\] where the inequality above is true by the calibration property. Consequently, the leaves of \\(L\\) are locally area-minimizing with respect to the metric \\(g\\), i.e., they are minimal hypersurfaces. This proves (2) implies (3). It remains to prove (3) implies (1). Given a Riemannian metric \\(g\\) such that each leaf of \\(\\mathcal{F}\\) is locally area-minimizing, we may consider an \\((n-1)\\)-form \\(\\theta\\) which restricts to the Riemannian volume form on each leaf. This is a calibration for all the leaves of \\(\\mathcal{F}\\), as above. Suppose \\(\\mathcal{F}\\) is not taut. Fix a transverse co-orientation of \\(\\mathcal{F}\\). Let \\(L \\subset M\\) be a leaf of \\(\\mathcal{F}\\). Define the accessible set \\(A(L)\\) to be the set of points \\(x \\in M\\) such that there is a positively directed arc transverse to \\(\\mathcal{F}\\) from \\(L\\) to \\(x\\). Clearly, \\(A(L)\\) is open and saturated by leaves of \\(\\mathcal{F}\\), therefore the boundary \\(\\partial A(L)\\) is also a (possibly empty) union of leaves. However, if \\(A(L) = M\\), then every leaf admits a positive transversal arc from \\(L\\) from both negative and positive sides, which we can combine to produce a transverse circle through every leaf, contradicting our hypothesis that \\(\\mathcal{F}\\) is not taut. Thus, \\(\\partial A(L) \\neq \\emptyset\\). Let \\(L' \\subset \\partial A(L)\\) be a leaf. We claim \\(A(L)\\) cannot accumulate to \\(L'\\) from the negative side. If it did, there would be a sequence \\(x_n \\in A(L)\\) converging to \\(x \\in L\\) from the negative side, hence there would be a positively directed arc from some \\(x_n\\) to \\(L'\\). But \\(x_n \\in A(L)\\), so there is a positively directed arc from \\(L\\) to \\(x_n\\). Combining, we obtain a positively directed arc joining \\(L\\) and \\(L'\\), forcing \\(L' \\subset A(L)\\), contradiction. Thus, \\(\\overline{A(L)}\\) is a compact manifold with boundary a collection of compact leaves \\(L_1, \\cdots, L_n\\) such that \\(A(L)\\) lies on the negative side of all of them. Therefore, the oriented disjoint union \\(L_1 \\sqcup \\cdots \\sqcup L_n\\) is null-cobordant, hence \\(\\chi(L_1) + \\cdots + \\chi(L_n) = 0\\). However, we then have \\[\\displaystyle 0 = \\int_{L_1 \\sqcup \\cdots \\sqcup L_n} \\theta = \\int_{L_1} \\theta + \\cdots + \\int_{L_n} \\theta = \\mathrm{vol}(L_1) + \\cdots + \\mathrm{vol}(L_n),\\] contradiction. This concludes the proof of the theorem. As an interesting application, we have the following theorem of Novikov and Rosenberg. I have attached a link to a proof I had written a while ago, which is lacking in detail but I feel gets the main ideas across. The main technical tool involves the theorem of Rummler and Sullivan above, together with a compactness theorem for minimal surfaces due to Choi-Schoen. Theorem. Let \\(M^3\\) be a closed oriented three-manifold. Let \\(\\mathcal{F}\\) be a taut foliation of \\(M^3\\). Then the leaves of \\(\\mathcal{F}\\) are \\(\\pi_1\\)-injective subsurfaces of \\(M\\). Moreover, any closed transversal to \\(\\mathcal{F}\\) is nontrivial in \\(\\pi_1\\). Proof. See here. The argument for closed transversals is completely analogous: we assume it is nullhomologous, therefore bounds a disk in the three-manifold by Dehn’s lemma. But then the same argument shows the disk can be homotoped rel boundary to lie entirely on a leaf, which is a contradiction. We end this topic by discussing a combinatorial version of the Sullivan-Rummler theorem. First, we introduce some terminology. A normal arc in a 2-simplex is a properly embedded arc intersecting a pair of distinct edges. A normal disk in a 3-simplex is a properly embedded disk whose boundary consists of either 3 or 4 properly embedded arcs in the respective 2-faces they are contained in. Definition. Let \\(M\\) be a three-manifold with a triangulation \\(\\tau\\). A normal surface is a surface \\(S \\subset M\\) such that \\(S\\) intersects each three-simplex in \\(M\\) in a normal disk. A foliation \\(\\mathcal{F}\\) on \\(M\\) is said to be in normal form \\(\\mathcal{F}\\) is transverse to the 1- and 2-simplices, distinct vertices lie in distinct leaves, and for each leaf \\(L\\) and a three-simplex \\(\\Delta \\subset \\tau\\), each non-point component of \\(L \\cap \\Delta\\) is a normal disk. Proposition. Let \\(M\\) be a three-manifold, and \\(\\mathcal{F}\\) be a codimension one foliation. There exists a smooth triangulation \\(\\tau\\) of \\(M\\) with respect to which \\(\\mathcal{F}\\) is in normal form. Proof. Find a smooth triangulation, and then subdivide until all the three-simplices get inside foliated charts. Applying transversality, we may assume for every three-simplex \\(\\Delta \\subset \\tau\\), \\(\\mathcal{F}\\) is transverse to the 1- and 2-faces of \\(\\Delta\\) except at some isolated points of Morse tangencies. The picture for \\(\\mathcal{F}\\vert\\Delta\\) in the coordinates given by the foliated chart is that of a curvilinear simplex sitting inside \\(\\Bbb R^3\\), getting scanned by affine linear hyperplanes \\(z = \\mathrm{const.}\\), and the 1- and 2-faces are Morse with respect to the \\(z\\)-height. It’s obvious how to subdivide the simplex further to achieve normal form: add faces parallel to the level set of the \\(z\\)-heights at all critical values, and then tilt the new faces a little to make it transverse to the level sets except at the vertices. Definition. A combinatorial volume preserving flow \\((\\phi, \\tau)\\) on a three-manifold \\(M\\) consists of a triangulation \\(\\tau\\) and an assignment of positive integral weights \\(\\phi(e)\\) as well as orientation to each edge \\(e \\subset \\tau^{(1)}\\), such that at each vertex, the conservation of mass property is satisfied: sum of incoming weights is equal to sum of outgoing weights. A codimension one co-oriented foliation in normal positive with a triangulation induces a natural orientation on each of the 1-skeleton: for any three-simplex, the co-orientation induces a linear ordering on the vertices of the simplex where \\(v &lt; w\\) if there is an edge from \\(v\\) to \\(w\\) pointing in the same direction as the co-orienting vector for the leaves transverse to that edge. Proposition. (Gabai) Let \\(\\mathcal{F}\\) be a co-oriented codimension-one foliation on a closed oriented three-manifold \\(M\\). \\(\\mathcal{F}\\) is taut if and only if there is a combinatorial volume preserving flow \\((\\phi, \\tau)\\) compatible with \\(\\mathcal{F}\\). Proof. Suppose \\(\\mathcal{F}\\) is taut, and \\(\\tau\\) be a smooth triangulation with respect to which it is in normal form. The tautness of \\(\\mathcal{F}\\) guarantees that the induced directed graph structure on \\(\\tau^{(1)}\\) gives a recurrent graph, i.e., any vertex can be joined with any vertex by a piecewise linear directed arc. This is because we may take a smooth positively oriented arc in \\(M\\) joining them so that it is transverse to the foliation, by tautness, after which we can simplicially approximate the arc. Thus, for every edge \\(e \\subset \\tau^{(1)}\\), there is a piecewise linear directed loop \\(\\gamma_e \\subset \\tau^{(1)}\\) containing \\(e\\). Let \\(\\mathcal{C} := \\{\\gamma_e\\}\\) denote a finite collection of such loops, one for each edge \\(e \\subset \\tau^{(1)}\\). We define \\(\\phi(e)\\) to be the number of times \\(\\mathcal{C}\\) crosses \\(e\\) counted with multiplicity. Then \\(\\phi\\) clearly satisfies conservation of mass, therefore \\((\\phi, \\tau)\\) is a combinatorial volume preserving flow. The converse is easy. Definition. For a combinatorial volume preserving flow \\((\\phi, \\tau)\\) on \\(M\\) and a normal surface \\(S \\subset M\\), we define the weight of \\(S\\) (to be thought as “combinatorial area”) as \\[\\displaystyle w(S) = \\sum_e \\phi(e) |e \\cap S|\\] where $\\vert e \\cap S \\vert $ denotes the cardinality of the set of intersections of $S$ with $e$. Let $\\mathcal{F}$ be a taut foliation with a combinatorial volume preserving flow $(\\phi, \\tau)$. For any leaf $L \\subset \\mathcal{F}$, let $S \\subset L$ be a compact normal subsurface. Let $R \\subset M$ be another normal surface with $\\partial S = \\partial R$ representing $[S] \\in H_2(M, \\partial S; \\Bbb Z)$. Then, \\[\\displaystyle \\begin{aligned} w(R) = \\sum_e \\phi(e) |e \\cap R| \\geq \\sum_e \\phi(e) \\langle e, R \\rangle&amp; = \\sum_e \\phi(e) \\langle e, S \\rangle \\\\ &amp;= \\sum_e \\phi(e) |e \\cap S| \\\\ &amp;= w(S)\\end{aligned}\\] where $\\langle e, R \\rangle$ denotes the algebraic intersection number i.e., the signed intersection count. The first inequality is true as clearly the unsigned count is more than the signed count, the subsequent equality is true as $R, S$ represent the same relative homology class and the final equality is true as $S$ intersects all the edges $e$ positively by definition of the orientation of $\\tau^{(1)}$ induced from the co-orientation of the leaves. Therefore, the leaves of a taut foliation in normal form are combinatorial area minimizing.",
      "categories": [],
      "tags": ["minimal-surfaces","taut-foliations","thurston-norm"]
    },
  
    {
      "title": "Monopoles and Thurston norm: Part I",
      "url": "/2021/12/07/monopoles-thurston-norm-i/",
      "date": "2024-03-17",
      "content": "A couple years ago I started writing a series of posts on Seiberg-Witten invariants which I never ended up finishing (which can be found here). To tie up with what I am learning now, I’ll write some notes on the 1997 paper ``Scalar curvature and the Thurston norm” by Kronheimer and Mrowka, which exhibits an interesting connection between Seiberg-Witten theory and the Thurston norm. Let us begin by recalling basic terminology. Let $M$ be an oriented closed three-manifold, equipped with a Riemannian metric $g$. A spinc (stylized spinC ) structure on $M$ is a unitary rank $2$ vector bundle $S \\to M$ together with a ``Clifford multiplication” \\(\\rho : TM \\to \\mathrm{End}(S)\\) satisfying the following property: given any oriented orthonormal frame \\(\\{e_1, e_2, e_3\\}\\) at a point \\(p \\in M\\), the following properties are true for all \\(i, j\\): \\[\\displaystyle \\begin{aligned}\\rho(e_i)\\rho(e_j) + \\rho(e_j)\\rho(e_i) &amp;= 2\\delta_{ij}I \\\\ \\rho(e_i)^\\star &amp;= -\\rho(e_i) \\\\ \\rho(e_1)\\rho(e_2)\\rho(e_k) &amp;= I\\end{aligned}\\] It can be checked that these conditions are independent of the choice of the oriented orthonormal frame. Therefore, \\(\\rho\\) is an orientation-preserving isometric isomorphism from \\(TM\\) onto the subbundle of \\(\\mathrm{End}(S)\\) denoted as \\(\\mathfrak{su}(S)\\), consisting of traceless anti-hermitian endomorphisms, equipped with the inner product \\(\\mathrm{tr}(a^\\star b)/2\\). Any three-manifold admits a spinc structure: it is a standard fact that the tangent bundle of a three-manifold is trivial, so we define \\(S = M \\times \\Bbb C^2\\) and let \\(\\rho(e_i) = \\sigma_i\\) be the Pauli matrices, where \\(\\{e_1, e_2, e_3\\}\\) is a global orthonormal frame on \\(M\\). The set of spinc structures is naturally an affine space over \\(H^2(M; \\Bbb Z)\\) for the following reason: given any class \\(\\alpha\\) in the second cohomology group, it corresponds naturally to a complex line bundle \\(L\\) over \\(M\\) so that \\(c_1(L) = \\alpha\\). For any spinc structure \\(\\mathfrak{s} = (S, \\rho)\\), we may form a new spinc structure \\((S \\otimes L, \\rho \\otimes 1_L)\\), denoted \\(\\mathfrak{s} + \\alpha\\). In fact, it is not too difficult to see that any two spinc structures differ by an element of the second integral cohomology group. Given a spinc structure \\((S, \\rho)\\), a spinc connection is a metric connection \\(B\\) on \\(S\\) such that \\(\\rho\\) is \\(B\\)-parallel, i.e., \\(\\nabla^B \\rho = 0\\). In other words, for all vector fields \\(X, Y\\) and section \\(\\psi\\) of \\(S\\), \\[\\nabla^B_X (\\rho(Y)\\psi) = \\rho(\\nabla_X Y)\\psi + \\rho(Y) \\nabla^B_X \\psi,\\] where \\(\\nabla_X Y\\) is the Levi-Civita connection on \\(M\\). In the example \\(S = M \\times \\Bbb C^2\\) described above, we can explicitly solve for a spin connection as follows: write \\(\\nabla^B_X \\psi = d \\psi(X) + B(X) \\psi\\) where \\(d\\psi(X)\\) is the directional derivative of the section \\(\\psi\\) of \\(S\\) treated as a function to \\(\\Bbb C^2\\), and \\(B\\) is a \\(\\mathfrak{u}(2)\\)-valued \\(1\\)-form on \\(M\\). Then the parallelity condition above gives \\([B(X), \\rho(Y)] = \\rho(\\nabla_X Y)\\). We may plug in \\(X, Y\\) from the oriented orthonormal basis \\(\\{e_1, e_2, e_3\\}\\) to write the trace-free part of \\(B(e_i)\\) completely in terms of the Pauli matrices and the Christoffel symbols. (Someone please do this computation and tell me the answer; I’ll make infinite sign errors if I try). The space of spinc connections on \\((S, \\rho)\\) is likewise an affine space over \\(\\Omega^1(M; i\\Bbb R)\\). Indeed, for any spinc connection \\(B\\) and an imaginary-valued 1-form \\(b\\), we may form a new spinc connection \\(B + b \\otimes 1_S\\), and any two spinc connections differ by such a 1-form. Let us call the sections of \\(S\\) as spinors. Since \\(S\\) is a unitary bundle of rank \\(2\\), its second exterior power \\(L = \\Lambda^2 S\\) is a line bundle with a \\(\\mathfrak{u}(1) (= i\\mathbb{R})\\)-connection induced from \\(B\\), which we will call \\(B^t\\). Indeed, \\(B^t\\) is the trace of the \\(\\mathfrak{u}(2)\\)-valued form \\(B\\) (since the derivative of determinant is trace). Since we saw in the previous paragraph that the trace-free part of \\(B^t\\) is completely determined by the Levi-Civita connection on \\(M\\), we conclude: a spinc connection \\(B\\) on a fixed Riemannian manifold is entirely determined by a \\(i\\mathbb{R}\\)-valued \\(1\\)-form \\(B^t\\). We shall denote \\(F_{B^t} = dB^t\\) to be the curvature of this connection on the determinant line bundle. Note that the corresponding cohomology class \\[\\displaystyle \\left [\\frac{i}{2\\pi} \\cdot F_{B^t} \\right ] \\in H^2(M; \\Bbb R)\\] is precisely the 1st Chern class of \\(\\Lambda^2 S\\). We call it the Chern class of the spinc structure, and denote it by \\(c_1(\\mathfrak{s})\\). Given a spinc connection, we may form the Dirac operator on spinors, which is a linear first order partial differential operator, as follows (the definition is basis-independent): \\[\\displaystyle D_B : \\Gamma(S) \\to \\Gamma(S),\\; D_B\\psi = \\sum_{i = 1}^3 \\rho(e_i)\\nabla^B_{e_i} \\psi\\] As a final observation, note that the Clifford multiplication \\(\\rho\\) can be extended to be defined on cotangent vectors by setting \\(\\rho(e^i) = \\rho(e_i)\\) where \\(e^i\\) is the dual covector to \\(e_i\\). We can extend it to all forms by the rule \\[\\displaystyle \\rho(\\alpha \\wedge \\beta) = \\frac12 \\left ( \\rho(\\alpha)\\rho(\\beta)+ (-1)^{|\\alpha||\\beta|} \\rho(\\beta)\\rho(\\alpha) \\right )\\] We may also define it for differential forms valued in complex coefficients, by letting \\(\\rho\\) simply commute with complex multiplication. Now that that’s all done, let us recall the Seiberg-Witten equations on 3-manifolds. Let \\(M\\) be a three manifold with a spinc structure \\(\\mathfrak{s} = (S, \\rho)\\). The Seiberg-Witten equations or monopole equations for a pair \\((B, \\psi)\\) consisting of a spinc connection and a spinor are: \\[\\displaystyle \\begin{aligned}\\frac{1}{2} \\cdot \\rho(F_{B^t}) &amp;= \\left (\\psi \\otimes \\psi^\\star\\right)_0 \\\\ D_B \\psi &amp;= 0 \\end{aligned}\\] Here, \\(\\psi \\otimes \\psi^* \\in S \\otimes S^* = \\mathrm{End}(S)\\) is a linear transformation, and \\((-)_0\\) denotes the traceless part of it. One says a solution \\((B, \\psi)\\) is gauge-equivalent to another solution \\((B', \\psi')\\) if there is a function \\(u : M \\to S^1\\) such that \\(B' = B - u^{-1} du \\otimes 1_S\\) and \\(\\psi' = u \\psi\\). One tries to solve the monopole equations upto gauge equivalence. Observe that for any solution \\((B, \\psi)\\), the cohomology class of \\(F_{B^t}\\) is unchanged under gauge equivalence. We call a solution reducible if \\(\\psi = 0\\), which forces \\(B^t\\) to be flat by the first equation. Notice that the equations above depend on the choice of a metric \\(g\\) on the Riemannian manifold \\(M\\). In our definition, we built the spin structure \\(\\mathfrak{s} = (S, \\rho)\\) itself using the metric. But it is not difficult to check that any two such choices of metrics \\(g_0, g_1\\) gives rise to isomorphic spin structures \\(\\mathfrak{s}_0, \\mathfrak{s}_1\\). This is because the space of metrics is a cone in the space of quadratic differentials, hence contractible. Thus, we can join \\(g_0, g_1\\) by a 1-parameter family of metrics \\(g_t\\). This gives rise to a 1-parameter family of spin structures \\(\\mathfrak{s}_t\\) interpolating \\(\\mathfrak{s}_0, \\mathfrak{s}_1\\). Therefore, the spinc structure depends only upto contractible choice on the space of Riemannian metrics. Consequently, the Chern class \\(c_1(\\mathfrak{s})\\) is certainly independent of the underlying metric. However, the Seiberg-Witten equations themselves depend on the metric, since the Dirac operator and the Clifford multiplication both depend on the metric. Definition. A cohomology class \\(\\alpha \\in H^2(M; \\Bbb R)\\) is a monopole class if there is a spinc structure \\(\\mathfrak{s} = (S, \\rho)\\) such that \\(c_1(\\mathfrak{s}) = \\alpha\\), and the corresponding Seiberg-Witten equations have an irreducible solution for all choices of Riemannian metrics. Observe that if \\(c_1(\\mathfrak{s}) \\neq 0\\), then if a solution to the Seiberg-Witten equations exist, they are necessarily irreducible. Otherwise, \\((B, 0)\\) is a solution, hence \\(F_{B^t} = 0\\), contradiction. Suppose \\((B, \\psi)\\) is an irreducible solution for the Seiberg-Witten equations with respect to some Riemannian metric \\(g\\) on \\(M\\). The linear part of the Seiberg-Witten equation tells us \\(D_B \\psi = 0\\) (i.e., \\(\\psi\\) is a harmonic spinor). We use the Weitzenbock-Lichnerowicz formula to deduce: \\[\\displaystyle 0 = D_B^\\star D_B \\psi = (\\nabla^B)^\\star \\nabla^B \\psi + \\frac12 \\rho(F_{B^t}) \\psi + \\frac14 s \\psi,\\] where \\(s\\) denotes the scalar curvature of \\((M, g)\\). The nonlinear part of the Seiberg-Witten equations imply the second term in the above is \\((\\psi \\otimes \\psi^*)_0 \\psi\\). We take inner product (wrt \\(g\\)) of the entire expression with \\(\\psi\\). Let us compute \\(\\langle (\\psi \\otimes \\psi^*)_0 \\psi, \\psi \\rangle\\). It is good to think of \\(\\psi\\) as simply a column vector, and \\(\\psi \\otimes \\psi^*\\) as simply the \\(2 \\times 2\\) matrix \\(\\psi \\psi^*\\) where \\(\\psi^*\\) is the conjugate-transposed row vector. Then: \\[\\displaystyle \\begin{aligned} \\langle (\\psi \\otimes \\psi^*)_0 \\psi, \\psi \\rangle &amp;= \\langle (\\psi \\psi^* - \\mathrm{tr}(\\psi \\psi^*)/2)\\psi, \\psi \\rangle \\\\ &amp;= \\langle \\psi \\psi^* \\psi,\\psi \\rangle - \\frac12 \\mathrm{tr}(\\psi \\psi^*) \\langle \\psi, \\psi \\rangle \\\\ &amp;= \\|\\psi\\|^4 - \\frac12 \\|\\psi\\|^4 \\\\ &amp;= \\frac12 \\|\\psi\\|^4 \\end{aligned}\\] Therefore, by using the definition of adjoint, we get: \\[\\displaystyle 0 = \\|\\nabla^B \\psi\\|^2 + \\frac12 \\|\\psi\\|^4 + \\frac14 s \\|\\psi\\|^2\\] Corollary. There are no irreducible solutions to the Seiberg-Witten equations for a metric \\(g\\) on a three-manifold of non-negative scalar curvature \\(s \\geq 0\\). In particular, manifolds which admit a metric of non-negative scalar curvature do not possess any monopole classes. Suppose the solution is irreducible. Let us integrate the above expression over the entire manifold. Ignoring the term involving the covariant derivative of \\(\\psi\\), we get \\[\\displaystyle \\int \\frac12 \\|\\psi\\|^4 + \\frac14 \\int s \\|\\psi\\|^2 \\leq 0\\] Therefore, \\[\\displaystyle \\begin{aligned}\\int \\|\\psi\\|^4 \\leq \\frac12 \\int (-s) \\cdot \\|\\psi\\|^2 &amp;\\leq \\frac12 \\left (\\int s^2 \\right)^{1/2} \\left (\\int \\|\\psi\\|^4 \\right )^{1/2} \\\\ \\implies \\int \\|\\psi\\|^4 &amp;\\leq \\frac14 \\int s^2\\end{aligned}\\] where we use that \\(\\psi\\) is not identically zero, by irreducibility. By the nonlinear part of the Seiberg-Witten equations, we have that the norm of \\(\\rho(F_{B^t})/2\\) is equal to the norm of \\((\\psi \\psi^*)_0\\), which we compute: \\[\\displaystyle \\begin{aligned} \\|(\\psi \\psi^*)_0\\|^2 &amp;= \\frac12 \\mathrm{tr} \\left ( (\\psi \\psi^*)_0 \\cdot (\\psi \\psi^*)_0^* \\right ) \\\\ &amp;= \\frac12 \\mathrm{tr}\\left (\\psi \\psi^* - \\frac12 \\|\\psi\\|^2 \\cdot 1_S \\right )^2 \\\\ &amp;= \\frac12 \\left ( \\|\\psi\\|^4 - \\frac12 \\|\\psi\\|^4 - \\frac12 \\|\\psi\\|^4 + \\frac14 \\|\\psi\\|^4 \\right ) \\\\ &amp;= \\frac14 \\|\\psi\\|^4 \\end{aligned}\\] Thus, \\(\\|(\\psi \\psi^*)_0\\| = \\|\\psi\\|^2/2\\). Remember that \\(\\rho\\) preserves norms, so we get norm of \\(F_{B^t}\\) with respect to \\(g\\) (or the inner product induced on the space of 2-forms thereof) is the same as \\(\\|\\psi\\|^2\\). Therefore, \\[\\displaystyle \\int \\|F_{B^t}\\|^2 = \\int \\|\\psi\\|^4 \\leq \\frac14 \\int s^2\\] Therefore, \\(\\|F_{B^t}\\|_{L^2} \\leq \\|s\\|_{L^2}/2\\), using \\(L^2\\)-norms. Definition. Let \\((M, g)\\) be a Riemannian \\(3\\)-manifold. Recall a differential \\(2\\)-form \\(\\omega\\) on the manifold is harmonic if \\(d\\omega = d^*\\omega = 0\\). Every cohomology class admits a unique harmonic representative in de Rham cohomology, by Hodge theory. We define the harmonic norm on \\(H^2(M; \\Bbb R)\\) by setting \\(\\|\\alpha\\|_{har, g}\\) to be the \\(L^2\\)-norm of the unique harmonic \\(2\\)-form representing the cohomology class \\(\\alpha\\). Corollary. If \\(\\alpha \\in H^2(M; \\Bbb R)\\) is a monopole class, then for all metrics \\(g\\) on \\(M\\), \\[\\displaystyle \\|\\alpha\\|_{har, g} \\leq \\frac{1}{4\\pi} \\cdot \\|s\\|_{L^2(M, g)}\\] This follows from what we derived as \\(F_{B^t}\\) represents the class \\(2\\pi/i \\cdot \\alpha\\), where \\(\\alpha = c_1(\\mathfrak{s})\\) is the Chern classes associated to the spin structure we started with, and the harmonic form minimizes the \\(L^2\\)-norm in a given cohomology class. Finally, we relate the harmonic norm with the Thurston norm for irreducible atoroidal manifolds. Since the Thurston norm is a norm defined on the second homology, we must first dualize it to a norm defined on cohomology. Definition. Let \\(M\\) be an oriented, closed, irreducible, atoroidal three-manifold with \\(b_1(M) \\neq 0\\). We define the dual Thurston norm by setting for any \\(\\alpha \\in H^2(M; \\Bbb R)\\), \\[\\displaystyle \\|\\alpha\\|_{Th} = \\sup_{\\Sigma} \\frac{|\\alpha[\\Sigma]|}{-\\chi(\\Sigma)},\\] where \\(\\Sigma\\) varies over all oriented embedded surfaces in \\(M\\) of genus at least \\(2\\). Proposition. The dual Thurston norm and the harmonic norm on an oriented, closed, irreducible, atoroidal three-manifold \\(M\\), satisfy the following inequality: \\[\\displaystyle \\|\\alpha\\|_{Th} \\leq \\sup_g \\frac{4\\pi\\|\\alpha\\|_{har, g}}{\\|s(g)\\|_{L^2(M, g)}},\\] where \\(g\\) varies over all Riemannian metrics on \\(M\\) and \\(s(g)\\) denotes the scalar curvature of \\((M, g)\\). Proof. Let us start by fiddling around to see if we get an idea. Pick a metric \\(g\\) on \\(M\\) and let \\(\\Sigma\\) be an embedded oriented surface of genus at least \\(2\\). Let \\(\\omega\\) be a \\(2\\)-form representing the class \\(\\alpha\\). Then, by the Gauss-Bonnet theorem, \\(2\\pi\\chi(\\Sigma)\\) is the integral of the curvature of \\(\\Sigma\\) with the induced metric from \\((M, g)\\). So, \\[\\displaystyle \\frac{\\alpha[\\Sigma]}{-\\chi(\\Sigma)} = -\\frac{2\\pi\\int_{\\Sigma}\\omega}{\\int_{\\Sigma} K d\\mathrm{vol}_g}\\] The numerator is bounded by the metric norm on \\(\\omega\\) (which can be bounded by the harmonic norm) times the volume of \\(\\Sigma\\), and the denominator is bounded by the \\(L^2\\)-norm of (half the) scalar curvature attained on \\(\\Sigma\\) times the volume of \\(\\Sigma\\). It seems we are awfully close, but \\(a \\leq b, c \\leq d\\) does not mean \\(a/c \\leq b/d\\). The shortcoming of this approach is that we are only focusing on the scalar curvature attained along \\(\\Sigma\\). We must pick metrics \\(g\\) such that the semi-local geometry around \\(\\Sigma\\) dominates in \\(M\\). Let \\(g_1\\) be a metric on \\(M\\) such that some neighborhood of \\(\\Sigma\\) in \\(M\\) is isometric to \\(\\Sigma \\times [0, 1]\\) with the product metric \\(dt^2 + h\\), where \\((\\Sigma, h)\\) is a hyperbolic surface of unit area. Let \\(g_r\\) be a radial rescaling so that in that neighborhood we have \\(g_r = r^2 dt^2 + h\\) and \\(g_r = g_1\\) outside a slightly larger neighborhood. Then the same neighborhood with the metric \\(g_r\\) is isometric to the product \\(\\Sigma \\times [0, r]\\). Therefore, the \\(L^2\\)-norm of the scalar curvature is: \\[\\displaystyle \\begin{aligned} \\int s(g_r)^2 \\, d\\mathrm{vol}_{g_r} &amp;= \\int_{\\Sigma \\times [0, r]} s(g_r)^2 \\, d\\mathrm{vol}_{g_r} + \\int_{M \\setminus \\Sigma \\times [0, 1]} s(g_1)^2 \\, d\\mathrm{vol}_{g_1} \\\\ &amp;= (-4\\pi\\chi(\\Sigma))^2 r + C \\end{aligned}\\] since \\(s(g_r) = 4\\pi\\chi(\\Sigma)\\) on \\(\\Sigma \\times [0, r]\\) and \\(d\\mathrm{vol}_{g_r} = r \\, dt\\, d\\mathrm{vol}_h\\), and \\(C\\) is a constant independent of \\(r\\). Observe also that if \\(\\omega\\) is any \\(2\\)-form representing the cohomology class \\(\\alpha\\), \\[\\displaystyle \\begin{aligned} |\\alpha[\\Sigma]|^2 \\leq \\left | \\int_{\\Sigma} \\omega \\right |^2 \\leq \\left ( \\int_{\\Sigma} \\|\\omega\\|_h d\\mathrm{vol}_h \\right )^2 \\leq \\|\\omega\\|_{L^2(\\Sigma, h)} ^2 \\mathrm{Area}(\\Sigma)^2 &amp;= \\|\\omega\\|_{L^2(\\Sigma, h)}^2 \\\\ &amp; \\leq r^{-2} \\|\\omega\\|_{L^2(M,g_r)}^2 \\end{aligned}\\] Therefore, we have the following equations: \\[\\displaystyle \\begin{aligned} \\|s(g_r)\\|_{L^2(M, g_r)} &amp;= -4\\pi \\chi(\\Sigma) r + C' \\\\ \\|\\alpha\\|_{har, g_r} &amp;\\geq r |\\alpha[\\Sigma]|\\end{aligned}\\] where \\(C'\\) is a constant independent of \\(r\\). Dividing the second by the first, one obtains: \\[\\displaystyle \\frac{\\|\\alpha\\|_{har, g_r}}{\\|s(g_r)\\|_{L^2(M, g_r)}} \\geq \\frac{r |\\alpha[\\Sigma]|}{ -4\\pi \\chi(\\Sigma) r + C'} \\to \\|\\alpha\\|_{Th}\\] as \\(r \\to \\infty\\). This proves the required inequality. Remark. As \\(r \\to \\infty\\), the Riemannian manifolds \\((M, g_r)\\) exhibit a neck-stretching along the embedded surface \\(\\Sigma \\subset M\\), and geometrically converges to a manifold with \\(\\Bbb H^2 \\times \\Bbb R\\) geometry. My guess is that if the above inequality is optimal, the equality is achieved in this limit. We now tie everything together by the following theorem: Theorem. For a closed oriented irreducible atoroidal \\(3\\)-manifold (also known as a hyperbolic \\(3\\)-manifold), the monopole classes are contained in the dual Thurston norm-ball. Proof. Suppose \\(\\mathfrak{s}\\) is a spinc structure with \\(\\alpha = c_1(\\mathfrak{s})\\) a monopole class. Let \\(g\\) be an auxiliary Riemannian metric on \\(M\\). Then combining the inequalities we have deduced above, we get \\[\\displaystyle \\|\\alpha\\|_{Th} \\leq \\sup_g \\frac{4\\pi}{\\|s(g)\\|_{L^2(M, g)}} \\cdot \\|\\alpha\\|_{har, g} \\leq \\sup_g \\frac{4\\pi}{\\|s(g)\\|_{L^2(M, g)}} \\cdot \\frac{1}{4\\pi} \\cdot \\|s(g)\\|_{L^2(M, g)} = 1\\] In the follow-up to this post, we will prove the converse direction. Before going there, we need to make a detour from this detour to talk about taut foliations in relation to Thurston norm, and Gabai’s theorem on existence of such.",
      "categories": [],
      "tags": ["monopoles","scalar-curvature","taut-foliations","thurston-norm"]
    },
  
    {
      "title": "Segue: a bit about foliations",
      "url": "/2024/03/13/segue-foliation/",
      "date": "2024-03-13",
      "content": "Recall that a foliation on a three-manifold is a decomposition of the manifold as a union of continuum-many disjoint, possibly noncompact subsurfaces (called leaves of the foliation), so that locally the decomposition is the standard decomposition of the three-space as a union of affine subspaces given by level sets of a linear functional. An easy example of a foliation is given by fibers of a fiber bundle \\(\\pi : M \\to S^1\\) from the three-manifold onto the circle, but not all foliations are fibers of a fibration. A famous example is the Reeb foliation, which is a foliation of the solid torus \\(S^1 \\times D^2\\) consisting a unique compact leaf given by the boundary torus, and the rest of the leaves are embedded planes spiraling around the torus, accumulating to the boundary leaf. Figure. Reeb foliation as a viscous fluid flow. One may double the solid torus along the boundary by \\((x, y) \\mapsto (y, -x)\\) to obtain an interesting foliation on \\(S^3\\). A general recipe to produce Reeb-like foliations is: suppose \\(M\\) is a manifold with torus boundary and \\(\\mathcal{F}\\) be a foliation on \\(M\\) by surfaces with boundary, such that the boundary of the leaves themselves foliate the boundary of the manifold \\(\\partial M\\). Then we may “spin” the leaves around the torus as we approach the boundary to obtain a foliation on \\(M\\) by the spun leaves of \\(\\mathcal{F}\\) as well as a boundary leaf \\(\\partial M\\). These are called dead-ends, since any arc transverse to the leaves foliation from the inside is stopped by the spinning leaves from ever intersecting the boundary leaf. One may also Dehn fill \\(\\partial M\\) by a Reeb torus to obtain closed examples. Theorem. Every three-manifold admits a foliation. Proof. Choose an ambient Riemannian metric on \\(M\\). Since \\(\\chi(M) = 0\\), there exists a nowhere zero vector field on \\(M\\). Taking the orthogonal complement at each point, we obtain a plane field \\(\\xi\\). We wish to modify \\(\\xi\\) to be everywhere integrable and thus give rise to a foliation. To this end, let \\(\\mathcal{T}= \\cup_i \\Delta_i^3\\) be a triangulation of \\(M\\). We use the following lemma: Lemma. (Thurston’s jiggling lemma) There exists a subdivision \\(\\mathcal{T}'\\) of \\(\\mathcal{T}\\) and a \\(C^0\\)-small perturbation \\(\\mathcal{T}''\\) of \\(\\mathcal{T}'\\) such that (1) \\(\\xi\\) is transverse to the interiors of the edges and faces of \\(\\mathcal{T}''\\) of \\(\\mathcal{T}'\\) and (2) \\(\\xi\\) is \\(C^\\infty\\)-close to being horizontal on each \\(3\\)-simplex of \\(\\mathcal{T}''\\) with respect to some affine coordinate system. Proof of Lemma. First, barycentric subdivide \\(\\mathcal{T}\\) until all simplices become of arbitrarily small diameter, i.e., \\(\\mathrm{diam}(\\Delta_i^3) &lt; \\varepsilon\\). Then by smoothness of \\(\\xi\\), we may choose a coordinate system on each simplex with height coordinate \\(z\\) such that \\(\\xi\\) is \\(\\varepsilon\\)-close to \\(\\ker(dz)\\). This ensures (2). Next, apply a crystalline subdivision procedure: embed \\(\\Delta^3\\) in \\([0, 1]^3\\) as \\[\\Delta^3 = \\{(x, y, z) \\in [0, 1]^3 : x + y + z \\leq 1\\}\\] Then slice by the hyperplanes \\(\\{x = k/n\\}\\), \\(\\{y = k/n\\}\\) and \\(\\{x + y + z = k/n\\}\\). This subdivides the simplices into uniformly small simplices such that each vertex in the one-skeleton has bounded valence. Moving the vertices up and down by small rigid motions within \\([0, 1]^3\\), the entire crystalline-subdivided simplex crumples up in a way that all the smaller simplices in the crystalline subdivision are of large slope and therefore transverse to the plane field \\(\\xi \\cong \\ker(dz)\\), ensuring (1) as well. In retrospect, the exact model of the subdivision process is not really important for this: see figure below. Figure. Thurston's jiggling as a Miura-ori. Thus, by applying the jiggling lemma, we have made \\(\\xi\\) transverse to the \\(2\\)-skeleton of the new triangulation \\(\\mathcal{T}''\\), i.e., the “local min/max” with respect to \\(\\xi\\) only occur at the vertices and possibly interiors of \\(3\\)-simplices. Remember that by construction, our \\(2\\)-plane field is co-oriented. Thus, the \\(1\\)-skeleton of the triangulation admits a directed graph structure, where we orient an edge so that it agrees with the co-orientation of the plane field. This also equips each simplex of the triangulation with a total order on the vertices so that all the edges point from a smaller vertex to a larger vertex. By a further subdivision of \\(\\mathcal{T}''\\) if necessary, we can ensure that we can color the simplices red and blue so that adjacent simplices have different colors. We may tilt any particular red simplex so that the characteristic foliation has ``clockwise holonomy”, i.e., the leaves spiral down clockwise. Then on an adjacent blue simplex it spirals counterclockwise with respect to the natural coordinate system, by compatibility of orientation. This effect can then be inductively transported on all simplices. Figure. Characteristic foliation on a simplex before and after smoothing. Intersect \\(\\xi\\) with the \\(2\\)-skeleton of the triangulation. On each simplex, this leaves an imprint of the plane field which is a singular (combinatorial) foliation on the boundary of the \\(2\\)-simplex, which we will call the characteristic foliation. It consists of exactly one minimum at the largest vertex, one maximum at the smallest vertex, and spiraling leaves connecting between them. We may extend this foliation into a neighborhood of the \\(2\\)-skeleton. This gives a codimension \\(0\\) submanifold with spherical boundaries on which the singular foliation is as described before. We would like to fill these holes by balls. This seems impossible, because of the spiraling of the leaves in the characteristic foliation. So, for each three-simplex \\(\\Delta^3\\) with maximum vertex \\(v\\) and minimum vertex \\(w\\), we find an arc \\(\\tau\\) transverse to the foliation joining \\(v, w\\) outside \\(\\Delta^3\\). If this was possible, we could delete a neighborhood of \\(\\tau\\) to obtain a solid torus hole with a nonsingular characteristic foliation on the boundary. Then spinning and Reeb-filling finishes the proof. It remains to show that such transverse arcs \\(\\tau\\) can in fact be constructed. To do this, recall the color-coding of the three-simplices described a paragraph ago. Suppose \\(\\Delta^3\\) is a red simplex. Then the characteristic foliation has clockwise holonomy. The strategy is to take an arc \\(\\tau\\) joining \\(v, w\\) in \\(\\partial \\Delta^3\\) transverse to the singular foliation with anti-clockwise holonomy, so that it is transverse to all the leaves. Then we could take a push-off of \\(\\tau\\) so that the interior of \\(\\tau\\) is disjoint from \\(\\Delta^3\\). This has a problem, in that the picture of the characteristic foliation in the above figure is ``wrong”. If the characteristic foliation was infinitely spiraling near the max/min vertices \\(v, w\\) as in the picture, we would not be able to extend it inwards on a regular neighborhood because of the singularity. We need to modify the plane field (or the coordinate system) so that near \\(v, w\\) the characteristic foliation is by concentric circles (or triangles, before smoothening), and outside a little neighborhood we have the spiraling pattern, to be able to extend to a smooth foliation in a regular neighborhood of the \\(2-\\)skeleton. But now we have a problem with constructing the arc \\(\\tau\\) near \\(v, w\\). To solve this problem, we observe that there is an adjacent blue simplex such that \\(v, w\\) are one of the non-extremal vertices of this simplex. We start the arc \\(\\tau\\) by going from \\(v\\) into this adjacent simplex, spiral downwards in counterclockwise fashion by following the singular foliation, come back to \\(\\Delta^3\\) and follow our transverse arc counterclockwise to the characteristic foliation on \\(\\partial \\Delta^3\\), and once we are sufficiently close to \\(w\\), go back out into the adjacent simplex and follow its characteristic foliation again until coming back to \\(w\\) from the outside. Taking a push-off of this satisfies the required transversality property. Remark. An analogous proof shows that all three-manifolds admit a contact structure, but its easier because the figure above for the characteristic foliation on the sphere is not wrong, and finding transverse arcs are much easier in contact topology. This also shows that any plane field can be homotoped to a foliation (respectively, contact structure). See, “Confoliations” by Thurston and Eliashberg for more. OK, every three-manifold has a foliation. But what if we changed the rules so that you cannot cheat? Definition. A foliation \\(\\mathcal{F}\\) is taut if there exists an closed curve \\(\\gamma\\) transversely intersecting all the leaves of \\(\\mathcal{F}\\). This immediately rules out existence of Reeb components and dead-end components. So the proof above, which heavily relied on filling toroidal holes by Reeb foliations, breaks completely. So which three-manifolds admit taut foliations? Some immediate examples are that of fibered manifolds in the beginning of the post. We give an example of a taut foliation which is not fibered. Example. Let \\(f : \\Sigma \\to \\Sigma\\) be a diffeomorphism of a surface of genus \\(g \\geq 2\\). Let \\(M = T(f)\\) be the mapping torus of \\(f\\), which admits an obvious fibering \\(\\pi : M \\to S^1\\) by construction. We shall modify the fibering to be a rather complicated taut foliation, as follows. Consider \\(\\Sigma \\times [0, 1]\\) with the standard foliation by \\(\\Sigma \\times \\{x\\}\\). Let \\(C \\subset \\Sigma\\) be any non-separating essential curve, for instance, a meridian. Then the annulus \\(C \\times [0, 1]\\) intersects all the leaves of the standard height foliation transversely. We cut \\(\\Sigma \\times [0, 1]\\) open along \\(C \\times [0, 1]\\), so that every leaf becomes a surface of genus \\(1\\) with two punctures. Figure. Messing up a fibering. Let \\(h : [0, 1] \\to [0, 1]\\) be a homeomorphism such that \\(0, 1\\) are fixed points of \\(h\\), such that \\(0\\) is an attracting fixed point. We now ``cross-glue” the cut open \\(\\Sigma \\times [0, 1]\\) along \\(C \\times [0, 1]\\) by \\(h\\), so that the cut-open leaves at different heights glue among themselves. Since \\(h(0) = 0\\) is an attracting fixed points, we will see infinite-genus surface leaves accumulating to \\(\\Sigma \\times \\{0\\}\\) in the resulting foliation. We glue the top and bottom by \\(f\\) to get back \\(M\\) with a new foliation that is definitely not fibered. Moreover, since the cutting-repasting operation does nothing to the foliation on one side, there is a closed transversal all the same: see the green arc above. However, this only gives examples of interesting taut foliations on the class of fibered three-manifolds. Eventually, I would like to describe Gabai’s construction of taut foliations on many more three-manifolds (in fact, one just needs the first betti number to be positive). For now, in the next post we shall discuss the geometry of taut foliations: Sullivan’s theorem (topologically taut implies geometrically taut) and what it has to do with max-flow-min-cut. And then return to the Thurston norm, eventually.",
      "categories": [],
      "tags": ["3-manifolds","contact-topology","taut-foliations"]
    },
  
    {
      "title": "Thurston norm: Part II",
      "url": "/2024/03/12/thurston-norm-ii/",
      "date": "2024-03-12",
      "content": "Theorem. (Thurston) Suppose \\((M, \\partial M)\\) is a compact oriented \\(3\\)-manifold-with-boundary, and every embedded surface representing a nonzero homology class has negative Euler characteristic. Then the Thurston norm-ball of \\((M, \\partial M)\\) is a finite-sided convex polyhedron. The hypothesis of the theorem implies the Thurston norm is in fact a norm, as opposed to a semi-norm. Note that this is satisfied, for instance, if \\(M\\) is a hyperbolic \\(3\\)-manifold with boundary. The theorem will follow from the following lemma about normed spaces, with \\(V = H_2(M, \\partial M; \\Bbb R)\\) as the vector space and \\(\\Lambda\\) as the integral lattice given by image of the change of coefficients homomorphism from the integral cohomology. Lemma. Let \\(V\\) is a finite-dimensional real vector space and \\(\\Lambda \\subset V\\) is an integer lattice. Let \\(\\\\| \\cdot\\\\|\\) be a norm on \\(V\\) and suppose \\(\\\\| \\cdot\\\\|\\) takes integer values on \\(\\Lambda\\). Then the unit ball in \\((V, \\\\| \\cdot\\\\| )\\) is a finite-sided convex polyhedron. Proof. For ease of discussion, suppose \\(V = \\Bbb R^3\\) and \\(\\Lambda = \\Bbb Z^3\\). Whenever \\(\\alpha, \\beta, \\gamma\\) are an integral basis of \\(\\Bbb R^3\\), there is a unique linear functional \\(L_{\\alpha, \\beta, \\gamma}\\) on \\(\\Bbb R^3\\) with integer coefficients such that its values at \\(\\alpha, \\beta, \\gamma\\) are \\(\\\\| \\alpha\\\\| , \\\\| \\beta\\\\| , \\\\| \\gamma\\\\|\\), respectively. Let \\(\\mathbf{e}_i, 1 \\leq i \\leq 3\\) denote the standard integral basis of \\(\\Bbb Z^3\\). Let us denote \\(L_n := L_{\\mathbf{e}_1, \\mathbf{e}_2, \\mathbf{e}_3 + n \\mathbf{e}_1}\\). We observe: \\[\\displaystyle L_n(\\mathbf{e}_3) = L_n(\\mathbf{e}_3 + n \\mathbf{e}_1) - n L_n(\\mathbf{e}_1) = \\\\| \\mathbf{e}_3 + n \\mathbf{e}_1\\\\| - n \\\\| \\mathbf{e}_1\\\\| ,\\] which is non-increasing in \\(n\\), by the triangle inequality. But as this value is integral, we conclude \\(L_n(\\mathbf{e}_3)\\) must be eventually constant. Therefore, for some sufficiently large \\(n\\), \\(L_n(\\mathbf{e}_3) = L_{n+1}(\\mathbf{e}_3)\\), which translates to: \\[\\\\| \\mathbf{e}_3 + n \\mathbf{e}_1\\\\| + \\\\| \\mathbf{e}_1\\\\| = \\\\| (\\mathbf{e}_3 + n \\mathbf{e}_1) + \\mathbf{e}_1\\\\|\\] Now, it is a property of any norm \\(\\| \\cdot\\|\\) on a vector space \\(V\\) that if \\(x, y \\in V\\) are two points such that one has \\(\\| x + y\\| = \\| x\\| + \\| y\\|\\), then \\(\\| \\cdot\\|\\) is a linear function on the entire Euclidean line segment connecting \\(x, y\\). This can be checked by the following tricky triangle inequality argument: suppose \\(t \\in [0, 1]\\), then \\[\\displaystyle \\begin{aligned}\\| x + y\\| = \\| x + ty + (1 - t)y\\| \\leq \\| x + ty\\| + (1-t)\\| y\\| &amp;\\leq \\| x\\| + t\\| y\\| +(1-t)\\| y\\| \\\\ &amp;= \\| x\\| + \\| y\\| \\end{aligned}\\] By hypothesis the first and last terms in the above chain of inequalities are equal, which means all the intermediate inequalities must be equality. Therefore, \\(\\| x + ty\\| = \\| x\\| + t\\| y\\|\\), as desired. As a corollary of this, we obtain \\(\\\\| \\cdot\\\\|\\) is linear along the Euclidean segment connecting \\(\\mathbf{e}_3 + n \\mathbf{e}_1\\) and \\(\\mathbf{e}_1\\). Therefore, \\(\\\\| \\cdot\\\\|\\) agrees with \\(L_n\\) along this segment. Now, consider the linear function \\(L_{m, n} := L_{\\mathbf{e}_1, \\mathbf{e}_2 + m \\mathbf{e}_1, \\mathbf{e}_3 + n \\mathbf{e}_1}\\). Notice \\(L_{m, n}\\) agrees with \\(L_n\\) on \\(\\mathbf{e}_3\\), and by an analogous argument as earlier, \\(L_{m, n}(\\mathbf{e}_2)\\) is eventually constant for large enough values of \\(m\\). Therefore, for some sufficiently large \\(m\\), \\(L_{m, n}(\\mathbf{e}_2) = L_{m+1,n}(\\mathbf{e}_2)\\) and so \\(\\\\| \\cdot\\\\|\\) agrees with \\(L_{m, n}\\) on the Euclidean segment connecting \\(\\mathbf{e}_2 + m \\mathbf{e}_1\\) and \\(\\mathbf{e}_1\\). Finally, consider \\[\\displaystyle L_{m, n, p} = L_{\\mathbf{e}_1, \\mathbf{e}_2 + m \\mathbf{e}_1 + p(\\mathbf{e}_3 + n \\mathbf{e_1}) + p \\mathbf{e}_1, \\mathbf{e}_3 + n \\mathbf{e}_1}\\] Let us write \\(\\alpha = \\mathbf{e}_1\\), \\(\\beta = \\mathbf{e}_2 + m\\mathbf{e}_1\\) and \\(\\gamma = \\mathbf{e}_3 + n\\mathbf{e}_1\\) for brevity. Mutatis mutandis, we conclude that \\(L_{m, n, p}\\) agrees with \\(L_{m, n, p+1}\\) for large enough values of \\(p\\). Consequently, for a sufficiently large value of \\(p\\), we must have \\(\\displaystyle L_{m, n, p}(\\beta) = L_{m, n, p+1}(\\beta)\\). Simplifying, we get \\[\\\\| \\beta+ p \\gamma + p \\alpha\\\\| + \\\\| \\gamma + \\alpha\\\\| = \\\\| \\beta + (p+1)\\gamma + (p+1)\\alpha\\\\|\\] But observe \\(\\\\| \\gamma + \\alpha\\\\| = \\\\| \\mathbf{e}_3 + (n+1)\\mathbf{e}_1\\\\| = \\\\| \\gamma\\\\| + \\\\| \\alpha\\\\|\\). Using this, we deduce, \\[\\\\| \\beta+ p \\gamma + p \\alpha\\\\| + \\\\| \\gamma\\\\| + \\\\| \\alpha\\\\| = \\\\| (\\beta + p\\gamma + p\\alpha) + \\gamma + \\alpha\\\\|\\] For any triple of vectors \\(x, y, z\\) in a normed vector space \\((V, \\| \\cdot\\| )\\), if \\(\\| x +y+z\\| = \\| x\\| +\\| y\\| +\\| z\\|\\) holds, then \\(\\| \\cdot\\|\\) is in fact linear on the entire simplex spanned by \\(x, y, z\\). This follows from an analogous argument as in the segment case: for all \\(t, s \\in [0, 1]\\), \\[\\displaystyle \\begin{aligned}\\| x + y + z\\| &amp;= \\| x + ty + sz + (1 - t)y + (1-s)z\\| \\\\ &amp;\\leq \\| x + ty + sz\\| + (1-t)\\| y\\| + (1-s)\\| z\\| \\\\&amp;= \\| x\\| + \\| y\\| + \\| z\\| \\end{aligned}\\] By hypothesis, all the inequalities above are equalities. Applying this with \\[x = \\beta+p\\gamma+p\\alpha, y = \\gamma, z = \\alpha,\\] we see \\(L_{m, n, p}\\) agrees with \\(\\\\| \\cdot\\\\|\\) on the entire simplex spanned by these vectors. Therefore, the hyperplane \\(\\{L_{m, n, p} = 1\\}\\) defines a facet of the unit norm ball, by convexity of the ball. Notice that \\(L_{m, n, p}\\) is an integral linear functional, and norm of \\(L_{m, n, p}\\) with respect to \\(\\\\| \\cdot\\\\|\\) is \\(1\\) as it is tangential to the unit norm ball, and the rest of the ball lies on the half-space \\(L_{m, n, p} \\leq 1\\). Varying \\(\\mathbf{e}_i\\), \\(1 \\leq i \\leq 3\\) over all integral bases of \\(\\Bbb Z^3\\) by an action of \\(\\mathrm{SL}_3(\\Bbb Z)\\), we see that that the vectors \\(\\beta + p\\gamma+p\\alpha\\), \\(\\gamma\\) and \\(\\alpha\\) can define all projectively rational simplices in \\(\\Bbb{RP}^2\\). Therefore, the unit norm ball of \\(\\\\| \\cdot\\\\|\\) is intersection of half-spaces defined by integral linear functionals of norm \\(1\\). Since the dual norm ball is compact, we conclude the norm ball must be a finite intersection of half-space defined by integral linear functionals. This concludes the proof. As a consequence, we give a solution to the exercise at the end of the previous post. Let \\(L \\subset S^3\\) be the Whitehead link, and \\(\\alpha, \\beta\\) be the generators of \\(H_2(S^3 \\setminus \\nu(L), \\partial \\nu(L); \\Bbb Z)\\) as before. We wish to find a norm-minimizing representative of \\(5 \\alpha + 3 \\beta\\). Recall we proved, \\[\\\\| \\alpha\\\\| = \\\\| \\beta\\\\| = \\\\| (\\alpha + \\beta)/2\\\\| = 1,\\] where \\(\\alpha + \\beta\\) has norm \\(2\\) because this is the homology class of the Seifert surface of the Whitehead link, which is genus \\(1\\) and therefore Euler characteristic \\(2 - 2 \\cdot 1 - 2 = -2\\) (as there are two components). By the Theorem above, we conclude that the entire segment connecting \\(\\alpha, \\beta\\) in the real homology vector space must be contained in the unit sphere of the Thurston norm. Hence, the convex combination \\(5/8 \\cdot \\alpha + 3/8 \\cdot \\beta\\) must have norm \\(1\\). Thus, \\(\\\\| 5 \\alpha + 3 \\beta\\\\| = 8\\). To find a minimizing representative, we simply consider \\(5\\) parallel copies of the surface \\(\\alpha\\), and \\(3\\) parallel copies of the surface \\(\\beta\\). A pair of surfaces chosen from each intersect in a properly embedded arc (connecting a pair of points in the two components of \\(L\\)). We take the oriented sum of the surfaces, by cutting both along the arc and pasting criss-cross so that orientations are preserved. Doing this for all arcs in the intersection resolves the singularities. This is the desired norm-minimizer, as can be checked by computing the Euler characteristic.",
      "categories": [],
      "tags": ["hyperbolic-geometry","taut-foliations","contact-topology"]
    },
  
    {
      "title": "Thurston norm: Part I",
      "url": "/2024/02/28/thurston-norm-i/",
      "date": "2024-02-28",
      "content": "Let \\((M, \\partial M)\\) be a compact, oriented \\(3\\)-manifold. We shall say a compact surface \\((S, \\partial S) \\subset M\\) is properly embedded if \\(S \\subset M\\) is an embedded surface and \\(\\partial S \\subset \\partial M\\) is a collection of embedded curves. A properly embedded oriented surface may be triangulated to obtain a singular \\(2\\)-cycle relative to \\(\\partial M\\), which represents its fundamental class \\([(S, \\partial S)] \\in H_2(M, \\partial M; \\Bbb Z)\\). Conversely, suppose we have a class \\(\\alpha \\in H_2(M, \\partial M; \\Bbb Z)\\). Then its Poincare dual \\(\\mathrm{PD}(\\alpha)\\) gives rise to a map \\(\\phi : M \\to S^1\\) by chasing the sequence isomorphisms: \\[\\displaystyle H_2(M, \\partial M; \\Bbb Z) \\cong H^1(M, \\Bbb Z) \\cong \\mathrm{Hom}(\\pi_1(M), \\Bbb Z) \\cong [M, S^1]\\] Let \\(p \\in S^1\\) be a regular value of \\(\\phi\\). Then \\(S = \\phi^{-1}(p)\\) satisfies \\([(S, \\partial S)] = \\alpha\\). One might then ask what is the minimum possible complexity of a surface representing a given relative second homology class. One measure of such a complexity is genus, but since our surfaces have boundary, we would like to consider the negative part of the Euler characteristic instead. Definition. For \\(\\alpha \\in H_2(M, \\partial M; \\Bbb Z)\\), the Thurston norm of \\(\\alpha\\) is defined as \\[\\displaystyle \\|\\alpha\\| = \\mathrm{inf}_S \\sum_{S_i \\subset S} \\max\\{0, -\\chi(S_i)\\},\\] where \\(S\\) varies over all surfaces such that \\(\\alpha = [(S, \\partial S)]\\) and \\(S_i\\) are connected components of \\(S\\). Notice that sphere, disk, annulus and torus components of a surface contribute nothing to the norm. In some sense, this is intentional: one is searching for surfaces of minimal complexity to cut \\(M\\) along after it has already been cut along all the two-sided incompressible spheres (i.e., prime decomposition) and a minimal collection of two-sided incompressible tori (i.e., JSJ decomposition). Nevertheless, formally ignoring these cases by not assigning them any importance in the norm allows one to define it in full generality. Observation. Let \\(M\\) be irreducible (i.e., all embedded spheres either bound a ball or are boundary-parallel). If \\((S, \\partial S) \\subset M\\) realizes Thurston norm in its homology class (we shall say: \\((S, \\partial S)\\) minimizes the norm), then \\(S\\) is incompressible. Proof. Suppose not. Irreducibility guarantees we can assume there are no spherical components. Then there must be a closed curve \\(\\gamma \\subset S\\) which is not nullhomotopic in \\(S\\), but is nullhomotopic in \\(M\\). Then the loop theorem implies \\(\\gamma\\) must also bound a disk \\(D\\) (called a “compressing disk”) in $M$. Consider a thickening of $S \\cup D \\subset M$ and take one of the boundary components to obtain a “compression” of \\(S\\) along \\(D\\), which we shall call \\(S'\\). Note \\(\\chi(S') = \\chi(S) + 2\\). If \\(\\gamma\\) is non-separating, we observe that \\(S'\\) cannot be a sphere by irreducibility of \\(M\\). If \\(\\gamma\\) is separating, say \\(S' = S_1' \\cup S_2'\\), then \\(S_1', S_2'\\) cannot be spheres as \\(\\gamma \\subset S\\) is essential. Therefore, \\((S', \\partial S')\\) has total negative Euler characteristic strictly less than that of \\((S, \\partial S)\\), contradicting the hypothesis that \\((S, \\partial S)\\) is a norm-minimizer. Remark. A surface \\((S, \\partial S) \\subset M\\) is said to be boundary-compressible if there is an embedded disk \\(D \\subset M\\) (called a “boundary-compressing disk”) such that $\\partial D = \\alpha \\cup \\beta$ is a union of a pair of arcs sharing endpoints such that $D \\cap S = \\alpha$ is an essential arc in $S$ and $D \\cap \\partial M = \\beta$. Since compressing along a boundary compressing disk is tantamount to cutting $S$ along $\\alpha$, the result is a surface $S’$ such that $\\chi(S’) = \\chi(S) + 1$. If $M$ is boundary-irreducible (i.e., $\\partial M$ has no spherical components and is $\\pi_1$-injective in $M$), we can rule out disk components in $S’$ by an analogous argument as above. Therefore, in this case the norm-minimizing surfaces must also be boundary-incompressible. Why stop here? We may define for any rational class $\\alpha \\in H_2(M, \\partial M; \\Bbb Q)$, $|\\alpha| = |k \\alpha|/k$ where $k$ is an integer so that $k\\alpha$ is integral. We may even extend $|\\cdot|$ to all of $H_2(M, \\partial M; \\Bbb R)$: simply write a real class as a real linear combination of an integral basis of $H_2(M, \\partial M; \\Bbb Z)$, and approximate the coefficients by rationals. There are two things to be checked in order to ensure this is well-defined: Is it true that $|k[S]|=k|[S]|$ for integer $k$? Is it true that $|[S] + [S’]| \\leq |[S]| + |[S’]|$? Check 1. Suppose $S’ = \\phi^{-1}(p)$ is a surface that represents $k[S]$, where $\\phi :M \\to S^1$ corresponds to the class $k \\mathrm{PD}[S] \\in H^1(M; \\Bbb Z)$. This map lifts along the $k$-fold covering map $S^1 \\to S^1$. Let us denote the lift as $\\tilde{\\phi} : M \\to S^1$. Then $S$ is disjoint union of the surfaces $S_i = \\tilde{\\phi}^{-1}(p_i)$, $1 \\leq i \\leq k$, each in the homology class of $[S]$. Moreover, if we choose $S’$ to be a norm-minimizer, each connected component $S_i$ has to be a norm-minimizer as well. Thus, $|k[S]| = k |[S]|$. Check 2. Suppose $M$ is irreducible and $\\partial M = \\emptyset$. We choose $S, S’$ to be norm-minimizers, which implies they are incompressible by an earlier observation. We put the surfaces in general position. Note that $S \\cap S’$ consists of disjoint simple closed curves as $S, S’ \\subset M$ are embedded. Suppose $\\gamma$ is a closed curve in the intersection which is nullhomotopic in $M$, then by incompressibility it is nullhomotopic in both $S, S’$. Without loss of generality, say $\\gamma$ is innermost in $S$, i.e., there’s no other loop in the Jordan disk bounded by $\\gamma$ in $S$ that is in the intersection locus $S \\cap S’$. The sphere co-bounded by the disk bounding $\\gamma$ in $S, S’$ respectively bounds a ball by irreducibility of $M$, and we may push $S$ to the boundary of the ball to reduce the cardinality of the intersection locus. After doing this finitely many times, we are left with an intersection locus consisting only of disjoint simply closed curves which are essential in both $S$ and $S’$. The local picture near the intersection is the same as $\\mathbf{X} \\times S^1$ where $\\mathbf{X}$ is the letter X. We replace this by $\\pmb{)(} \\times S^1$ in a way that the resulting surface is oriented. The resulting surface $S’’$ is obtained by cutting $S, S’$ along certain disjoint essential simple closed curves and gluing along the seams. Therefore, $\\chi(S’’) = \\chi(S) +\\chi(S’)$. Moreover, no component of $S’’$ can be a sphere, as that would imply one of the seams in $S$ or $S’$ is non-essential. Observe $S’’$ represents the homology class $[S] + [S’]$. Therefore, $|[S] +[S’]| \\leq |[S]| + |[S’]|$, as desired. If $\\partial M \\neq \\emptyset$, and $M$ is irreducible and boundary-irreducible, then from the remark below the observation above, we may likewise conclude the same inequality. The verifications above implies $| \\cdot |$ is a well-defined semi-norm on $H_2(M, \\partial M; \\Bbb Q)$ and as such can be continuously extended to a semi-norm on $H_2(M, \\partial M; \\Bbb R)$. Note that if $(M, \\partial M)$ is a hyperbolic $3$-manifold with cuspidal boundary, this is in fact a norm, as there cannot be any essential spheres, tori, disks or annuli inside the manifold, which are precisely the surfaces on which the Thurston norm vanishes. Definition. The Thurston norm-ball of $(M, \\partial M)$ is defined to be the unit ball in $H^2(M, \\partial M; \\Bbb R)$ under the Thurston norm. Figure: Thurston norm-ball for the Whitehead link. As an example, we try to compute the Thurston norm for the complement $S^3 \\setminus \\nu(L)$ of the Whitehead link $L \\subset S^3$. The real homology of the complement is a real vector space of rank $2$, generated by Poincare dual to the meridians of each of the components $K_1, K_2$ indicated in the picture. These are given by the thrice-punctured sphere $\\alpha$ bounded by $K_1$, and the punctured torus $\\beta$ bounded by $K_2$, respectively, indicated by the red and blue surfaces in the picture. Each of these have Euler characteristic $-1$ and are norm-minimizing, so they are in the unit sphere for the Thurston norm. Symmetrically, $-\\alpha, -\\beta$ are also elements in the unit sphere. In the picture we also have a green dot which corresponds to the class of $(\\alpha + \\beta)/2$. Note that $\\alpha + \\beta$ is represented by the surface drawn in green, given by an oriented sum of the surfaces $\\alpha$ and $\\beta$. This is a “Seifert surface” for the Whitehead link, and its Euler characteristic is \\(-2\\) (sum of the ones for \\(\\alpha, \\beta\\)). In fact, we shall show next time that the entire line segment connecting \\((1, 0)\\) and \\((0, 1)\\) is contained in the unit sphere. Therefore, the unit norm-ball is the magenta diamond above. Exercise. Can you imagine a norm-minimizing representative of \\(2 \\alpha + \\beta\\)? How about \\(5 \\alpha + 3 \\beta\\)?",
      "categories": [],
      "tags": ["hyperbolic-geometry","taut-foliations","contact-topology"]
    },
  
    {
      "title": "The h-principle for Legendrian immersions",
      "url": "/2022/05/17/h-principle-legendrian/",
      "date": "2022-05-17",
      "content": "Consider a bicycle on a 2-dimensional cartesian plane. We will choose coordinates \\((x, y)\\) for the position of the bicycle, and angle \\(\\theta\\) that the steering wheel makes with the \\(x\\)-axis. In other words, our model of the bicycle has three degrees of freedom, two of them given by position in \\(\\Bbb R^2\\) and the other given by the angle of the steering wheel in \\(S^1\\). Thus, the configuration space of the bicycle is \\(M = \\Bbb R^2 \\times S^1\\). The trajectory of such a bicycle in motion \\(\\gamma(t) = (x(t), y(t))\\) on \\(\\Bbb R^2\\) must have tangent \\(\\gamma'(t)\\) parallel to the direction \\((\\cos \\theta(t), \\sin \\theta(t))\\) of the steering wheel. In other words, the motion of the bicycle is constrained by the differential relation \\(\\dot{x} \\cos(\\theta) - \\dot{y} \\sin(\\theta) = 0\\) on \\(M\\). The relation can be described as a rank 2 subbundle \\(\\xi \\subset TM\\) given by kernel \\(\\xi = \\ker \\alpha\\) of a differential \\(1\\)-form \\(\\alpha = \\cos(\\theta) dx - \\sin(\\theta) dy\\) on \\(M\\). Motions of trajectories of the bicycle are therefore paths \\(\\gamma\\) in \\(M\\) which are parallel to the distribution \\(\\xi\\), i.e., \\(\\gamma' \\in \\xi\\). The situation here is the simplest example of a so-called contact manifold. A contact manifold is a manifold \\(M\\) of odd dimension \\(\\dim M = 2n+1\\) equipped with a \\(1\\)-form \\(\\alpha\\) which is completely nonintegrable, i.e., \\(\\alpha \\wedge (d\\alpha)^{\\wedge n}\\) is nowhere-vanishing. Contact manifolds are studied upto contactomorphisms, which are diffeomorphisms preserving the conformal class of the contact \\(1\\)-forms. Therefore, contactomorphisms preserve the associated hyperplane distribution \\(\\xi = \\ker \\alpha\\), which carries with it a conformal class of a fiberwise symplectic structure given by \\(d\\alpha\\); we denote this class by \\(\\mathrm{CS}(\\xi)\\). It is a theorem that any contact manifold is locally contactomorphic to \\((\\Bbb R^{2n+1}, \\xi_0)\\) where \\[\\xi_0 = \\ker(dz - \\sum_{i = 1}^n y_i dx_i)\\] This can be seen in the bicycle example, as one can locally scale appropriately so that the form becomes \\(dx - \\tan(\\theta) dy\\) and use \\(\\tan(\\theta)\\) as a coordinate. Contact manifolds are the odd-dimensional counterparts to symplectic manifolds, which typically occur in physics as phase spaces \\(T^*Q\\) of a manifold \\(Q\\). The analogous example in the contact world is the \\(1\\)-jet space \\(J^1 Q = \\Bbb R \\times T^* Q\\), where the contact form is defined by \\(dz - \\sum_i p_i dq_i\\) where \\(p_i, q_i\\) are the generalized position and momentum coordinates of the phase space. Note that \\(\\sum_i p_i dq_i\\) is the tautological \\(1\\)-form on \\(T^* Q\\), and its exterior derivative \\(\\sum_i dp_i \\wedge dq_i\\) is exactly the symplectic form on the phase space. Functions \\(f : Q \\to \\Bbb R\\) give rise to Lagrangian submanifolds of \\(T^* Q\\) given by image of the exact \\(1\\)-form considered as a section \\(df : Q \\to T^* Q\\). Likewise, functions \\(f : Q \\to \\Bbb R\\) give rise to certain special submanifolds of \\(J^1 Q\\) given by image of the \\(1\\)-jet prolongation \\(J^1(f) : Q \\to J^1 Q\\). These are called Legendrian submanifolds; we give a general definition below. An immersion \\(f : N \\to (M^{2n+1}, \\xi)\\) into a contact manifold is called isotropic if \\(f\\) is \\(\\xi\\)-parallel, i.e., \\(df\\) maps \\(TN\\) to \\(\\xi\\). This imposes the condition that \\(\\dim N \\leq n\\), and we say \\(f\\) is Legendrian if the equality \\(\\dim N = n\\) is achieved. Since \\(3 = 2 \\cdot 1 + 1\\), the trajectories of motion of a bicycle were Legendrian paths in \\(\\Bbb R^2 \\times S^1\\). Bicycle tracks have interesting properties: despite being constrained by a closed differential relation (in this case, a differential equation), one can travel from any point to any other point using a bicycle (that’s part of the point of a bicycle, really…). Not only that, but it’s possible to carry out impressive maneuvers to navigate through virtually any set of obstacles. The following theorem might shed some light into this phenomenon. Let us call a pair \\((F, f) : (TN, N) \\to (TM, M)\\) of maps to be a formal Legendrian immersion if \\(F\\) is a bundle monomorphism covering \\(f\\) and \\(F\\) is fiberwise Legendrian (guess what this means). Any Legendrian immersion \\(f\\) gives rise to a formal Legendrian immersion \\((df, f)\\), and to distinguish this sub-class of formal immersions we call them holonomic. When we speak of homotopies, we shall think of them as happening inside this “space” of formal Legendrian immersions. We also equip \\(M\\) with an arbitrary ambient Riemannian metric. Theorem. Any formal Legendrian immersion is homotopic to a holonomic Legendrian immersion by a \\(C^0\\)-small homotopy. The result is also true for CW-complex parametrized families of Legendrian immersions and relative to submanifolds on which the formal immersions are already holonomic. We will deduce this from Eliashberg-Mishachev’s holonomic approximation theorem. The form of the theorem we shall need is the following. Let \\(X \\to V\\) be a fiber bundle, \\(\\mathcal{R} \\subset X^{(r)}\\) be a subset of the total space of the associated \\(r\\)-jet bundle, called a differential relation of order \\(r\\) (for example, the constraint on bicycle trajectories can be viewed as a differential relation of order \\(1\\)). Sections \\(V \\to X^{(r)}\\) which land inside \\(\\mathcal{R}\\) will be called formal sections of \\(\\mathcal{R}\\), and among these, those which come from \\(r\\)-jet prolongation of a section \\(V \\to X\\) will be called holonomic sections. We shall introduce two important properties of a differential relation before stating the theorem: Let \\(\\phi : I^k \\to V\\) be a continuous map, \\(\\{f_t : \\{\\phi(t)\\} \\to V : t \\in I^k\\}\\) a continuous family of formal sections and \\(\\{\\widetilde{f}_t : \\mathrm{Op}(\\phi(t)) \\to V : t \\in \\partial I^k\\}\\) be a family of holonomic extensions of \\(f_t\\) for \\(t \\in \\partial I^k\\). Then we say \\(\\mathcal{R}\\) is (parametrically) locally integrable if there exists a continuous family of holonomic extensions \\(\\{\\widetilde{f}_t : \\mathrm{Op}(\\phi(t)) \\to V : t \\in I^k\\}\\) agreeing with the earlier family for all \\(t \\in \\partial I^k\\). For \\(k = 0\\), note that this simply says every jet in \\(\\mathcal{R}\\) is value of the \\(r\\)-jet prolongation of some section of \\(\\mathcal{R}\\) at the basepoint. Let \\(D^k \\times D^{n-k} \\cong H\\) denote a handle, and let \\(C = D^k \\times \\{0\\} \\subset H\\) denote the core. Let \\(\\phi : H \\times I^m \\to V\\) be an isotopy, and let \\(H_t := \\phi(H \\times \\{t\\})\\), \\(C_t := \\phi(C \\times \\{t\\}) \\subset H_t\\) for all \\(t \\in I^m\\). Suppose we are given (a) a family of germs of holonomic sections \\(\\{f_t : \\mathrm{Op}(H_t) \\to \\mathcal{R}\\}\\) near the handles, and (b) a family-homotopy of germs of holonomic sections \\(\\{f_{t, s} : \\mathrm{Op}(\\partial H_t \\cup C_t) \\to \\mathcal{R}\\}\\), \\(s \\in [0, 1]\\) near the union of the boundary and the core of the handles, such that \\(f_t\\) extends \\(f_{t, 0}\\), and \\(\\{f_{t, s}\\}\\) is a constant in \\(s\\) on \\(\\mathrm{Op}(\\partial H_t \\cap C_t)\\). The relation \\(\\mathcal{R}\\) is said to be (parametrically) microflexible if there exists \\(\\varepsilon &gt; 0\\), depending on \\(\\phi\\) and the data given, such that there is a homotopy of germs of holonomic sections \\(\\widetilde{f}_{t, s} : \\mathrm{Op}(H_t) \\to \\mathcal{R}\\), \\(s \\in [0, \\varepsilon]\\) extending the given data while staying constant on \\(\\mathrm{Op}(\\partial H_t \\cap C_t)\\). Theorem. (Eliashberg-Mishachev) \\(\\mathcal{R} \\subset X^{(r)}\\) be a locally integrable microflexible differential relation of order \\(r\\). Let \\(K \\subset V\\) be a positive codimension subcomplex and \\(f : \\mathrm{Op}(K) \\to \\mathcal{R}\\) be a germ of a formal section. Then for any arbitrarily small \\(\\delta, \\varepsilon &gt; 0\\), there exists a diffeotopy \\(\\{h_t : V \\to V\\}\\) which is \\(\\delta\\)-small in \\(C^0\\)-norm, and a holonomic section \\(\\widetilde{f} : \\mathrm{Op}(h_1(K)) \\to \\mathcal{R}\\) such that \\(\\widetilde{f}, f\\) are uniformly \\(\\varepsilon\\)-close on \\(\\mathrm{Op}(h_1(K)) \\subset \\mathrm{Op}(K)\\). Suppose \\((M, \\xi_M), (N, \\xi_N)\\) are two contact manifolds. An immersion \\(f : M \\to N\\) is called isocontact if \\(f^*\\mathrm{CS}(\\xi_N) = \\mathrm{CS}(\\xi_M)\\). A map from \\(M\\) to \\(N\\) is equivalently a section of the product bundle \\(X = M \\times N\\) over \\(M\\), and the property of being an isocontact immersion can be formulated as a differential relation \\(\\mathcal{R} \\subset X^{(1)}\\). \\(\\mathcal{R}\\) is locally integrable by Gray’s stability theorem, as any linear isocontact embedding can be exponentiated to contact charts. \\(\\mathcal{R}\\) is also microflexible, as the contact isotopy extension theorem holds with no restrictions (an interesting remark here is that the same cannot be said for the isosymplectic version, as the symplectic isotopy extension demands \\(H^2(H, \\partial H \\cup C) = 0\\) which is true iff \\(H\\) is not a \\(1\\)-handle.) Thus, holonomic approximation theorem applies: a formal isocontact immersions to \\(N\\) near a positive codimension subcomplex of \\(M\\) can be homotoped to a holonomic isocontact immersion on a \\(C^0\\)-slightly perturbed domain. In fact, the effect of the perturbation of the domain can be reversed by the contact isotopy extension theorem, using the observation that \\(\\mathcal{R}\\) is invariant under the action of \\(\\mathrm{Cont}(M)\\) on \\(X^{(1)} = J^1(M, N)\\). Now suppose \\(V\\) is an arbitrary manifold, \\((M, \\xi_M)\\) is a contact manifold, and \\[(F, f) : (TV, V) \\to (TM, M)\\] is a formal Legendrian immersion. \\(F\\) maps \\(TV\\) fiberwise into \\((\\xi_M, \\mathrm{CS}(\\xi_M))\\), therefore there is a canonical symplectic complement of \\(F(TV)\\) in \\(f^*\\xi\\), isomorphic to \\(T^*V\\). Choosing a co-orientation for the distribution \\(\\xi\\), we get a trivial line bundle complementary to \\(\\xi \\subset TM\\). Combining, we get that \\(F(TV) \\subset f^* TM\\) has a complementary bundle isomorphic to \\(T^*V \\times \\Bbb R\\). This provides an extension of \\((F, f)\\) to a formal isocontact immersion \\((\\widehat{F}, \\widehat{f}) : (T J^1V, J^1V) \\to (TM, M)\\). Applying the isocontact holonomic approximation theorem near the zero section as in the last paragraph, we obtain a holonomic Legendrian immersion \\(\\widetilde{f} : V \\to M\\) homotopic through formal Legendrian immersions to \\((F, f)\\) by a \\(C^0\\)-small homotopy. This finishes the proof. In particular, this says any immersed path in \\(\\Bbb R^2\\), no matter how complicated, can be approximated by bicycle trajectories. This is because any path in \\(\\Bbb R^2\\) may be lifted to an immersion \\(\\Bbb R^2 \\times S^1\\) and upgraded to a formal Legendrian immersion, at which point one can use the result above. The projection of the Legendrian path back to \\(\\Bbb R^2\\) (the “front projection”) need no longer be smooth, and in fact will contain many cusps: imagine the maneuvers needed to park a car in a tight space, and the track left by the process. In an appropriate sense, the holonomic approximation is possible precisely because of these zig-zags through cusps, which enable the tangent vectors to be parallel to the very twisty contact distribution.",
      "categories": [],
      "tags": ["contact-topology","h-principle","symplectic-topology"]
    },
  
    {
      "title": "Seiberg-Witten Theory: IV",
      "url": "/2022/03/19/sw-theory-iv/",
      "date": "2022-03-19",
      "content": "Let \\(M\\) be a closed oriented smooth \\(4\\)-manifold with a choice of a Riemannian metric \\(g\\), and a spinC-structure \\(\\mathfrak{s}\\). The spinC-structure gives rise to a Clifford representation of the complexified tangent bundle \\(\\rho : T^{\\Bbb C} M \\to \\mathrm{End}(S)\\) on the complex spinor bundle \\(S\\) which is of rank \\(4 = 2^{4/2}\\), admitting a chiral decomposition \\(S = S^- \\oplus S^+\\) and associated determinant line bundle \\(L = \\Lambda^2 S^+ \\cong \\Lambda^2 S^-\\) whose 1st Chern class is the integral lift of the 2nd Stiefel-Whitney class of \\(M\\) coming from \\(\\mathfrak{s}\\), as discussed in Part III. We choose a connection \\(A\\) on \\(L\\) which, combined with the LC connection on \\((M, g)\\), determines a spin connection on \\(S\\). Then there is an associated Dirac operator \\(\\slash \\!\\!\\! \\partial_A : \\Gamma^{\\pm}(S) \\to \\Gamma^{\\mp}(S)\\). Moreover, we have the Hodge star operator \\(\\star : \\Omega^2(M) \\to \\Omega^2(M)\\) and we shall call the eigenspaces of \\(\\star\\) of eigenvalues \\(\\pm 1\\) as the self-dual and anti-self-dual \\(2\\)-forms, giving a decomposition \\(\\Omega^2 = \\Omega^{2,+} \\oplus \\Omega^{2, -}\\); we shall write \\(\\omega^+\\) to mean the self-dual part of a \\(2\\)-form \\(\\omega\\). The SD-ASD decomposition mirrors the chiral decomposition \\(S = S^+ \\oplus S^-\\). More precisely, the connection between these is explained by the spin representation \\(\\rho : T^{\\Bbb C} M \\to \\mathrm{End}(S) = S \\otimes S\\) which may be baked to a representation \\[\\displaystyle \\rho : \\Omega^2(M) \\otimes \\Bbb C = \\Lambda^2 T^*M \\otimes \\Bbb C \\to S \\otimes S\\] by replacing wedge with Clifford multiplication wherever it appears. We obtain the decomposition \\(S^+ \\otimes S^- \\cong \\Omega^0 \\oplus \\Omega^{2,+}\\), a mnemonic for which is that a left-handed and a right-handed spin-1/2 fermion can combine to give a spin 0 (which has a single state, so rank of \\(\\Omega^0\\) is \\(1\\)) or a spin 1 (which has three states -1, 0, 1, so rank of \\(\\Omega^{2,+}\\) is \\(3\\)) fermion; note that the projection to the first factor is simply taking trace. Whenever \\(\\psi\\) is a positive chirality spinor (a section of \\(S^+\\)), we will write \\((\\psi \\otimes \\psi^\\dagger)_0\\) to mean the trace-0 part of the tensor, conceptualized as a self-dual 2-form. Given all of this, we shall now write down the Seiberg-Witten equations. For a pair \\((A, \\psi) \\in \\mathcal{A}(L) \\oplus \\Gamma(S^+)\\), these are given by \\[\\displaystyle \\slash \\!\\!\\! \\partial_A \\psi = 0 \\\\ F_A^+ = (\\psi \\otimes \\psi^\\dagger)_0\\] The second equation is the quadratic part; observe both sides are \\(i \\Bbb R\\)-valued self-dual \\(2\\)-forms on \\(M\\). We may perturb the SW equations by adding \\(i \\mu\\) to the right hand side of the second equation, for a fixed self-dual \\(2\\)-form \\(\\mu\\), which I expect is useful for transversality arguments later. The natural gauge symmetries of these equations is recorded by the group \\(\\mathcal{G} = C^\\infty(M, S^1)\\). For \\(g \\in \\mathcal{G}\\), it acts on the complex vector bundle \\(S^+\\) by pointwise multiplication; thus the induced action on sections is \\(\\psi \\mapsto g \\psi\\) and the induced action on the line bundle \\(L\\) is by \\(g^2\\) (see Part III); this implies the action by conjugation on the covariant derivative \\(\\nabla^A_L\\) corresponding to the connection \\(A\\) is given as follows: \\[\\displaystyle g^{-2} \\nabla^A_L g^{2} = g^{-2} d g^{2} + g^{-2} A g^2 = -2g^{-1} dg + A\\] Therefore, the induced action on connections is given by \\(A \\mapsto -2g^{-1} dg + A\\). It is straightforward to check that SW-equations are invariant under the action of \\(\\mathcal{G}\\); indeed \\(\\slash \\!\\!\\! \\partial_{g\\cdot A} (g \\cdot \\psi) = \\gamma^\\mu ( g^{-1} \\nabla^A_i g )g \\psi = g^{-1} \\gamma^\\mu \\nabla^A_i \\psi\\) and \\(F_{g\\cdot A}^+ = F_A^+\\) as deforming the connection by a locally exact form \\(-2g^{-1} dg = -2d\\log(g)\\) leaves the curvature invariant. The moduli space of solutions of the SW-equations, defined by the space of solutions modded out by the action of \\(\\mathcal{G}\\) will be denoted as \\(\\mathcal{M}_{\\mathfrak{s}, g, \\mu}\\). The main result which will be discussed in the course of time is that \\(\\mathcal{M}_{\\mathfrak{s}, g, \\mu}\\) is a compact, smooth, oriented manifold of dimension \\(-(2\\chi(M) + 3\\sigma(M))/4 + c_1(L)^2\\) for a generic perturbation \\(\\mu\\) when \\(b_2^+ &gt; 1\\). In the zero dimensional case, counting the signed connected components gives us the so-called Seiberg-Witten invariants of \\(M\\).",
      "categories": [],
      "tags": ["gauge-theory","index-theory","spin-geometry"]
    },
  
    {
      "title": "Seiberg-Witten Theory: III",
      "url": "/2022/01/03/sw-theory-iii/",
      "date": "2022-01-03",
      "content": "I will begin by discussing a little bit about my limited understanding of the origin of the Dirac operator, readers are welcome to point out the many errors that will follow. A relativistic scalar field is a function \\(\\phi : \\Bbb R^4 \\to \\Bbb C\\) on space-time. The Lagrangian for a free scalar field of mass \\(m &gt; 0\\) is \\(\\mathcal{L} = (\\eta^{\\mu \\nu} \\partial_\\mu \\phi^* \\partial_\\nu \\phi - m^2 \\phi^*\\phi)/2\\) where \\(\\eta^{\\mu \\nu}\\) denotes the Minkowski metric. This is supposed to mimic the Lagrangian for a simple harmonic oscillator, given as \\(\\mathcal{L} = (\\dot{x}^2 - \\omega^2 x^2)/2\\); indeed, a common way to motivate the free scalar field is as a scaling limit of a lattice of harmonic oscillators across space-time, under the mesh of the lattice tending to \\(0\\). See here for an interesting discussion regarding the validity of such an interpretation. We compute the Euler-Lagrange equations: \\[\\displaystyle \\begin{aligned}\\frac{\\partial}{\\partial x^\\mu} \\frac{\\partial \\mathcal{L}}{\\partial \\dot{\\phi}_\\mu} &amp;= \\frac{\\partial \\mathcal{L}}{\\partial \\phi} \\\\ \\frac{\\partial}{\\partial x^\\mu} \\frac{\\partial \\mathcal{L}}{\\partial \\dot{\\phi}^*_\\mu} &amp;= \\frac{\\partial \\mathcal{L}}{\\partial \\phi^*}\\end{aligned}\\] which gives \\((\\Box + m^2)\\phi = 0\\) and \\((\\Box + m^2)\\phi^* = 0\\) where \\(\\Box = \\eta^{\\mu\\nu} \\partial^2_{\\mu\\nu} = \\partial^2_t - \\partial^2_x - \\partial^2_y - \\partial^2_z\\) is the d’Alembert operator; this is known as the Klein-Gordon equation. The drawback of the setup of free scalar fields is that there is no obvious quantum mechanical interpretation; indeed, observe that the Lagrangian as a function of the generalized coordinates \\(\\phi, \\phi^*, \\partial_\\mu \\phi, \\partial_\\mu \\phi^*\\) is invariant under Lorentz transformations as \\(\\eta^{\\mu \\nu}\\) is Lorentz-invariant; Noether’s theorem then gives rise to a conserved quantity which may be checked to be the 4-vector \\(j^\\mu = \\phi^* \\partial_\\mu \\phi - \\phi \\partial_\\mu \\phi^*\\). The conservation can be explicitly checked by verifying \\(\\eta^{\\mu \\mu} \\partial_\\mu j^\\mu = 0\\). This is the probability current density; in QM the corresponding quantity has \\(j^0\\) as the probability density, but in this setup \\(j^0 = \\phi^* \\partial_t \\phi - \\phi \\partial_t \\phi^*\\) can be negative, since the Klein-Gordon equation is a second order PDE so the initial conditions \\(\\psi, \\partial_\\mu \\psi\\) at \\(t = 0\\) can be chosen arbitrarily. This is one of the reasons Dirac wanted to figure out a first order PDE as the equation of motion. So he started by writing \\((i \\gamma^\\mu \\partial_\\mu - m) \\phi = 0\\) where \\(\\gamma^0, \\gamma^1, \\gamma^2, \\gamma^3\\) are arbitrary “constants”. The equation must be compatible with the Klein-Gordon equation for free scalar field, so by multiplying the above equation with its conjugate: \\[\\displaystyle \\begin{aligned}(i \\gamma^\\mu \\partial_\\mu + m)(i \\gamma^\\mu \\partial_\\mu - m) \\phi &amp;= 0 \\\\ \\implies (\\gamma^{\\mu} \\gamma^{\\nu} \\partial^2_{\\mu \\nu} + m^2)\\phi &amp;= 0\\end{aligned}\\] Comparing with the Klein-Gordon equation, we obtain the relations \\(\\gamma^\\mu \\gamma^\\nu + \\gamma^\\nu \\gamma^\\mu = 2\\eta^{\\mu \\nu}\\). Astute readers will observe that these are exactly the Clifford relations where the underlying quadratic space is the Minkowski space \\((\\Bbb R^4, \\eta^{\\mu\\nu})\\), discussed in detail in the positive definite case in Part I and II. There is a completely analogous irreducible complex spinor representation of \\(\\mathrm{Cliff}_{1, 3}(\\Bbb R)\\) on \\(S = \\Bbb C^4\\), for example using the gamma matrices \\[\\displaystyle \\begin{aligned}\\gamma^0 &amp;= \\begin{pmatrix}1 &amp; &amp; &amp; \\\\ &amp; 1 &amp; &amp; \\\\ &amp; &amp; -1 &amp; \\\\ &amp; &amp; &amp; -1\\end{pmatrix}, &amp;\\gamma^1 = \\begin{pmatrix} &amp; &amp; &amp; 1 \\\\ &amp; &amp; 1 &amp; \\\\ &amp; -1 &amp; &amp; \\\\ -1 &amp; &amp; &amp; \\end{pmatrix}, \\\\ \\gamma^2 &amp;= \\begin{pmatrix} &amp; &amp; &amp; i \\\\ &amp; &amp; i &amp; \\\\ &amp; -i &amp; &amp; \\\\ -i &amp; &amp; &amp; \\end{pmatrix}, &amp;\\gamma^3 = \\begin{pmatrix} &amp; &amp; 1 &amp; \\\\ &amp; &amp; &amp; -1 \\\\ -1 &amp; &amp; &amp; \\\\ &amp; 1 &amp; &amp; \\end{pmatrix}\\end{aligned}\\] The operator \\(\\slash \\!\\! \\partial = \\gamma^\\mu \\partial_\\mu : C^\\infty(\\Bbb R^4) \\otimes S \\to C^\\infty(\\Bbb R^4) \\otimes S\\) is called the Dirac operator. Note that \\(\\slash \\!\\! \\partial^2 = \\Box\\) is the square-root of the d’Alembertian. We can think of the domain and codomain \\(C^\\infty(\\Bbb R^4) \\otimes S \\cong C^\\infty(\\Bbb R^4, S)\\) as \\(S\\)-valued functions on spacetime or spinor fields. Thus, solutions to the Dirac operator are spinor fields \\(\\phi = (\\phi^0, \\phi^1, \\phi^2, \\phi^3) : \\Bbb R^4 \\to S\\) and a basis of solutions can be extracted out: \\(e^{-i m t} \\mathbf{e}_1, e^{-i m t} \\mathbf{e}_2, e^{i m t} \\mathbf{e}_3, e^{i m t} \\mathbf{e}_4\\). These are independent of the spatial coordinates, so one can imagine these as the rest-solutions. Let’s take some time to interpret what these four solutions mean. Observe that the complexified Lie algebra \\(\\mathfrak{spin}(1,3) \\subset \\mathrm{Cliff}(1, 3)\\) sits inside the Clifford algebra spanned by the \\(S_{ij} = \\frac12 \\gamma^i \\gamma^j\\) for \\(i \\neq j \\in \\{0, \\cdots, 3\\}\\) which can be checked by exhibiting these as tangent vectors to an appropriate path starting at the identity, and observing that the dimension matches that of \\(\\Lambda^2 \\Bbb R^4 \\cong \\mathfrak{so}(4)\\) which is the same as \\(\\mathfrak{so}(1, 3)\\) upon complexifying. The elements \\(S_{01}, S_{02}, S_{03}\\) are infinitisimal Lorentz boosts and \\(S_{23}, S_{31}, S_{12}\\) are the infinitisimal rotations, about the \\(x, y, z\\)-axes, respectively. Next, note that in the gamma matrix representation above, \\(i S_{12}\\) has eigenvectors \\(\\mathbf{e}_1, \\mathbf{e}_3\\) with eigenvalue \\(1/2\\) (“spin up” states) and eigenvectors \\(\\mathbf{e}_2, \\mathbf{e}_4\\) with eigenvalue \\(-1/2\\) (“spin down” states). What this says about the solutions above is that the first pair and the second pair of solutions are fields with different spins along the \\(z\\)-axis. What does the fact that there are two pairs of spin up/down solutions mean? The point is the first pair solves for fermions at rest, whereas the second pair solves for antifermions at rest: mass is never negative, so \\(e^{imt} = e^{-im(-t)}\\) indicates that the time is negated, and moreover from the definition of relativistic 4-momentum, the energy \\(E = -m\\) is negated as well… that is, the second pair of solutions are predicting fields which quantize to particles travelling backward in time with negative energy. The Dirac equation, therefore, solves for massive fermionic/antifermionic spin-1/2 fields; whenever a massive fermionic particle appears in vacuum under a free field, they appear paired with an antifermion, and after generation of the pair they leave in opposite time-directions. Soon after Dirac posited this theoretical prediction of antiparticles, Carl D. Anderson experimentally verified the existence of positrons for which he was awarded the Nobel prize in the 30’s. Remark 1: One way to organize this is using the chirality operator \\(\\gamma^5 := i \\gamma^0 \\gamma^1 \\gamma^2 \\gamma^3\\) which is the volume element in the Clifford algebra. Observe that in the Dirac representation, \\(\\gamma^5\\) simply switches the first two coordinates with the last two, i.e., the fermionic solutions go the antifermionic solutions and vice versa, as \\((\\gamma^5)^2 = 1\\). The eigenspaces of \\(\\gamma^5\\) corresponding to the eigenvalues \\(\\pm 1\\) gives a chiral decomposition \\(S = S^+ \\oplus S^-\\) of the spinor representation, as discussed in Part I and II. Moreover, note \\(\\{\\gamma^5, \\gamma^\\mu\\} = 0\\), so \\(\\{\\gamma^5, \\slash \\!\\! \\partial\\} = 0\\). In particular, \\(\\slash \\!\\! \\partial\\) flips the eigenspaces of \\(\\gamma^5\\), i.e., \\(\\slash \\!\\! \\partial(S^{\\pm}) = S^{\\mp}\\). As all good stories must come to an end, so will this one, and we shall move on to the most general context in which Dirac operator can be defined, a la Atiyah-Singer. Let \\((M^n, g)\\) be an even dimensional Riemannian manifold \\(n = 2m\\) with a spinC structure. It admits a complex spinor bundle \\(S\\) of rank \\(2^m\\) with spinor representation \\(\\rho : TM \\to \\mathrm{End}_{\\Bbb C}(S)\\) as described in Part II. Let \\(\\cdot\\) denote the Clifford multiplication and \\(\\nabla\\) denot the Levi-Civita connection on \\((M, g)\\). Definition. A spin connection on \\(M\\) is a unitary connection \\(\\nabla^s\\) on \\(S\\) such that \\[\\nabla^s_X(Y \\cdot s) = (\\nabla_X Y) \\cdot s + Y \\cdot \\nabla^s_X(s)\\] A brief explanation is imperative here. Given a manifold \\(M\\), a connection \\(\\nabla\\) is a differential operator which eats two tangent vector fields \\(X, Y\\) and spits out a new tangent vector field \\(\\nabla_X Y\\) such that \\(\\nabla\\) is bilinear in either variables when taken linear combination with real constant scalars, but behaves in the following way under multiplication by scalar fields: \\(\\nabla_{f X} Y = f \\nabla_X Y\\), and \\(\\nabla_X (fY) = X(f) Y + f \\nabla_X Y\\). Therefore, such operators are global analogue of the directional derivative operator in \\(\\Bbb R^n\\). There are many choices for a connection in general, but if \\((M, g)\\) is Riemannian there is a unique such operator which satisfies (1) torsion-freeness, i.e., \\(\\nabla_X Y - \\nabla_Y X = [X, Y]\\) and (2) metric-compatibility, i.e., \\(X g(Y, Z) = g(\\nabla_X Y, Z) + g(Y, \\nabla_X Z)\\); this is called a Levi-Civita connection. The fundamental theorem of Riemannian geometry says that such a connection is uniquely determined by the metric \\(g\\); the torsion-freeness condition might seem technical and unintuitive, but turn that perspective around and think of it as the right condition that makes the existence of a “good” connection an overdetermined problem, which gives this uniqueness. An analogous story can be developed for a connection \\(\\nabla\\) on a bundle \\(E\\) over \\(M\\), which eats a pair \\((s, X)\\) consisting of a section \\(s \\in \\Gamma(M; E)\\) (or an \\(E\\)-valued field) and a tangent vector field \\(X\\) on \\(M\\) and spits out a section \\(\\nabla_X(s) \\in \\Gamma(M; E)\\) again. If \\(E\\) is a Hermitian bundle, then we can further demand an obvious metric-compatibility condition; we call such connections unitary. However, there is no analogue of the torsion-freeness condition as Lie brackets of \\(E\\)-valued fields are a nonsense concept, so there may be lots of unitary connections on a given bundle. We can measure the nonuniqueness explicitly; indeed, suppose \\(\\nabla, \\nabla'\\) are two different connections on \\(E\\). Then \\(\\nabla - \\nabla'\\) is an operator which is bilinear in both the tangent field variable and the \\(E\\)-field variable. Thus, for any tangent field \\(X\\) we can think of \\(\\nabla_X - \\nabla'_X\\) as an \\(\\mathrm{End}(E)\\)-valued \\(1\\)-form on \\(M\\), i.e., \\(\\nabla - \\nabla' \\in \\Omega^1(M; \\mathrm{End}(E))\\). This says that the space of connections \\(\\mathcal{A}_E\\) on \\(E\\) is an affine space over the vector space \\(\\Omega^1(M; \\mathrm{End}(E))\\), in the sense that there is no preferred choice of origin. In local coordinates that trivialize the vector bundle, one can thus write any connection as \\(\\nabla = d + A\\) where \\(A\\) is a matrix-valued \\(1\\)-form. Observe that the group \\(\\mathcal{G}_E := \\mathrm{Aut}(E)\\) of all self-automorphisms of the bundle (coordinate transformations of \\(E\\)-valued fields) acts on \\(\\mathcal{A}_E\\) by conjugation \\(A^g = dg A dg^{-1}\\) (coordinate transformation acts on matrices by basechange); \\(\\mathcal{G}_E\\) is called the gauge group and the space \\(\\mathcal{A}_E/\\mathcal{G}_E\\) is the moduli space of connections. This is a gigantic space; a better thing to do is to look at the moduli space of flat connections. More on this later. Footnote: In general, one can define a connection on a bundle with a specified “structure group” that is a Lie group. For example, it is \\(\\mathrm{GL}(n, \\Bbb R)\\) for a real bundle, \\(\\mathrm{GL}(n, \\Bbb C)\\) for a complex bundle, \\(\\mathrm{O}(n)\\) and \\(\\mathrm{SO}(n)\\) for a bundle with a fiberwise metric that is unoriented or oriented respectively, \\(U(n)\\) for a Hermitian bundle as above, and \\(\\mathrm{Spin}(n)\\) or \\(\\mathrm{Spin}^{\\Bbb C}(n)\\) for a bundle with a real or complex spin structure. One can phrase these things better in terms of a “principal \\(G\\)-bundle”, and there is a dictionary between such objects and vector bundles with structure group in \\(G\\). In this case the connection is a \\(\\mathfrak{g}\\)-valued object and the space of connections is an affine space over \\(\\Omega^1(M; \\mathfrak{g})\\), the space of \\(\\mathfrak{g}\\)-valued \\(1\\)-forms on \\(M\\). A quick and clean introduction to these things is outside the scope of this post (but if you’re interested feel free to ask me!), and I’ll assume much of this below. A spin connection entangles the horizontal/tangent vector fields with the vertical/spinor fields using the spinor representation of the former on the latter. Loosely speaking, the tangent vectors act on the spinors by gamma matrices, so one expects that, simply, \\(\\nabla^s_\\nu(\\gamma^\\mu \\sigma) = \\gamma^\\mu \\nabla^s_\\nu(\\sigma)\\). However, the catch here is that the gamma matrices change point-to-point since they are parametrized by the manifold, and the rate of change of \\(\\gamma^\\mu\\) in the \\(\\nu\\)-direction is exactly \\(\\Gamma^{\\kappa}_{\\mu \\nu} \\gamma^{\\kappa}\\). So, the corrected formula is \\[\\nabla^s_\\nu(\\gamma^\\mu \\sigma) =\\gamma^\\mu \\nabla^s_\\nu(\\sigma) + \\Gamma^\\kappa_{\\mu \\nu} \\gamma^{\\kappa} \\sigma\\] Here is one approach to construct the spin connection using principal bundles: the LC connection \\(\\nabla\\) on \\(TM\\) can be thought as an \\(\\mathfrak{so}(n)\\)-valued connection \\(\\omega\\) on the frame bundle of \\(M\\). Out of this, we want a \\(\\mathfrak{spin}^{\\Bbb C}(n)\\)-valued connection on the spinC-frame bundle (see Part II) \\(P\\), at which point we can take the associated bundle \\(P \\times_{\\rho_0} \\Bbb C^{2^n}\\) to recover the spinor bundle \\(S\\), and get an induced spin connection as well. To do this, observe \\(\\mathfrak{spin}^{\\Bbb C}(n) \\cong \\mathfrak{so}(n) \\oplus i\\Bbb R\\). We shall define \\(\\slash \\!\\! \\omega: M \\to \\mathfrak{spin}^{\\Bbb C}(n)\\) by defining it to be \\(\\omega\\) in the first component and something else in the other component; this something else will be an arbitrarily chosen connection \\(A\\) on a complex line bundle; so jointly we shall define \\(\\slash \\!\\! \\omega = (\\omega, A)\\). To construct such things, observe that the 2:1 map inducing isomorphism of Lie algebras \\(\\mathrm{Spin}^{\\Bbb C}(n) \\to \\mathrm{SO}(n) \\times S^1\\) is \\(\\lambda q \\mapsto (q, \\lambda^2)\\) where \\(q\\) denotes an even-degree monomial of unit norm and \\(\\lambda \\in \\Bbb C\\) is a unit-norm complex scalar. The second projection is a character \\(\\mathrm{Spin}^{\\Bbb C}(n) \\to S^1\\) given by \\(\\lambda^2\\); using this we can obtain a complex line bundle \\(\\mathcal{L}\\) out of a spinC structure as discussed in Part II. It follows from calculations in that post that then \\(w_2(M) = c_1(\\mathcal{L}) \\pmod{2}\\), so \\(c_1(\\mathcal{L})\\) is the integral cohomology class lifting \\(w_2(M)\\); we take this to be our line bundle and choose a connection \\(A\\) on \\(\\mathcal{L}\\). By construction, \\(\\tilde{\\omega} = (\\omega, A)\\) defines a well-defined \\(\\mathfrak{spin}^{\\Bbb C}(n)\\)-valued connection on the spinor bundle, and therefore a spin connection on \\(S\\). Remark 2: This story becomes much easier in dimension \\(4\\), essentially because there is a better way to understand the associated line bundle \\(\\mathcal{L}\\): it’s just \\(\\Lambda^{top} S^+\\), the determinant line bundle of the spinors of positive chirality. The reason that this is specific to dimension \\(4\\) is the simple but extremely amusing fact that \\(n = 2^{n/2}\\) for some \\(n &gt; 2\\) (think of one side as the number of spacetime coordinates and the other side as the number of spinor coordinates) iff \\(n = 4\\). I will explain this detail in an upcoming follow-up. Remark 3: What this shows is that given a spinor bundle \\(S\\) on a Riemannian manifold \\((M, g)\\), the spin connection \\(\\nabla^s\\) depends on a choice of a connection \\(A\\) on the associated complex line bundle \\(\\mathcal{L}\\) given by only thinking about the complex scalar spinors. This will be important later on as we discuss the Seiberg-Witten equations. Nevertheless, now that we have a spinor bundle with a spin connection, we can write the Dirac operator, which is exactly the same expression as before, except we now use the spin connection and not the usual partial derivative: Definition. In a local orthonormal frame \\((\\mathbf{e}^1, \\cdots, \\mathbf{e}^n)\\) the Dirac operator is defined by \\[\\slash \\!\\! \\partial_A = \\gamma^\\mu \\nabla^s_\\mu : \\Gamma(M; S) \\to \\Gamma(M; S)\\] where \\(\\gamma^\\mu = \\rho(\\mathbf{e}^\\mu)\\) are images of the vectors under the spinor representation. There’s a more coordinate-free way to say it: \\(\\slash \\!\\! \\partial_A\\) is the composition of \\[\\nabla^s : \\Gamma(M; S) \\to \\Gamma(M; S \\otimes T^*M)\\] followed by the isomorphism (Legendre transform) \\[\\Gamma(M; S \\otimes T^*M) \\to \\Gamma(M; S \\otimes TM)\\] given by the Riemannian metric, further followed by the map \\[\\Gamma(M; S \\otimes TM) \\to \\Gamma(M; S)\\] given by the pointwise Clifford multiplication. It’s easy to see that the above expression is what this evaluates to in coordinates. Observe that by following the same argument as Remark 1, with the volume form as the chirality operator, we obtain \\(\\slash \\!\\! \\partial_A\\) flips the decomposition \\(S = S^+ \\oplus S^-\\) in the sense that \\(\\slash \\!\\! \\partial_A(S^\\pm) = S^\\mp\\). We denote \\(\\slash \\!\\! \\partial_A^+ : \\Gamma(M; S^+) \\to \\Gamma(M; S^-)\\) and \\(\\slash \\!\\! \\partial_A^- : \\Gamma(M; S^-) \\to \\Gamma(M; S^+)\\) to be the restrictions of \\(\\slash \\!\\! \\partial_A\\) to the positive and negative chirality spinors. We will show that \\(\\slash \\!\\! \\partial_A\\) is formally self-adjoint, equivalently, \\(\\slash \\!\\! \\partial_A^+\\) is formally adjoint to \\(\\slash \\!\\! \\partial_A^-\\). Suppose \\(\\sigma_1, \\sigma_2 \\in \\Gamma_{supp}(M; S)\\) be a pair of compactly supported sections of \\(S\\). Observe, \\[\\displaystyle \\begin{aligned}\\langle \\slash \\!\\! \\partial_A \\sigma_1, \\sigma_2 \\rangle &amp;= \\langle \\gamma^\\mu \\nabla^s_\\mu \\sigma_1, \\sigma_2 \\rangle \\\\ &amp;= \\langle \\nabla^s_\\mu \\sigma_1, \\gamma^\\mu \\sigma_2 \\rangle \\\\ &amp;= -\\langle \\nabla^s_\\mu \\sigma_1, \\gamma^\\mu \\sigma_2 \\rangle \\\\ &amp;= - \\partial_\\mu \\langle \\sigma_1, \\gamma^\\mu \\sigma_2 \\rangle - \\langle \\sigma_1, \\sigma_2 \\nabla^s_\\mu \\gamma^\\mu \\rangle + \\langle \\sigma_1, \\slash \\!\\! \\partial_\\mu \\sigma_2 \\rangle \\end{aligned}\\] Next, define a vector field \\(X\\) so that \\(g(X, Y) = -\\langle \\sigma_1, \\sigma_2 Y \\rangle\\) for all \\(Y\\). We compute the divergence: \\[\\displaystyle \\begin{aligned}\\mathrm{div}(X) = -\\langle \\nabla^s_\\mu X, \\gamma^\\mu \\rangle &amp;= -\\partial_\\mu \\langle X, \\gamma^\\mu \\rangle - \\langle X, \\nabla^s_\\mu \\gamma^\\mu \\rangle \\\\ &amp;= - \\partial_\\mu \\langle \\sigma_1, \\sigma_2 \\gamma^\\mu \\rangle - \\langle \\sigma_1, \\sigma_2 \\nabla^s_\\mu \\gamma^\\mu \\rangle \\end{aligned}\\] Combining, this shows \\(\\langle \\slash \\!\\! \\partial_A \\sigma_1, \\sigma_2 \\rangle = \\mathrm{div}(X) + \\langle \\sigma_1, \\slash \\!\\! \\partial_A \\sigma_2 \\rangle\\). Integrating both sides over \\(M\\) and using divergence theorem, we obtain \\(\\slash \\!\\! \\partial_A\\) is self-adjoint with respect to the standard Hermitian inner product on compactly supported smooth sections of \\(S\\). In the relativistic, flat spacetime, we had \\(\\slash \\!\\! \\partial^2 = \\Box\\) is the d’Alembertian. In the nonrelativistic flat case we get \\(\\slash \\!\\! \\partial^2 = \\Delta\\) where the Laplacian \\(\\Delta = - \\partial_{\\mu \\mu}^2\\) has an unfortunate negative sign in front of it because of my sign conventions. If spacetime has curvature, we choose coordinates such that \\(\\nabla^s_\\mu \\gamma^\\nu(0) = 0\\) and compute: \\[\\displaystyle \\begin{aligned} \\slash \\!\\! \\partial^2 = \\gamma^\\mu \\nabla^s_\\mu (\\gamma^\\nu \\nabla^s_\\nu) &amp;= \\gamma^\\mu \\gamma^\\nu \\nabla^s_\\mu \\nabla^s_\\nu \\\\ &amp;= - (\\nabla^s_\\mu)^2 + \\frac12 \\gamma^\\mu \\gamma^\\nu F_{\\mu \\nu}\\end{aligned}\\] Where \\(F_{\\mu \\nu} = [\\nabla^s_\\mu, \\nabla^s_\\nu]\\) is the curvature operator for the spin connection, and the first term is exactly the Laplacian. The connection \\(1\\)-form associated to the spin bundle is valued in \\(\\mathfrak{spin}^{\\Bbb C}(n) \\cong \\mathfrak{so}(n) \\oplus i \\Bbb R\\), so \\(\\slash \\!\\! \\omega = \\omega + A\\), which means \\(F = R + F^A\\) where \\(R\\) is the Riemann curvature tensor of \\((M, g)\\) and \\(F^A\\) is the curvature of the associated complex line bundle. Remembering \\(\\mathfrak{so}(n) \\subset \\mathfrak{spin}^{\\Bbb C}(n)\\) is spanned by \\(1/2 \\gamma^{\\mu}\\gamma^{\\nu}\\), we compute: \\[\\displaystyle \\gamma^\\mu \\gamma^\\nu R_{\\mu \\nu} = \\frac14 R_{\\mu \\nu \\sigma \\rho} \\gamma^\\mu \\gamma^\\nu \\gamma^\\sigma \\gamma^\\rho\\] We fix \\(\\rho\\) and sum over the rest of the indices first. The terms where \\(\\mu, \\nu, \\sigma\\) add up to \\(0\\) by Bianchi’s identity, so the result is \\(R_{\\mu \\nu \\mu \\rho} \\gamma^\\nu \\gamma^\\rho\\), and the terms where \\(\\nu, \\rho\\) are distinct also sum up in pairs and cancel, leaving \\(2 R_{\\mu \\nu \\mu \\nu} (\\gamma^\\nu)^2 = -2 R_{\\mu \\nu \\mu \\nu} = 2\\ \\mathrm{scal}\\). This gives \\[\\displaystyle \\frac12 \\gamma^\\mu \\gamma^\\nu R_{\\mu \\nu} = \\frac12 \\cdot \\frac14 \\cdot 2 \\ \\mathrm{scal} = \\frac{\\mathrm{scal}}{4}\\] Combining everything, we obtain the Weitzenböck formula: \\[\\displaystyle \\slash \\!\\! \\partial^2 \\psi = \\Delta \\psi + \\frac{\\mathrm{scal}}{4} \\psi + \\frac{F^A}{2} \\cdot \\psi\\] where \\(F^A \\cdot \\psi = 1/2 F^A_{\\mu \\nu} \\gamma^\\mu \\gamma^\\nu \\psi\\) is the curvature of the line bundle acting by Clifford multiplication on spinor fields. This concludes the basic discussion for the Dirac operator. Up next, we specialize to the case of dimension 4 and introduce the Seiberg-Witten equations.",
      "categories": [],
      "tags": ["clifford-algebras","spin-geometry","index-theory"]
    },
  
    {
      "title": "Seiberg-Witten Theory: II",
      "url": "/2021/12/27/sw-theory-ii/",
      "date": "2021-12-27",
      "content": "Recall from the last paragraph of Part I that we wished to carry out all of the linear algebra but now parametrized over a manifold \\(M\\). Let us try to naively carry out the procedure, and in the process we will encounter the issue: let \\((M, g)\\) be a Riemannian \\(n\\)-manifold where \\(n = 2m\\) is even. The Riemannian metric \\(g\\) is a smoothly-varying inner product on each tangent space \\(T_p M\\), \\(p \\in M\\) which assemble to the tangent bundle \\(TM\\), so one can take the Clifford algebra \\(\\mathrm{Cliff}(T_p M, g_p)\\) for each \\(p \\in M\\) and assemble these to a “Clifford algebra bundle” \\(\\mathrm{Cliff}(M) := \\mathrm{Cliff}(TM, g)\\). One can try to construct a fiberwise complex spinor representation, which would be a bundle \\(S\\) over \\(M\\) such that for each \\(p \\in M\\), \\(S_p\\) is the complex spinor representation of \\(\\mathrm{Cliff}(T_pM, g_p)\\); this we know how to construct, simply look at the complexification \\(T_p^{\\Bbb C} M := T_p M \\otimes \\Bbb C\\) with the complexified inner product \\(g^{\\Bbb C}_p := g_p \\otimes \\Bbb C\\) (which is a symmetric bilinear form, not a Hermitian inner product), take \\(\\mathrm{Cliff}^{\\Bbb C}(T_p M, g_p) := \\mathrm{Cliff}(T_p^{\\Bbb C} M, g^{\\Bbb C}_p)\\) the complex Clifford algebra (which is in fact the complexification of the real Clifford algebra as described before in Part I) which assemble to the complex Clifford bundle \\(\\mathrm{Cliff}^{\\Bbb C}(M)\\), look at its action on the exterior algebra over the maximal totally isotropic subspace (or “Lagrangian subspace” in symplectic geometry terminology) of \\(T_p^{\\Bbb C} M\\) as described previously, and that’s exactly \\(S_p\\). Assemble these up and we are done… Except, to construct the maximal isotropic, we needed an extra piece of data, a choice of an orthogonal almost-complex structure or a transformation \\(J_p : T_p M \\to T_p M\\) such that \\(J_p^2 = -I\\) and \\(J_p\\) is an isometry with respect to \\(g_p\\); the eigenspace corresponding to the eigenvalue \\(i\\) of \\(J_p\\) on \\(T_p^{\\Bbb C} M\\) is the maximal isotropic. This extra piece of data is not just a random choice that we can make; to assemble everything to a bundle at the end, we need a smoothly varying family of almost-complex structures on each tangent space of \\(M\\), i.e., a metric-compatible, fiberwise almost complex structure \\(J : TM \\to TM\\), \\(J^2 = -I\\). Existence of such a thing is not automatic, in fact they do not always exist. Kahler manifolds (eg, smooth zero loci of homogeneous equations treated as subsets of \\(\\Bbb{CP}^n\\)) are examples of such things, in fact they are exactly the ones for which this \\(J\\) is integrable in the sense that it gives rise to complex coordinate charts on the manifold; integrability is a closed condition \\(J\\) (the Nijenhuis tensor vanishes) so certainly Kahler manifolds are a rarer class than we are looking for. So what exactly are the Riemannian manifolds \\((M, g)\\) which admit an orthogonal almost-complex structure? Define \\(\\omega(X, Y) = g(X, JY)\\) and observe that \\(\\omega\\) is a \\(2\\)-form on \\(M\\), and moreover \\(\\omega^m := \\omega \\wedge \\cdots \\wedge \\omega\\) is a nowhere vanishing volume form on \\(M\\). Thus, \\(\\omega\\) is an almost-symplectic structure, the difference from an actual symplectic structure being again an integrability condition: \\(d\\omega = 0\\) or closedness of \\(\\omega\\). On the other hand if \\(M\\) was an almost-symplectic manifold, the form \\(\\omega\\) assumed to have no apriori compatibility with \\(g\\), one could have constructed an orthogonal almost-complex structure by the polar decomposition formula: \\(J = (\\Omega^{\\mathsf{T}} \\Omega)^{-1/2}\\Omega\\) where \\(\\Omega\\) denotes the matrix of the bilinear form \\(\\omega\\) with respect to some \\(g\\)-orthonormal basis; these are the so-called \\(\\omega\\)-compatible almost complex structures (particularly relevant when \\(\\omega\\) is symplectic, in the theory of pseudoholomorphic curves). In any case, we see that the class of manifolds we are interested in is larger, even, than symplectic manifolds. Nonetheless, they are not abundant. The only spheres which admit an almost-complex structures are \\(S^2\\) and \\(S^6\\). Indeed, suppose \\(TS^{2n}\\) admits an almost complex structure \\(J\\). Then \\(J \\otimes \\Bbb C\\) gives an eigendecomposition of complex vector bundles \\(T^{\\Bbb C} S^{2n} = E \\oplus \\overline{E}\\) where \\(E = TS^{2n}\\) with the complex structure \\(J\\), and \\(\\overline{E}\\) is the conjugate. We compute the Chern class \\(c_n\\) of either side; note that \\(c_n(T^{\\Bbb C} S^{2n}) = 0\\) by complex stable triviality of the complexified tangent bundle of the sphere, and \\(c_n(E \\oplus \\overline{E}) = c_n(E) + c_n(\\overline{E})\\). If \\(n\\) was even, this would be \\(2c_n(E) = 2\\chi(S^{2n})[S^{2n}] = 4[S^{2n}]\\), which gives the required contradiction. Note that the argument here is really a Pontryagin class argument, \\(p_k(S^{4k}) = c_{2k}(T^{\\Bbb C} S^{4k})\\). Indeed, if \\(k = 1\\), then \\(p_1(S^4) = 0\\) can be seen geometrically, since by Chern-Weil theory \\(p_1(M) = 1/(8\\pi^2) \\int_M \\mathrm{tr}(\\Omega^2)\\) where \\(\\Omega\\) is the curvature \\(2\\)-form of some chosen Riemannian metric on \\(M\\). If \\(M\\), like the sphere, admits a metric of constant curvature \\(K\\), then \\(\\Omega_{ij} = K d\\omega^i \\wedge d\\omega^j\\) which implies \\(\\Omega^2\\) has no diagonal terms and so the \\(1\\)st Pontryagin form itself is zero. In the case \\(n\\) is odd, the above procedure gives no contradiction as \\(c_n(\\overline{E}) = -c_n(E)\\); we can instead argue by Chern classes modulo \\(p\\) for some odd prime \\(p\\): from here, we see if \\(n - p + 1 &gt; 0\\), the universal Chern classes modulo \\(p\\), \\(c_n \\pmod{p}\\) can be written as a polynomial in \\(c_1 \\pmod{p}, \\cdots, c_{n-1} \\pmod{p}\\) and the first Steenrod power \\(P^1(c_{n-p+1} \\pmod{p})\\). Specializing to \\(TS^{2n}\\) we get that since \\(c_i = 0\\) for all \\(i &lt; n\\), \\(c_n(TS^{2n}) = 2[S^{2n}] \\pmod{p} = 0\\), which would be a contradiction. For this, we require an odd prime \\(p\\) such that \\(p &lt; n - 1\\), that is, \\(n &gt; 4\\). This leaves the cases \\(n = 1, 2, 3, 4\\) and \\(n = 2, 4\\) are eliminated by the earlier argument with the Pontryagin class. Thus, \\(n = 1, 3\\) are the only possibilities and these in fact do admit almost complex structure; whether \\(S^6\\) admits an integrable almost complex structure is still an open problem. Here’s the punchline. You do not actually need an almost complex structure to get a spinor bundle, all you need is a much weaker spinc structure. My understanding is that the story of spin geometry begins with trying to “soften” almost complex geometry; almost complex structures are rare, so we would like to enlarge the tangent bundle to the “spinor bundle” where almost complex structures are abundant. Let’s organize what we did in Part I from this viewpoint; given a real inner product space \\((V, \\langle \\cdot, \\cdot \\rangle)\\), we are interested in studying Clifford modules \\(W\\) over \\(V\\) which is a Hermitian inner product space \\(W\\) on which \\(V\\) acts in a way that each unit vector \\(v \\in V\\) acts by an almost complex structure \\(J_v : W \\to W\\), i.e., \\(J_v^2 = -I\\) and for any pair \\(u, v \\in V\\) of unit vectors, \\(J_u J_v = -J_v J_u\\). That is to say, \\(W\\) is an enlargement of \\(V\\) which admit the unit sphere in \\(V\\)’s worth of almost-complex structures which are all compatible (i.e., for any pair of unit vectors \\(u, v\\), the complex structures \\(I, J_u, J_v, J_u J_v\\) form a linear almost-hyperKahler structure on \\(W\\)). The subalgebra of \\(\\mathrm{End}(W)\\) generated by \\(\\{J_v : v \\in V, \\|v\\| = 1\\}\\) is the (actual, physically perceivable) Clifford algebra \\(\\mathrm{Cliff}(V) \\subset \\mathrm{End}(W)\\); one simply identifies \\(v\\) with \\(J_v\\) and composition of operators is the Clifford product, so \\(V\\) sits inside its Clifford algebra as the degree \\(1\\) elements. Next, observe that the axioms of the Clifford algebra implies for any pair of orthogonal unit vectors \\(u, v\\in V\\), \\(-vuv^{-1} = u\\) unless \\(u = \\pm v\\) in which case \\(-vuv^{-1} = -u\\). Define \\[\\begin{gather*}\\mathrm{ad} : \\mathrm{Cliff}(V)^\\times \\to \\mathrm{End}(\\mathrm{Cliff}(V)),\\\\ \\mathrm{ad}_\\alpha(u) = -\\alpha u \\alpha^{-1}\\end{gather*}\\] Observe that \\(\\mathrm{ad}_v(V) \\subset V\\) if \\(v\\) is a degree \\(1\\) element by our observation before. In fact, we get also from our observation that if \\(\\|v\\| = 1\\) then \\(\\mathrm{ad}_v\\) is reflection along the hyperplane \\(\\langle v \\rangle^\\perp\\). Thus, define, \\[\\displaystyle \\begin{align*}\\mathrm{Pin}(V) &amp;= \\{v_1 \\cdots v_k \\in \\mathrm{Cliff}(V) : v_i \\in V, \\|v_i\\| = 1\\} \\\\ \\mathrm{Spin}(V) &amp;= \\mathrm{Pin}(V) \\cap \\mathrm{Cliff}^+(V)\\end{align*}\\] These are both subgroups of \\(\\mathrm{Cliff}(V)^\\times\\), and the adjoint representation restricts to homomorphisms (caveat: this doesn’t quite work, but the lie will be explained below) \\(\\mathrm{ad} : \\mathrm{Pin}(V) \\to \\mathrm{O}(V)\\) and \\(\\mathrm{ad} : \\mathrm{Spin}(V) \\to \\mathrm{SO}(V)\\) (here we are using that every orthogonal transformation is a product of reflections) which are \\(2:1\\) because \\(\\langle v \\rangle^\\perp = \\langle -v\\rangle^\\perp\\) so the reflections \\(\\mathrm{ad}_v\\) and \\(\\mathrm{ad}_{-v}\\) are the same. In fact they are both covering maps, and \\(\\mathrm{ad} : \\mathrm{Spin}(V) \\to \\mathrm{SO}(V)\\) is the universal cover. There is an alternative description of these groups: consider the involution \\(*\\) on \\(\\mathrm{Cliff}(V)\\) which acts on degree \\(1\\) elements by \\(v^* := -\\overline{v}\\) and extending to monomials by reversing order: \\((v_1 \\cdots v_k)^* = v_k^* \\cdots v_1^*\\). The spinor norm is defined by \\(\\\\|x\\\\| = x^* x\\); observe on degree \\(1\\) elements this coincides with the norm coming from the inner product, and \\(\\\\|xy\\\\| = \\\\|x\\\\| \\\\|y\\\\|\\) follows from the definition. Thus, products of unit norm elements of \\(V\\) is contained in the unit sphere of \\(\\mathrm{Cliff}(V)\\) under this norm, hence so is \\(\\mathrm{Pin}(V)\\). But it is possible to have non-monomial elements in the unit sphere as well; to eliminate these we need the extra condition that \\(x^* V x = V\\). Indeed, then \\(\\mathrm{ad}_x \\in \\mathrm{O}(V)\\) hence \\(x \\in \\mathrm{Pin}(V)\\) is forced. Therefore, \\[\\displaystyle \\mathrm{Pin}(V) = \\{x \\in \\mathrm{Cliff}(V) : \\\\|x\\\\| = 1, x^* V x = V\\}\\] and \\(\\mathrm{Spin}(V) = \\mathrm{Pin}(V) \\cap \\mathrm{Cliff}^+(V)\\) as before. Now we are in a position to explain the lie in the definition of the double cover \\(\\mathrm{Pin}(V) \\to \\mathrm{O}(V)\\) above; the adjoint action \\(\\mathrm{ad}_x(u) = -xux^*\\) is not a homomorphism in \\(x\\) from the full pin group. Indeed, \\(\\mathrm{ad}_x \\circ \\mathrm{ad}_{x'} = -\\mathrm{ad}_{xx'}\\); one has to correct for signs here, one of the many woes of working in a superalgebra. One way to do it is to taint an element with negative sign in odd degrees and positive sign in even degrees. Then \\(\\mathrm{ad}_x(v) := (-1)^{\\|x\\|} x v x^*\\) works perfectly fine and agrees with the usual adjoint on the spin group, where sign is a non-issue as it lives in even degrees. So far all we have talked about is the real Clifford algebra. The complex Clifford algebra is just obtained from tensoring everything up with \\(\\otimes_{\\Bbb R} \\Bbb C\\); the last definition of the pin group goes through in this setup provided we complexify \\(*\\) correctly: define \\(v^* = -\\overline{v}\\) in degree \\(1\\) instead; note that the conjugation only affects the scalars that hang around because of extending scalars to \\(\\Bbb C\\) in the definition of the complex Clifford algebra, not the vectors themselves (remember the inner product on \\(V \\otimes \\Bbb C\\) is still a symmetric bilinear form, not a Hermitian one). We call the resulting groups \\(\\mathrm{Pin}^{\\Bbb C}(V)\\) and \\(\\mathrm{Spin}^{\\Bbb C}(V)\\). Explicity, \\[\\displaystyle \\begin{align*}\\mathrm{Pin}^{\\Bbb C}(V) &amp;= \\{e^{i\\theta} x \\in \\mathrm{Cliff}^{\\Bbb C}(V) : x \\in \\mathrm{Pin}(V)\\} \\\\ \\mathrm{Spin}^{\\Bbb C}(V) &amp;= \\{e^{i\\theta} x \\in \\mathrm{Cliff}^{\\Bbb C}(V) : x \\in \\mathrm{Spin}(V)\\}\\end{align*}\\] This time \\(\\mathrm{ad} : \\mathrm{Pin}^{\\Bbb C}(V) \\to \\mathrm{O}(V)\\) and \\(\\mathrm{ad} : \\mathrm{Spin}^{\\Bbb C}(V) \\to \\mathrm{SO}(V)\\) have kernel \\(S^1 \\cong U(1)\\). From the concrete description of the spin group above, we see \\(\\mathrm{Spin}^{\\Bbb C}(V)\\) is almost \\(U(1) \\times \\mathrm{Spin}(V)\\), except \\(\\pm 1\\) can appear in either factor, which leads to a \\(\\Bbb Z/2\\)-ambiguity. Thus, \\(\\mathrm{Spin}^{\\Bbb C}(V) \\cong U(1) \\times_{\\Bbb Z/2} \\mathrm{Spin}(V)\\). As a consequence, \\(\\mathrm{Spin}^{\\Bbb C}(V)\\) can also be thought as a double cover of \\(U(1) \\times \\mathrm{SO}(V)\\). The real usage of complexifying everything up is that the representation theory of \\(\\mathrm{Cliff}^{\\Bbb C}(V)\\) is simpler than that of \\(\\mathrm{Cliff}(V)\\). This is not strictly speaking relevant to us, but just to explain that comment I will go into a very brief detour: our focus has so far been on even-dimensional \\(V\\) but more or less everything discussed above goes through in odd-dimensions as well (however, \\(\\mathrm{Cliff}^{\\Bbb C}(V)\\) for odd dimensional \\(V\\) has two irreducible representations). Then for every \\(n\\) we have the Clifford algebras \\(\\mathrm{Cliff}(n)\\) (what we called \\(\\mathrm{Cliff}_{n, 0}\\) in Part I) and \\(\\mathrm{Cliff}^{\\Bbb C}(n)\\). But as it happens, there is a periodicity in the structure of these algebras: the complex Clifford algebras are \\(2\\)-periodic in the sense that \\(\\mathrm{Cliff}^{\\Bbb C}(n+2) = M_2(\\mathrm{Cliff}^{\\Bbb C}(n))\\) whereas the real Clifford algebras happen to be \\(8\\)-periodic, i.e., \\(\\mathrm{Cliff}(n+8) = M_{16}(\\mathrm{Cliff}(n))\\). \\(\\mathrm{Cliff}^{\\Bbb C}(n)\\) is always either a matrix algebra (on its unique complex spinor representation) or a product of two matrix algebras (in case \\(n\\) is odd). But \\(\\mathrm{Cliff}(n)\\) form the complicated Bott tower: the first eight algebras starting from \\(n = 0\\) are \\[\\displaystyle \\Bbb R, \\Bbb C, \\Bbb H, \\Bbb H \\oplus \\Bbb H, M_2(\\Bbb H), M_4(\\Bbb C), M_8(\\Bbb R), M_8(\\Bbb R) \\oplus M_8(\\Bbb R)\\] One should conceptualize this as a linear version of the topological Bott periodicty, one of many ways of stating which is that the homotopy groups of \\(O(\\infty)\\) are \\(8\\)-periodic. Let me mention a modest, but illuminating example. \\(\\mathrm{Cliff}(3)\\) is generated by \\(e_1, e_2, e_3\\), the full graded algebra breaks into four parts \\(\\mathrm{Cliff}_0 \\oplus \\mathrm{Cliff}_1 \\oplus \\mathrm{Cliff}_2 \\oplus \\mathrm{Cliff}_3\\) indexed by degree. The degree \\(2\\) part is generated by \\(e_1 e_2, e_2 e_3, e_3 e_1\\) which can be sent to the quaternions \\(i, j, k\\); hence, there is an embedding \\(\\Bbb H \\cong \\mathrm{Cliff}(2) \\hookrightarrow \\mathrm{Cliff}(3)\\) as the degree \\(2\\) elements (more generally, \\(\\mathrm{Cliff}(n-1)\\) embeds in \\(\\mathrm{Cliff}(n)\\) as the degree \\(n-1\\) elements). The degree \\(0\\) and \\(3\\) parts are both \\(1\\)-dimensional, the latter generated by \\(e_1 e_2 e_3\\). The \\(\\mathrm{Spin}(3)\\) group lives inside the even degree part which is \\(\\mathrm{Cliff}_0 \\oplus \\mathrm{Cliff}_2 = \\Bbb R \\oplus i \\Bbb H = \\Bbb H\\), consisting of all the elements of unit norm, i.e., \\(\\mathrm{Spin}(3) \\cong S^3 \\cong \\mathrm{SU}(2)\\). It is a classical fact that conjugation by a quaternion are rotations in the \\(i\\Bbb H\\) factor, so this gives \\[\\mathrm{ad} : \\mathrm{Spin}(3) \\cong \\mathrm{SU}(2) \\to \\mathrm{SO}(3)\\] It is tempting to try to figure out \\(\\mathrm{Spin}(4)\\) as well. From the Bott tower above we can see \\[\\mathrm{Cliff}(4) \\cong \\Bbb H \\oplus \\Bbb H\\] This is in fact a \\(*\\)-algebra isomorphism. The unit sphere then is \\(\\mathrm{SU}(2) \\times \\mathrm{SU}(2)\\). So, we have \\[\\mathrm{Spin}(4) \\subseteq \\mathrm{SU}(2) \\times \\mathrm{SU}(2)\\] The equality holds as there is a \\(2 : 1\\) map \\(\\mathrm{SU}(2) \\times \\mathrm{SU}(2) \\to \\mathrm{SO}(4)\\) given by \\((q_1, q_2) \\mapsto (u \\mapsto q_1 u \\overline{q_2})\\), and the kernel is \\(\\Bbb Z/2 \\cong \\{(1, 1), (-1, -1)\\}\\). I haven’t quite worked out the details of how it fits together with the linear algebra of \\(\\mathrm{Cliff}(4)\\), though. The final piece of linear algebra that I want to discuss in this post is about how the complex Clifford algebra, the complex spinor representation and the spin group are tied together. First, observe (say, using Schur’s lemma) that \\(\\mathrm{End}_{\\Bbb C}(S) \\cong \\mathrm{Cliff}^{\\Bbb C}(V)\\), so the Clifford algebra is completely recovered from the complex spinor representation. Next, consider the spinc automorphisms of \\(S\\), i.e., a pair of transformations \\(A : V \\to V\\) and \\(T : S \\to S\\) such that \\(A\\) is orthogonal and \\(T\\) is unitary, such that \\(T \\circ \\rho \\circ T^{-1} = \\rho \\circ A\\) where \\(\\rho : V \\to \\mathrm{End}(S)\\) is the (reified, i.e., in degree \\(1\\)) Clifford representation. Then we claim \\(\\mathrm{Aut}_{\\mathrm{Spin}^{\\Bbb C}}(S) \\cong \\mathrm{Spin}^{\\Bbb C}(V)\\), so that the spin group is also recoverable from the complex spinor representation. Indeed, \\(T \\in \\mathrm{End}(S) \\cong \\mathrm{Cliff}^{\\Bbb C}(V)\\) hence \\(T = \\rho(x)\\) for some \\(x \\in \\mathrm{Cliff}^{\\Bbb C}(V)\\). Unitarity of \\(T\\) implies \\(\\\\|x\\\\| = 1\\); moreover the condition implies \\(\\rho(x^* v x) = \\rho(A v)\\) for all \\(v \\in V\\). But \\(\\rho : \\mathrm{Cliff}(V) \\to \\mathrm{End}(S)\\) is an isomorphism so \\(x^*vx = Av\\). Therefore, \\(\\mathrm{ad}_x(V) = V\\), but also \\(\\mathrm{ad}_x\\) is an orientation-preserving transformation of \\(V\\). This implies \\(x\\) is in fact even, and so \\(x \\in \\mathrm{Spin}^{\\Bbb C}(V)\\), which proves the claim. Finally, the complex spinor representation itself can be restricted to the group \\(\\mathrm{Spin}^{\\Bbb C}(V) \\subset \\mathrm{Cliff}^{\\Bbb C}(V)\\) from the full Clifford algebra, which gives a representation, also called the complex spinor representation, \\(\\mathrm{Spin}^{\\Bbb C}(V) \\to \\mathrm{End}(S)\\). Recall in the case \\(\\dim V\\) was even, we had defined a splitting \\(S = S^+ \\oplus S^-\\) into the eigenspaces of the volume form on \\(V\\) and degree \\(1\\) elements acted on the decomposition by switching \\(S^+, S^-\\). As \\(\\mathrm{Spin}^{\\Bbb C}(V)\\) consists only even elements, we obtain that the representation over the spin group splits as \\(S^+ \\oplus S^-\\); it is a fact that \\(S^{\\pm}\\) are irreducible representations of \\(\\mathrm{Spin}^{\\Bbb C}(V)\\). Here is how all of this ties the topological setup that was being discussed in the first couple of paragraphs in the beginning of the post. Suppose that \\(S\\) is a spinor bundle over a Riemannian manifold \\((M, g)\\) of dimension \\(n = 2m\\). Consider the model spinc structure \\(\\rho_0 : \\Bbb R^n \\to \\mathrm{End}(\\Bbb C^{2^m})\\) that was discussed in Part I. Then define a principal \\(\\mathrm{Spin}^{\\Bbb C}(n)\\)-bundle \\(P_\\rho \\to M\\) whose fiber over \\(p \\in M\\) consists of all the spinc isomorphisms between \\(\\rho_0\\) and \\(\\rho_p : T_p M \\to \\mathrm{End}(S_x)\\); that is: \\[\\displaystyle P_\\rho = \\{(p, A, T) : A \\in \\mathrm{Isom}(\\Bbb R^n, S_p), T \\in \\mathrm{Isom}(\\Bbb C^{2^m}, S), T \\circ \\rho_0 \\circ T^{-1} = \\rho \\circ A\\}\\] with \\(\\mathrm{Spin}^{\\Bbb C}(n)\\) acting by \\(\\alpha \\cdot (p, A, T) = (p, A \\circ \\mathrm{ad}_\\alpha, T \\circ \\rho_0(\\alpha))\\). If we forget the factor of \\(T\\) then this is simply the orthonormal frame bundle \\(\\mathrm{Fr}(M) \\to M\\), fiber of a generic point \\(p\\) of which is simply the space of all possible frames of \\(T_p M\\), and \\(\\mathrm{Spin}^{\\Bbb C}(n)\\) acts non-effectively by the projection \\(\\mathrm{Spin}^{\\Bbb C}(n) \\to \\mathrm{SO}(n)\\) to the group of orthogonal transformations, which simply permute the frames around over any given point. Remembering the spinor representation in the definition has the effect that the “spin” (whatever that is, more on this below) of the framing is remembered. In fact, consider \\(P_\\rho \\times_{\\mathrm{ad}} \\mathrm{SO}(n) = (P \\times \\mathrm{SO}(n))/\\mathrm{Spin}^{\\Bbb C}(n)\\) where \\(\\mathrm{Spin}^{\\Bbb C}(n)\\) acts diagonally, on \\(P\\) by permuting the spin framings and on \\(\\Bbb R^n\\) by \\(\\mathrm{ad}\\). Then it is clear that \\(P_\\rho \\times_{\\mathrm{ad}} \\mathrm{SO}(n) \\cong \\mathrm{Fr}(M)\\), as one is collapsing down the \\(T\\) factor (“spin”) wherever they record more information than the \\(A\\) factor (“frames”), so one just ends up with the frames. This is an incredibly concise way of putting the idea of spinor bundles, and it is clear with a little though that one can go the other way as well; if there was a \\(\\mathrm{Spin}^{\\Bbb C}(n)\\)-equivariant map \\(P \\to \\mathrm{Fr}(M)\\) from some principal \\(\\mathrm{Spin}^{\\Bbb C}(n)\\)-bundle to the frame bundle, one could take \\(P \\times_{\\rho_0} \\Bbb{C}^{2^m}\\) to get back the spinor representation, where \\(\\rho_0 : \\mathrm{Spin}^{\\Bbb C}(n) \\to M_{2^m}(\\Bbb C)\\) is the restriction of the model spinor representation to the spinc subgroup. All of this goes through likewise for real spinor representations as well, and parity of dimension of \\(M\\) is a mere convenience. Definition. A spinc structure on an oriented Riemannian manifold \\((M^n, g)\\) is a principal \\(\\mathrm{Spin}^{\\Bbb C}(n)\\)-bundle \\(P \\to M\\) such that \\(P \\times_{\\mathrm{ad}} \\mathrm{SO}(n) \\cong \\mathrm{Fr}(M)\\). Likewise, a spin structure is a principal \\(\\mathrm{Spin}(n)\\)-bundle \\(P \\to M\\) such that \\(P \\times_{\\mathrm{ad}} \\mathrm{SO}(n) \\cong \\mathrm{Fr}(M)\\). We have proved that admitting a (complex) spinor representation is equivalent to admitting a spinc structure. I will demonstrate that this is far, far more flexible a condition than admitting an almost complex structure, but before that I would like to present some pictures which puts it in an intuitive and handwavy way; after all, for much of the time we have been doing abstract linear algebra and it might seem at first that spin structures emerge out of playing such algebraic games. I would like to argue, on the contrary, that it “actually exists” and something whose presence “can be felt”. Let me discuss the real spin structure. Recall \\(\\mathrm{Spin}(n)\\) is the universal double cover of \\(\\mathrm{SO}(n)\\). For any nice topological group \\(G\\) the universal cover can be written as follows: \\[\\widetilde{G} = \\{\\gamma \\in \\mathrm{Maps}([0, 1], G) : \\gamma(0) = e\\}/\\sim\\] where \\(\\sim\\) denotes homotopy relative to the basepoint \\(0\\). The covering projection \\(\\widetilde{G} \\to G\\) is \\(\\gamma \\mapsto \\gamma(1)\\). Now, there is a group structure on \\(\\widetilde{G}\\) which is given by \\((\\alpha \\beta)(t) = \\alpha(t) \\beta(t)\\) and this is the one which lifts the group structure on \\(G\\). However, it is equivalent to the group structure given by \\(\\alpha * (\\alpha(1)\\beta)\\) where \\(*\\) denotes path concatenation, as can be seen by hand. Specialize to the case \\(G = \\mathrm{SO}(n)\\), which tells you elements of \\(\\mathrm{Spin}(n)\\) are paths in \\(\\mathrm{SO}(n)\\) starting at the identity, with multiplication of two such paths given by translating the initial point to the endpoint of the other, and then concatenating. To visualize this with \\(n = 3\\), consider the following artifice. Consider a sphere \\(S^2 \\subset \\Bbb R^3\\) with an infinite strip (or a framed, proper ray) attached to it, which has red markings by arrows pointing up: \\(\\mathrm{SO}(3)\\) acts on the sphere by rotating it, but when we physically carry out a rotation we will have to follow a path of rotations starting at the identity and leading to the required rotation; the purpose of the strip is to keep track of this path “in space” rather than “in time”. For example, this is the effect of rotating the sphere by \\(2\\pi\\) around the blue axis, which is the identity operation but as the strip tells you, that path you traced out is a nontrivial loop in \\(\\mathrm{SO}(3)\\). Indeed, try to unravel the strip out by moving it to one side as it was before, and one ends up with the following configuration: We see one of the red arrows pointing down, in other words a full twist in the strip. If we do it again, we might see either two full twists or none, depending on how we unravel the strip and bring it to one side - I encourage carrying this out by cutting out some paper strips. Therefore, it makes sense to count the number of twists on the strip modulo 2, i.e., the strip can have only two states, an “up” state and a “down” state, corresponding to any state of the sphere. This is exactly how elements of \\(\\mathrm{Spin}(3)\\) look like. This description of the spin group is not new; it is called the Dirac’s belt/plate trick. An elaborate animation can be found here where many such strips or belts are emerging out of the object that is exhibiting rotation. I think of a spin structure on a manifold \\(M\\) as a collection of such strips or framed proper rays from infinity attached to each unit tangent sphere so that the manifold looks like a marionette, and the associated “spin field” is the signed count of the number of full-twists or the up/down states along the strings. Probably not very useful, but sort of pleasant. Finally, let us get to exactly what kind of topological obstructions there are for a spin or spinc structure on a manifold to exist. Off the top of my head, here is a way to do this by throwing the kitchen sink at it: the frame bundle of \\(M\\) is classified by a map \\(M \\to B\\mathrm{SO}(n)\\), and the question of admitting a spin or spinc structure is the same question as lifting this to a map \\(\\psi : M \\to B\\mathrm{Spin}(n)\\) or \\(M \\to B\\mathrm{Spin}^{\\Bbb C}(n)\\) respectively. In the first case, there is a fibration sequence \\(\\mathrm{SO}(n) \\to \\mathrm{Spin}(n) \\to B\\Bbb Z/2\\) where the last map classifies the first map, which is a double covering. By delooping everything, we get a fibration sequence \\(B\\mathrm{SO}(n) \\to B\\mathrm{Spin}(n) \\to B^2\\Bbb Z/2\\). Thus, the question of lifting a map from \\(M\\) to the middle term to a map into the fiber is equivalent to the question of whether the composition \\(M \\to B^2 \\Bbb Z/2\\) to the base is nullhomotopic. This is classified by an element of \\(H^2(M; \\Bbb Z/2)\\); moreover it follows that this element lies in the image of the homomorphism \\(\\psi^* : H^2(B\\mathrm{SO}(n); \\Bbb Z/2) \\to H^2(M; \\Bbb Z/2)\\). As explained in this post, the cohomology ring \\(H^*(B\\mathrm{SO}(n); \\Bbb F_2) = \\Bbb F_2[w_1, w_2, \\cdots, w_n]\\) is generated by universal Stiefel-Whitney classes, hence the unique nonzero element in degree \\(2\\) is \\(w_2\\). Thus, the class in \\(H^2(M; \\Bbb Z/2)\\) is the second Stiefel-Whitney class \\(w_2(M)\\). In the second case, there is a fibration sequence \\(\\mathrm{Spin}^{\\Bbb C}(n) \\to \\mathrm{SO}(n) \\to BU(1)\\) which one can deloop as before and argue that the relevant obstruction for lifting \\(\\psi\\) to \\(M \\to B\\mathrm{Spin}^{\\Bbb C}(n)\\) lies in \\(H^3(M; \\Bbb Z)\\). Apparently, the class here is the “3rd integral Stiefel-Whitney class” \\(W_3 := \\beta w_2\\), where \\(\\beta : H^2(-; \\Bbb F_2) \\to H^3(-; \\Bbb Z)\\) is the integral Bockstein in degree \\(2\\), which looks intuitive enough but I haven’t worked out precisely why. Moreover, it might be worth phrasing all of this in terms of explicit cocycles than abstract obstruction theory. Edit: I have figured out why the obstruction class is \\(W_3 = \\beta w_2\\). There is a short exact sequence \\[0 \\to \\Bbb Z/2 \\to \\mathrm{Spin}^{\\Bbb C}(n) \\to \\mathrm{SO}(n) \\times \\mathrm{U}(1) \\to 0\\] which is classified by an element of \\(H^2(\\mathrm{SO}(n) \\times \\mathrm{U}(1); \\Bbb Z/2) \\cong H^2(\\mathrm{SO}(n); \\Bbb Z/2) \\oplus H^2(\\mathrm{U}(1); \\Bbb Z/2)\\) whose projection to the first factor classifies the short exact sequence \\[0 \\to \\Bbb Z/2 \\to \\mathrm{Spin}(n) \\stackrel{\\mathrm{ad}}{\\to} \\mathrm{SO}(n) \\to 0\\] obtained from the above short exact sequence by “forgetting the complex scalars” and the projection to the second factor classifies the short exact sequence \\[0 \\to \\Bbb Z/2 \\to U(1) \\stackrel{\\times 2}{\\to} U(1)\\] obtained from the same short exact sequence by “forgetting the orthogonal matrices”. Therefore, the pertaining element of \\(H^2(\\mathrm{SO}(n); \\Bbb Z/2)\\) is \\(w_2\\) and let us call the element in \\(H^2(U(1); \\Bbb Z/2)\\) as \\(\\alpha\\). Thus, the classifying element is \\(w_1 + \\alpha\\). Extending the short exact sequence to a fiber long exact sequence by delooping and dualizing gives for any \\(X\\) a short exact sequence \\[\\displaystyle [X, B\\mathrm{Spin}^{\\Bbb C}(n)] \\to [X, B\\mathrm{SO}(n)] \\oplus [X, B\\mathrm{U}(1)] \\to [X, B^2 \\Bbb Z/2] \\cong H^2(X; \\Bbb Z/2)\\] where the last map is, treating \\([X, BG]\\) as the group of isomorphism classes of principal \\(G\\)-bundles, \\[(E, F) \\mapsto w_2(E) + \\alpha(F) \\pmod{2}\\] Thus, \\(E\\) is a spinc-bundle if and only if \\((E, E)\\) maps to \\(0\\) if and only if \\[w_2(E) = \\alpha(E) \\pmod{2}\\] Observe this condition is equivalent to demanding that \\(\\alpha(E)\\) is an integral lift in \\(H^2(X; \\Bbb Z)\\) of \\(w_2(E) \\in H^2(X; \\Bbb Z/2)\\). Thus, \\(\\beta w_2(E) = 0 \\in H^3(X; \\Bbb Z)\\) by construction of Bockstein. In fact, once \\(E\\) has a spinc-structure then one focus on the complex scalars in the structure group and immediately turn it into a complex bundle, and \\(c_1(E) = \\alpha(E)\\) is exactly its first Chern class. In either case, it is evident from this that the existence of spin or spinc structures is much easier than almost complex structures; to start, all spheres have them! Every oriented \\(3\\)-manifold admits a spin structure because they are parallelizable, so all the pertaining characteristic classes vanish. Apparently, it is true that any oriented \\(4\\)-manifold admits a spinc structure. Next time, we shall discuss some geometry: the spin connection and the Dirac operator.",
      "categories": [],
      "tags": ["characteristic-classes","clifford-algebras","representation-theory","spin-geometry"]
    },
  
    {
      "title": "Notes on Steenrod Squares",
      "url": "/2021/12/26/steenrod-squares/",
      "date": "2021-12-26",
      "content": "These are some roughly written notes I am preparing as I study Steenrod operations. I expect nothing new beyond what is in Hatcher Chapter 4.L will be said here, but I will mention other references if I use them. This post is not going to be part of a series, and will instead be updated as I progress and decide to write more. A cohomology operation of type \\((G_1, G_2, m_1, m_2)\\) is a natural transformation \\[H^{m_1}(-; G_1) \\to H^{m_2}(-; G_2)\\] where \\(H^*\\) denotes singular cohomology. In other words, they are homomorphisms \\[\\Phi_X : H^{m_1}(X; G_1) \\to H^{m_2}(X; G_2)\\] such that for any map \\(f : X \\to Y\\), \\(f^* \\Phi_Y(\\alpha) = \\Phi_X(f^* \\alpha)\\); we will mostly drop the reference to the space \\(X\\) and denote the natural transformation by \\(\\Phi\\), as the space will be clear from context. One way to understand the motivation here is via the fact that singular cohomology is representable by Eilenberg-Maclane space \\(K(G, n)\\) (recall these are CW-complexes characterized uniquely upto homotopy equivalence by the property that all the homotopy groups vanish except the one in degree \\(n\\), and \\(\\pi_n \\cong G\\)), that is, \\(H^n(X; G) = [X, K(G, n)]\\) where \\([A, B]\\) denotes based homotopy classes of maps \\(A \\to B\\). Therefore, invoking Yoneda’s lemma, we obtain that cohomology operations of type \\((G_1, G_2, m_1, m_2)\\) are classified by elements of \\(H^{m_2}(K(G_1, m_1); G_2)\\). As a corollary, nontrivial cohomology operations only exist when \\(m_1 \\leq m_2\\). Moreover if \\(m_1 = m_2\\) then by Hurewicz’s theorem and universal coefficients theorem, we compute the cohomology group to be \\(\\mathrm{Hom}(G_1, G_2)\\), which implies the only cohomology operations in this case are change-of-coefficients homomorphisms. First interesting examples of cohomology operations are \\(H^k(X; \\Bbb F_p) \\to H^{kp}(X; \\Bbb F_p)\\) given by \\(\\alpha \\mapsto \\alpha^p\\). In the case \\(p = 2\\), the cup-square modulo 2 is a useful cohomology operation and can be used to detect topology. For example, consider \\(\\Bbb{CP}^2\\) and \\(S^2 \\vee S^4\\). These spaces have the same cohomology groups by cellular homology. However, if \\(\\alpha \\in H^2(\\Bbb{CP}^2; \\Bbb F_2)\\) denotes the generator then \\(\\alpha^2 = 1\\) but there is no degree \\(2\\) element in the cohomology ring of \\(S^2 \\vee S^4\\) which squares to \\(0\\); incidentally this says the attaching map of the \\(4\\)-cell in \\(\\Bbb{CP}^2\\), which is the Hopf map \\(h : S^3 \\cong \\partial D^4 \\to (\\Bbb{CP}^2)^{(3)} = S^2\\), is not nullhomotopic, implying \\(\\pi_3(S^2) \\neq 0\\). The major drawback with this operation, though, is that it is not stable under suspension. Indeed, the ring structure in \\(H^*(\\Sigma \\Bbb{CP}^2; \\Bbb F_2)\\) is completely trivial, cup product of any pair of elements is \\(0\\). However, \\(\\Sigma \\Bbb{CP}^2\\) is not homotopy equivalent to \\(\\Sigma(S^2 \\vee S^4) \\simeq S^3 \\vee S^5\\). To prove something like this, we need to develop a stable generalization of the cup-square modulo 2 or the \\(p\\)-th power operation modulo \\(p\\) in general; these are exactly what Steenrod squares or Steenrod power operations are, respectively. Notice that as a corollary of this we end up proving that the attaching map of the \\(5\\)-cell in \\(\\Sigma \\Bbb{CP}^2\\), which is the suspension \\(\\Sigma h : S^4 \\to S^3\\) of the Hopf map is not nullhomotopic, which demonstrates \\(\\pi_4(S^3) \\neq 0\\). Indeed, we shall end up proving that the spaces are never homotopy equivalent even if they are suspended \\(k\\)-fold, which demonstrates the first stable stem \\(\\pi_1^s := \\lim_k \\pi_{k+1}(S^k) \\neq 0\\). (Actually, one can deduce this from just \\(\\pi_4(S^3) \\neq 0\\), by the sharp version of the Freudenthal suspension theorem specifying the stable range.) There are two cases to consider, \\(p = 2\\) and \\(p\\) an odd prime. In the former, we shall have the Steenrod square operations \\(Sq^i : H^n(X; \\Bbb F_2) \\to H^{n+i}(X; \\Bbb F_2)\\) for every \\(i \\geq 0\\). In the latter case, we shall have the Steenrod power operations \\(P^i : H^n(X; \\Bbb F_p) \\to H^{n+2i(p-1)}(X; \\Bbb F_p)\\) for every \\(i \\geq 0\\). These operations are characterized by the following axioms: \\(Sq^0 = \\mathbf{1}, P^0 = \\mathbf{1}\\). \\(Sq^1 = \\beta_2\\) is the Bockstein homomorphism for the sequence \\(0 \\to \\Bbb Z_2 \\to \\Bbb Z_4 \\to \\Bbb Z_2 \\to 0\\). \\(Sq^i a = a^2\\) if \\(i = \\vert a\\vert\\), \\(Sq^i a = 0\\) if \\(i &gt; \\vert a\\vert\\), and likewise \\(P^i a = a^p\\) if \\(2i = \\vert a\\vert\\), \\(P^i a = 0\\) if \\(2i &gt; \\vert a\\vert\\). \\(Sq^i \\sigma = \\sigma Sq^i, P^i \\sigma = \\sigma P^i\\), where \\(\\sigma : H^*(X) \\to H^*(\\Sigma X)\\) is the suspension isomorphism. Cartan’s formula: \\(Sq^j(a \\smile b) = \\sum_i Sq^i a\\smile Sq^{j-i} b\\) and \\(P^j(a \\smile b) = \\sum_i P^i a \\smile P^{j-i} b\\). Adem relations regarding compositions of Steenrod squares or powers: \\[\\displaystyle \\begin{aligned}Sq^i Sq^j &amp;= \\sum_k \\binom{j-k-1}{i-2k} Sq^{i+j-k} Sq^k, \\; i &lt; 2j \\\\ P^i P^j &amp;= \\sum_k (-1)^{i+k} \\binom{(p-1)(j-k)-1}{i-pk} P^{i+j-2k} P^k, \\; i &lt; pj \\\\ P^i \\beta_p P^j &amp;= \\sum_k (-1)^{i+k} \\binom{(p-1)(j-k)-1}{i-pk} \\beta_p P^{i+j-k} P^k \\\\ &amp;- \\sum_k (-1)^{i+k} \\binom{(p-1)(j-k)-1}{i-pk-1} P^{i+j-k} \\beta_p P^k, \\; i \\leq pj.\\end{aligned}\\] Define the totals \\(Sq : H^*(X; \\Bbb F_2) \\to H^*(X; \\Bbb F_2)\\) and \\(P : H^*(X; \\Bbb F_p) \\to H^*(X; \\Bbb F_p)\\) as \\[\\begin{align*} Sq &amp;= Sq^0 + Sq^1 + Sq^2 + \\cdots \\\\ P &amp;= P^0 + P^1 + P^2 + \\cdots\\end{align*}\\] Then Cartan’s formula is just stating \\(Sq\\) and \\(P\\) are ring endomorphisms. The relativized versions \\(Sq : H^*(X, A; \\Bbb F_2) \\to H^*(X, A; \\Bbb F_2)\\) and \\(P : H^*(X, A; \\Bbb F_p) \\to H^*(X, A; \\Bbb F_p)\\) of the operations can be constructed from the axioms via the natural isomorphism \\(H^*(X, A) \\cong H^*(X/A)\\); for these we require the Cartan formula is true under relative cup product \\(H^*(X, A) \\times H^*(X, B) \\to H^*(X, A \\cup B)\\). The axioms above are not independent in any sense. In fact, the rest of the axioms follow from the relativized versions of 1, 3 and 5 (see Epstein-Steenrod) We begin with the construction of the Steenrod squares and power operations instead. The general idea is pretty geometric: consider the \\(p\\)-fold exterior cup product \\[H^*(X; \\Bbb F_p)^{\\otimes p} \\to H^*(X^p; \\Bbb F_p)\\] Let \\(\\alpha \\in H^n(X; \\Bbb F_p)\\) be an element, and consider its image under the map \\(\\alpha^{\\otimes p}\\). Appealing to the fact quoted in the first paragraph of this post, this is represented by a map \\(f : X^p \\to K(\\Bbb Z/p, np)\\). Note that \\(\\Bbb Z/p\\Bbb Z\\) acts on \\(X^p\\) by permuting the factors cyclically. Let us define \\[\\begin{gather*}T : X^p \\to X^p \\\\ T(x_1, \\cdots, x_p) = (x_p, x_1, \\cdots, x_{p-1})\\end{gather*}\\] Then $T$ generates the aforementioned cyclic action. The composition \\(f \\circ T : X^p \\to K(\\Bbb Z/p, np)\\) is a new map but it is nonetheless homotopic to the older map \\(f\\) as they both represent the same element \\(\\alpha^{\\otimes p} \\in H^{np}(X^p; \\Bbb F_p)\\). The homotopy can be written as a map \\(X^p \\times [0, 1/p] \\to K(\\Bbb Z/p, np)\\) (the odd choice \\([0, 1/p]\\) for the time-interval will be clear in a bit). One can argue the same for \\(f \\circ T\\) and \\(f \\circ T^2\\) and obtain a homotopy \\(X^p \\times [1/p, 2/p] \\to K(\\Bbb Z/p, np)\\), and so on until we have come back full circles to \\(f \\circ T^{p-1}\\) and \\(f \\circ T^p = f\\). Paste these homotopies end-to-end to get a map \\[f_1 : X^p \\times S^1 \\to K(\\Bbb Z/p, np)\\] It turns out that one can choose all the earlier homotopies between \\(f, f \\circ T, f \\circ T^2, \\cdots\\) carefully such that, by obstruction theory, \\(f_1\\) is nullhomotopic. Once that is established, consider the \\(\\Bbb Z/p\\)-action on \\(X^p \\times S^1\\) given by a diagonal action where the action on \\(X^p\\) is as before and on \\(S^1\\) is given by a \\(2\\pi/p\\) rotation, permuting the arcs which were intervals of the earlier homotopies; these \\(\\Bbb Z/p\\)-translates of \\(f_1\\) are also all nullhomotopic, and the nullhomotopies \\(X^p \\times D^2 \\to K(\\Bbb Z/p, np)\\) glue up to a map \\[f_2 : X^p \\times E_2 \\to K(\\Bbb Z/p, np),\\] where \\(E_2\\) is the complex given by attaching \\(p\\)-many \\(2\\)-cells to the circle, and it admits a \\(\\Bbb Z/p\\)-action which simultaneously rotates the “equator” \\(S^1\\) by \\(2\\pi/p\\) and cyclically permutes the \\(2\\)-cells. Inducting upward, one ends up with a map \\(f_\\infty : X^p \\times E\\Bbb Z/p \\to K(\\Bbb Z/p, np)\\) where \\(E\\Bbb Z/p\\) is a contractible complex on which \\(\\Bbb Z/p\\) acts freely. Restrict this map on the first factor to the diagonal copy of \\(X \\subset X^p\\), and mod out by the \\(\\Bbb Z/p\\)-action to get a map \\(X \\times B\\Bbb Z/p \\to K(\\Bbb Z/p, np)\\). This represents an element in \\[H^{*}(X \\times B\\Bbb Z/p; \\Bbb F_p) \\cong H^{*}(X; \\Bbb F_p) \\otimes \\Lambda_{\\Bbb F_p}^*[x] \\otimes \\Bbb F_p[y]\\] of degree \\(np\\), where \\(\\vert x\\vert = 1, \\vert y\\vert = 2\\). Therefore, the element can be written as \\[\\sum_{0 \\leq i \\leq np} \\omega_{(p-1)n-i} \\otimes \\theta_i(\\alpha)\\] where \\(\\omega_{2j} = y^j, \\omega_{2j+1} = x y^j\\) and \\(\\theta_i(\\alpha) \\in H^{n+i}(X; \\Bbb F_p)\\). If \\(p = 2\\), the Steenrod squares will be \\(Sq^i = \\theta_i\\) and if \\(p\\) is an odd prime the Steenrod powers will be \\(P^i = \\kappa_i \\theta_{2i(p-1)}\\) for certain appropriate normalizing factor \\(\\kappa_i\\). Caveat: Here we used the isomorphism \\[H^*(B\\Bbb Z/p; \\Bbb F_p) \\cong \\Lambda^*_{\\Bbb F_p}[x] \\otimes \\Bbb F_p[y],\\] where \\(\\vert x\\vert = 1, \\vert y\\vert = 2\\). To demonstrate this, observe \\(B\\Bbb Z/p\\) is an infinite dimensional lens space so has a single cell in every dimension; the integral cellular cochain complex has differentials alternating between \\(0\\) and multiplication by \\(p\\) whereas the mod \\(p\\) cellular cochain complex has no differentials. By naturality with respect to the change of coefficients homomorphism \\(\\Bbb Z \\to \\Bbb Z_p\\), we see that the map from integral cohomology is surjective in even degrees and zero in odd degrees. Comparing the Bockstein sequences corresponding to the short exact sequences \\(0 \\to \\Bbb Z \\to \\Bbb Z \\to \\Bbb Z_p \\to 0\\) and \\(0 \\to \\Bbb Z_p \\to \\Bbb Z_{p^2} \\to \\Bbb Z_p \\to 0\\), we obtain that the Bockstein homomorphism \\[\\beta_p : H^n(B\\Bbb Z/p; \\Bbb F_p) \\to H^{n+1}(B\\Bbb Z/p; \\Bbb F_p)\\] is zero in even degrees and an isomorphism in odd degrees. Next, let \\(y \\in H^2(B \\Bbb Z/p; \\Bbb F_p)\\) be pullback of the generator of \\(H^2(\\Bbb{CP}^\\infty)\\) under the fibration \\(B\\Bbb Z/p \\to \\Bbb{CP}^\\infty\\) induced from \\(S^\\infty \\to \\Bbb{CP}^\\infty\\) after quotienting by the \\(\\Bbb Z/p \\subset U(1)\\) action on the domain; this is simply an isomorphism in even degrees by the discussion above. Then by the fact that \\(\\beta_p\\) is an isomorphism in degree \\(1\\), we find an element \\(x \\in H^1(B\\Bbb Z/p; \\Bbb F_p)\\) such that \\(\\beta_p(x) = y\\). By ring structure of the Bockstein, \\(\\beta(x y^k) = y^{k+1}\\) are generators in even degrees, therefore \\(xy^k\\)’s must generate the odd degrees. This finishes the proof. Unfortunately, checking that these indeed satisfy the required properties is much harder than it sounds, for full details see Hatcher, Ch 4.L (I might add in more details here as I understand them on the way). We move on to some computations. To return to the earlier example, observe that for the generator \\(\\alpha \\in H^2(\\Bbb{CP}^2; \\Bbb F_2)\\), \\(Sq^2 \\alpha = \\alpha^2 \\neq 0\\) and therefore by stabilit we must also have \\(Sq^2 \\sigma^k(\\alpha) \\neq 0\\), where \\(\\sigma^k(\\alpha) \\in H^{2+k}(\\Sigma^k \\Bbb{CP}^2; \\Bbb F_2)\\) is the generator of the \\(k\\)-fold suspension. However, for \\[S^k(S^2 \\vee S^4) \\simeq S^{2+k} \\vee S^{4+k},\\] all Steenrod squares simply vanish, since \\(Sq^2\\) of a class in \\(H^*(S^{2+k})\\) stays there by naturality with respect to the retract on that factor, and likewise for the other factor, but there’s no space in the cohomology of spheres for nontrivial cohomology operations. The argument goes through word-by-word with the mapping cone \\(C(f)\\) in place of \\(\\Bbb{CP}^2\\), where \\(f : S^{2n-1} \\to S^n\\) is a map of Hopf invariant \\(1\\). This shows the stable stem \\(\\pi_1^s, \\pi_3^s, \\pi_7^s\\) are all nonzero, as they call contain the stable Hopf fibrations of appropriate degree, which by above are actually non-null. In fact, one can argue using these Hopf fibrations that \\(\\pi_2^s, \\pi_6^s, \\pi_{14}^s\\) are nonzero as well: recall that there is a graded ring structure on \\(\\pi_*^s\\) defined upto appropriately stabilizing by \\((f, g) \\mapsto \\Sigma^* f \\circ g\\), the graded commutativity of this product upto stabilization can be seen by writing the suspension as smashing with the circle many times, and then permuting factors, which tells that the product is homotopic to \\(\\Sigma^* f \\wedge \\Sigma^* g\\). The claim is that under this product, the squares of the Hopf fibrations are stably nonzero. Suppose \\(h : S^{n+1} \\to S^n\\) is a suspension of the Hopf map, and let \\(C_n\\) denote the mapping cone. If \\(\\Sigma h \\circ h : S^{n+2} \\to S^n\\) is nullhomotopic, consider the map \\(S^{n+3} = D^{n+2} \\cup_{S^{n+1}} D^{n+2} \\to C_n\\) defined on the equator by sending it to the \\(n\\)-skeleton by \\((\\Sigma h) \\circ h\\), on the top hemisphere by the nullhomotopy of \\(\\Sigma h \\circ h\\) and on the bottom hemisphere by \\(C(\\Sigma h) \\circ h\\). Attach a \\(D^{n+4}\\) to \\(C_h\\) along this map to obtain a cell complex \\(X\\). Then observe \\(Sq^2 : H^n(X; \\Bbb F_2) \\to H^{n+2}(X; \\Bbb F_2)\\) is, by naturality applied to inclusion of the \\((n+2)\\)-skeleton, the same as \\(Sq^2 : H^n(C_h; \\Bbb F_2) \\to H^{n+2}(C_h; \\Bbb F_2)\\) which is a suspension of the corresponding \\(Sq^2\\) on the mapping cone of the Hopf map, which is the Hopf invariant, \\(1\\). Thus, \\[Sq^2 : H^n(X; \\Bbb F_2) \\to H^{n+2}(X; \\Bbb F_2)\\] is an isomorphism. Further, we obtain that \\(Sq^2 : H^{n+2}(X; \\Bbb F_2) \\to H^{n+4}(X; \\Bbb F_2)\\) is the same, since by naturality applied to the quotient map \\(X \\to X/S^n\\) which is an isomorphism above degree \\(n\\) by cellular homology, \\(Sq^2 : H^{n+2}(C_{\\Sigma^2 h}; \\Bbb F_2) \\to H^{n+4}(C_{\\Sigma^2 h}; \\Bbb F_2)\\), once again an isomorphism. Thierefore \\(Sq^2 Sq^2 : H^n \\to H^{n+4}\\) must be an isomorphism but by Adem relations \\(Sq^2 Sq^2 = Sq^3 Sq^1 = 0\\) as \\(Sq^1 = 0\\); there’s no \\(H^{n+1}\\) for it to be nonzero. (I will probably fill in something about the relation between Steenrod squares and Stiefel-Whitney classes, an analogous relation between Steenrod powers with Chern classes modulo \\(p\\) will be used in Seiberg-Witten Theory: Part 2. I might end up doing some exercises from Chapter 4.L and write the interesting solutions here, and there’s plenty of examples in Hatcher in any case. Recommendations on computations are welcome.)",
      "categories": [],
      "tags": ["characteristic-classes","stable-homotopy-theory","steenrod-squares"]
    },
  
    {
      "title": "Markov Chains: I",
      "url": "/2020/11/02/markov-chains-i/",
      "date": "2020-11-02",
      "content": "Broadly speaking, a discrete-time dynamical system is a “space” \\(X\\) along with a transformation \\(T : X \\to X\\), in an appropriate category of “spaces” (topological spaces, measure spaces, …). I think of a discrete Markov chain as a discrete-time dynamical system where the transformation \\(T\\) behaves “randomly”. Before illustrating this in detail let me reproduce the precise definition, based on Lecture 10 of the course notes here. We shall say a discrete-time stochastic process \\(\\{X_n\\}_{n \\geq 0}\\) takes values in a countable “state space” \\(S\\) if \\(\\mathrm{Range}(X_n) \\subseteq S\\) for all \\(n \\geq 0\\) and \\(S\\) is countable. Without loss of generality, we can throw away the “irrelevant states” and let \\(S = \\bigcup_{n \\geq 0} \\mathrm{Range}(X_n)\\). We fix a probability distribution \\(\\mathbf{a} = (a_k : k \\in S)\\) on the state space, i.e., \\(0 \\leq a_k \\leq 1\\) for all \\(k \\in S\\), such that \\(\\sum_{k \\in S} a_k = 1\\). Furthermore, let \\(P = (p_{ij})_{i, j \\in S}\\) be a \\(\\|S\\| \\times \\|S\\|\\)-dimensional matrix with elements indexed by \\(S \\times S\\), such that for all \\(i, j \\in S\\), \\(0 \\leq p_{ij} \\leq 1\\) and \\(\\sum_{j \\in S} p_{ij} = 1\\) for all \\(i \\in S\\). A discrete-time stochastic process \\(\\{X_n\\}_{n \\geq 0}\\) taking values in a countable state space \\(S\\) is a discrete, time-stationary, countable-state space Markov chain with initial distribution \\(\\mathbf{a}\\) and transition probability matrix \\(P\\) if \\(X_0 \\sim \\mathbf{a}\\), and for all \\(n \\in \\Bbb N\\), \\(i_0, i_1, \\cdots, i_n \\in S\\), \\[\\Bbb P(X_0 = i_0, X_1 = i_1, \\cdots, X_n = i_n) = a_{i_0} p_{i_0 i_1} p_{i_1 i_2} \\cdots p_{i_{n-1} i_n}\\] Let us compute the distribution of \\(X_n\\) on \\(S\\) explicitly: For any \\(i \\in S\\), \\[\\displaystyle \\begin{aligned}\\Bbb P(X_n = i) &amp;= \\sum_{i_0, \\cdots, i_{n-1} \\in S} \\Bbb P(X_n = i, X_{n-1} = i_{n-1}, \\cdots, X_0 = i_0) \\\\ &amp;= \\sum_{i_0, \\cdots, i_{n-1} \\in S} a_{i_0} p_{i_0 i_1} \\cdots p_{i_{n-2} i_{n-1}} p_{i_{n-1} i} = (\\mathbf{a}^\\mathsf{T} P^n)_i\\end{aligned}\\] Therefore, \\(X_n \\sim \\mathbf{a}^\\mathsf{T} P^n\\). Note that therefore the distribution of the process \\(\\{X_n\\}_{n \\geq 0}\\) depends linearly on the initial distribution \\(\\mathbf{a}\\) on \\(S\\); to be precise let \\(\\mathscr{P}(S)\\) denote the space of probability distributions on \\(S\\), then the transition matrix \\(P\\) acts on this space by multiplying by a row vector on the left: \\(T : \\mathscr{P}(S) \\to \\mathscr{P}(S)\\), \\(\\mathbf{a} \\mapsto \\mathbf{a}^\\mathsf{T} P\\), which preserves convex combinations, and the result of iterating this operator \\(n\\) times is the same as running the Markov process for time \\(n\\), starting from the initial distribution \\(\\mathbf{a}\\). Since the space of probability distributions on \\(S\\) is convex hull of the Dirac masses \\(\\delta_i\\), \\(i \\in S\\), it suffices to understand the process for these initial distributions. We get, \\[\\displaystyle T(\\delta_i) = \\sum_{j \\in S} p_{i j} \\delta_j\\] Thus, we abuse notation and write the map \\(T : S \\to \\mathscr{P}(S)\\). Note that for any \\(i \\in S\\), \\(T(i)\\) is the law of the conditional distribution \\(X_{n+1} \\| X_n = i\\) for any \\(n \\geq 0\\). \\(T\\) is vaguely like a map \\(T : S \\to S\\) determining a dynamical system on \\(S\\), but the dynamics is no longer deterministic; pushing a point \\(i \\in S\\) forward by \\(T\\) does not give a point but a “probability cloud” \\(T(i) \\in \\mathscr{P}(S)\\) which associates to \\(j \\in S\\) the probability \\(p_{ij}\\). I learnt this interpretation from Vadim Kaimanovich, and I find it to be an efficient way of thinking. This operator \\(T\\) is called a Markov kernel. We shall understand the iterates \\(T^k\\), \\(k \\geq 2\\) to be determined by the rows of the \\(k\\)-step transition matrix \\(P^k\\). One can recover the stochastic process \\(\\{X_n\\}_{n \\geq 0}\\) on \\(S\\) from the Markov kernel as follows: Fix an initial distribution \\(\\mathbf{a}\\) on \\(S\\) and define a probability measure \\(\\Bbb P_{\\mathbf{a}}\\) on \\(S^{\\Bbb N_0}\\) by defining it on cylinder events in a natural way: \\[\\displaystyle \\Bbb P_{\\mathbf{a}}(\\{\\omega \\in S^{\\Bbb N_0} : \\omega_0 = s_0, \\omega_1 = s_1, \\cdots, \\omega_k = s_k\\}) = a_{s_0} T(s_0)(s_1) \\cdots T(s_{k-1})(s_k)\\] One can think of the probability space \\((S^{\\Bbb{N}_0}, \\mathscr{C}, \\Bbb{P}_\\mathbf{a} )\\) as the background space of all sample paths the Markov chain can take, starting with initial distribution \\(\\mathbf{a}\\) and transition matrix \\(P\\), with each path carrying their individual likelihoods. Finally, let \\(\\Sigma : S^{\\Bbb N_0} \\to S^{\\Bbb N_0}\\) be the right-shift operator, and define \\[\\displaystyle X_n := X_0 \\circ \\Sigma^{\\circ n} : (S^{\\Bbb N_0}, \\mathscr{C}, \\Bbb P_{\\mathbf{a}}) \\to S\\] This gives a straightforward way of speaking of several notions in dynamical systems in the context of Markov chains. If \\((X, T)\\) is a dynamical system, \\(A \\subseteq X\\) is a subset, we can speak of the hitting time function \\(\\tau_A : X \\to \\Bbb N \\cup \\{\\infty\\}\\), defined by \\(\\tau_A(x) = \\inf \\{k \\geq 0 : T^k(x) \\in A\\}\\), to be the first time the forward-orbit of \\(x\\) goes inside \\(A \\subseteq X\\) under iterates \\(T\\). Clearly, \\(\\tau_A(x) = 0\\) if \\(x \\in A\\) and \\(A \\subset X\\) is forward-invariant, i.e., \\(T(A) \\subseteq A\\) if and only if \\(\\tau_{X \\setminus A}(x) = \\infty\\) for all \\(x \\in A\\). In the context of a Markov chain, we define a random variable-valued hitting time \\(\\tau_A\\) for any subset \\(A \\subseteq S\\) by \\[\\displaystyle \\tau_A(i) = \\inf\\{k \\geq 0 : (X_k\\|X_0 = i) \\in A\\}\\] We shall say the state \\(i \\in S\\) leads to the state \\(j \\in S\\) if \\(\\Bbb P(\\tau_j(i) &lt; \\infty) &gt; 0\\). It is easy to see this happens if and only if the set of sample paths in \\(S^{\\Bbb N_0}\\) which reach \\(j\\) in some finite time has positive \\(\\Bbb P_i\\)-probability, or equivalently \\((P^n)_{ij} &gt; 0\\) for some \\(n \\in \\Bbb N_0\\). This is a reflexive, transitive (since \\(P^{n+m} = P^n P^m\\)) relation on \\(S\\) but is not going to be symmetric in general. An easy example is the deterministically monotone Markov chain on \\(\\Bbb Z\\) with kernel \\(T : \\Bbb Z \\to \\mathscr{P}(\\Bbb Z)\\) given by \\(T(k) = \\delta_{k+1}\\), shifting mass one step to the right. Any state only leads to states to the right of it. So we can say that the states that \\(i \\in S\\) leads to form the “forward-orbit” of \\(i\\) in this “fuzzy” dynamical system. A subset \\(C \\subset S\\) is said to be closed if \\(\\Bbb P(\\tau_{S \\setminus C}(i) = \\infty) = 1\\) for all \\(i \\in C\\), hence these are the forward-invariant subsets of the Markov chain. We can symmetrize the said relation to form an equivalence relation \\(\\sim\\) on \\(S\\), by defining \\(i \\sim j\\) iff \\(i\\) leads to \\(j\\) as well as \\(j\\) leads to \\(i\\), and in this case state \\(i\\) is said to communicate with state \\(j\\). The \\(\\sim\\)-equivalence classes in \\(S\\) are called communication classes. States achievable in backward time are also achievable in forward time within a communication class. A Markov chain is said to be irreducible if the state space consists of only one communication class. In the measurable space of sample paths \\((S^{\\Bbb N_0}, \\mathscr{C})\\), the irreducibility hypothesis essentially says that the paths do not stay trapped in a tube \\(A^{\\Bbb N_0}\\) forever, for some subset \\(A \\subset S\\), which would be a proper communication class if this situation occurs. This vaguely suggests that running an irreducible Markov process from any point will initiate a dynamical system which is chaotic in some sense. Let us work towards making the last remark incredibly precise. Let \\(S\\) be a finite state space, \\(P\\) be a transition matrix on this state space. Recall that \\(P : \\mathscr{P}(S) \\to \\mathscr{P}(S)\\) acts on the convex set of probability distributions on \\(S\\) by multiplication on the left, \\(\\mathbf{a} \\mapsto \\mathbf{a}^\\mathsf{T} P\\). Since \\(S\\) is a finite state space, \\(\\mathscr{P}(S)\\) as a subset of \\(\\Bbb R^S\\) has exactly \\(S\\)-many extreme points given by the Dirac masses at the points of \\(S\\), which makes it a simplex of dimension \\(\\|S\\| - 1\\). A simplex is a topological disk, and multiplying on the left by \\(P\\) gives a continuous self-map of this disk, which has to have a fixed point by Brouwer’s fixed point theorem. Thus, there exists a probability vector \\(\\mathbf{\\pi}\\) such that \\(\\mathbf{\\pi}^\\mathsf{T} P = \\mathbf{\\pi}^\\mathsf{T}\\); such a vector is called a stationary distribution for the Markov chain. If \\(P\\) is irreducible, there is in fact a unique stationary distribution: Observe that kernel of the matrix \\(I - P\\) is the space of harmonic functions on the weight graph on \\(S\\) determined by the Markov chain, that is, \\(P f = f\\) if and only if \\(f(x) = \\sum_{y \\in S} P_{x, y} f(y)\\) for all \\(x \\in S\\). By irreducibility, the weighted graph is connected in the sense that, for any two states in \\(S\\), there is a path of positive weight connected them in the said graph. Since \\(S\\) is finite, such a function \\(f\\) must attain a minimum, which forces it to be constant everywhere by connectedness. This implies \\(\\dim \\ker(I - P) = 1\\), hence \\(\\dim \\ker(I - P^\\mathsf{T}) = 1\\) as well. This shows kernel of \\(I - P^\\mathsf{T}\\) is \\(1\\)-dimensional, which forces \\(\\pi\\) to be the unique stationary distribution for the Markov chain. Theorem. Let \\(S\\) be a finite state space, and \\(T : S \\to \\mathscr{P}(S)\\) be the Markov kernel for an irreducible Markov chain on \\(S\\). Let \\(\\pi\\) be the corresponding unique stationary distribution. Then, \\[\\Sigma : (S^{\\Bbb N_0}, \\mathscr{C}, \\Bbb P_\\pi) \\to (S^{\\Bbb N_0}, \\mathscr{C}, \\Bbb P_\\pi)\\] is an ergodic transformation. Proof. First of all, \\(\\Sigma\\) is easily checked to be measure preserving since \\(\\pi\\) is a stationary measure. Suppose \\(A \\subset S^{\\Bbb N_0}\\) is a \\(\\Sigma\\)-invariant subset, that is, \\(\\Sigma^{-1}(A) = A\\). Consider the random variable \\(Z : (S^{\\Bbb N_0}, \\mathscr{C}, \\Bbb P_\\pi) \\to \\{0, 1\\}\\), \\(Z = \\mathbf{1}_A\\). Define the random variables \\(Z_k = \\Bbb E[Z\\|X_0, \\cdots, X_k]\\) for \\(k \\geq 0\\). Clearly, \\(\\Bbb E[Z_{k+1}\\|X_0, \\cdots, X_k] = Z_k\\) so \\(\\{Z_k\\}_{k \\geq 1}\\) forms a discrete-time martingale. Moreover, this martingale is bounded since \\(\\Bbb E[\\|Z_k\\|] \\leq \\Bbb E[\\|Z\\|]\\) for all \\(k \\geq 1\\). Therefore, by Martingale Convergence Theorem, \\(Z_k \\to Z_\\infty\\) almost surely, where the only possibility is \\(Z_\\infty = \\Bbb E[Z\\|X_1, X_2, \\cdots] = Z\\) since the \\(\\sigma\\)-algebra generated by \\(X_1, X_2, \\cdots\\) is the full product \\(\\sigma\\)-algebra on \\(S^{\\Bbb N_0}\\), taking conditional expectation with respect to which returns the random variable itself. Note that by \\(\\Sigma\\)-invariance of \\(A\\), \\(Z \\circ \\Sigma^n = Z\\) for all \\(n \\geq 1\\). Thus, \\[\\begin{aligned}\\displaystyle Z_k(\\omega) &amp;= \\Bbb E[Z\\|X_0 = \\omega_0, \\cdots, X_k=\\omega_k] \\\\ &amp;= \\Bbb E[Z \\circ \\Sigma^k\\|X_0=\\omega_0, \\cdots, X_k=\\omega_k] \\\\ &amp;= \\Bbb E[Z \\circ \\Sigma^k\\|X_k=\\omega_k] \\\\ &amp;= \\Bbb E[Z\\|X_0=\\omega_k]\\end{aligned}\\] For every \\(\\omega \\in S^{\\Bbb N_0}\\). As \\(Z_k \\to Z\\) almost surely, for \\(\\Bbb P_\\pi\\)-almost every \\(\\omega \\in S^{\\Bbb N_0}\\) we get \\(\\Bbb E[Z\\|X_0 = \\omega_k] = Z(\\omega)\\). By irreducibility, for every state \\(s \\in S\\), \\(\\Bbb P_\\pi\\)-almost every sample path visit \\(s\\) infinitely often. Thus, \\(Z = \\Bbb E[Z\\|X_0 = s]\\) almost surely for every state \\(s \\in S\\). In particular, \\(Z\\) is a degenerate random variable, so \\(\\Bbb P_\\pi(A)\\) is either \\(0\\) or \\(1\\). This establishes ergodicity.",
      "categories": [],
      "tags": ["dynamical-systems","ergodic-theory","markov-chains"]
    },
  
    {
      "title": "Poisson Process: I",
      "url": "/2020/09/06/poisson-process-i/",
      "date": "2020-09-06",
      "content": "I am taking the course Introduction to Stochastic Processes offered by my institute and taught by Parthanil Roy this semester, and wanted to jot down some notes interspersed with my own thoughts somewhere, hence this post. We have started by discussing about point processes, so that is what I expect to talk about in the first few posts of the series. I have recycled the exposition and terminology present in the lecture notes from the instructor of the course, and the text “Lectures on the Poisson Process” by Last and Penrose, also available online, which I am reading independently. A point process on a space \\(\\mathbb{X}\\) is a random collection of countably many points on \\(\\mathbb{X}\\). One can think of it as a measure on the configuration space of countably many points on \\(\\mathbb{X}\\) but this becomes rather uselessly abstract. One way to understand this is to imagine \\(\\mathbb{X}\\) as a dartboard, and we are randomly throwing countably many darts at it. We can fix any measurable subset \\(B \\subset \\mathbb{X}\\) of the dartboard and ask how many darts hit \\(B\\). This itself is a random variable, and taking expectation of this variable defines a measure \\(\\lambda\\) on \\(\\mathbb{X}\\), where \\(\\lambda(B)\\) is the average number, or the intensity of darts that hit \\(B\\). As we vary \\(B \\subset \\mathbb{X}\\), probing the whole dartboard by its measurable subsets, the random variables which count the number of darts in the region \\(B\\) of the dartboard determines the full random configuration of darts. To make this setup precise, we’ll change our viewpoint. Let \\((\\mathbb{X}, \\mathcal{X})\\) be a measurable space, and \\(M(\\mathbb{X})\\) be the space of \\(\\Bbb N_0\\)-valued measures on this space. Moreover let \\(\\overline{M}(\\mathbb{X})\\) be the space of countable linear combination of elements of \\(M(\\mathbb{X})\\); we shall think of elements of this space as counting measures on \\(\\mathbb{X}\\), although generally they can be more complicated than counting measures, which are really linear combinations of Dirac masses at distinct points on \\(\\mathbb{X}\\). We can equip \\(\\overline{M}(\\mathbb{X})\\) with a \\(\\sigma\\)-algebra \\(\\mathcal{M}\\) generated by collection of all cylinder subsets of the form \\(\\{\\mu \\in \\overline{M}(\\mathbb{X}) : \\mu(B) = k\\}\\), where \\(B \\in \\mathcal{X}\\), \\(k \\in \\Bbb N_0 \\cup \\{\\infty\\}\\). Define a point process on \\((\\mathbb{X}, \\mathcal{X})\\) to be a measurable map \\(\\eta : (\\Omega, \\mathcal{A}, \\Bbb P) \\to (\\overline{M}(\\mathbb{X}), \\mathcal{M})\\) from some probability measure space \\((\\Omega, \\mathcal{A}, \\Bbb P)\\). This looks different from what we were describing in the first paragraph but all we did was a currying trick; for any fixed measurable set \\(B \\subset \\mathbb{X}\\), denote by \\(\\eta(B)\\) to be the random variable \\((\\Omega, \\mathcal{A}, \\Bbb P) \\to \\Bbb N_0 \\cup \\{\\infty\\}\\), \\(\\omega \\mapsto \\eta(\\omega)(B)\\), which is the number of points of \\(\\eta\\) in \\(B\\). The intensity measure on \\((\\mathbb{X}, \\mathcal{X})\\) is given by \\(\\lambda(B) := \\Bbb E \\eta(B)\\). What this perspective allows us to see is that a point process can alternatively be described as a random counting measure on \\((\\mathbb{X}, \\mathcal{X})\\). Alternatively, one can unfurl the whole thing to a map \\(\\eta : \\Omega \\times \\mathcal{X} \\to \\Bbb N_0 \\cup \\{\\infty\\}\\), \\((\\omega, B) \\mapsto \\eta(\\omega)(B)\\). This is called the transition kernel of the process. A simple example of a point process is as follows. Let \\(X_1, \\cdots, X_n : (\\Omega, \\mathcal{A}, \\Bbb P) \\to (\\mathbb{X}, \\mathcal{X})\\) be \\(\\mathbb{X}\\)-valued random variables, or random points on \\(\\mathbb{X}\\), which are independently distributed with the same law \\(\\mu\\). Then define \\(\\eta := \\delta_{X_1} + \\cdots + \\delta_{X_n}\\) where \\(\\delta_x\\) denotes the Dirac mass at \\(x \\in \\mathbb{X}\\). This is called the binomial process with sample size \\(n\\) and sampling distribution \\(\\mu\\) on \\(\\mathbb{X}\\), as \\[\\displaystyle \\Bbb P(\\eta(B) = k) = \\binom{n}{k} \\mu(B)^k (1 - \\mu(B))^{n-k}\\] A point process \\(\\eta\\) on \\(\\mathbb{X}\\) is called proper if there exists \\(\\mathbb{X}\\)-valued random variables \\(X_1, X_2, \\cdots\\) and a \\(\\mathbb{N}_0 \\cup \\{\\infty\\}\\)-valued random variable \\(Z\\) such that almost surely, \\(\\eta = \\sum_{i = 1}^Z \\delta_{X_i}\\). A class of examples of central attention for us are Poisson processes. Let us begin by introducing such a process on the non-negative real line \\([0, \\infty)\\) for ease of exposition. A countable collection of points on \\([0, \\infty)\\) can be imagined as marking off the times - starting the clock at \\(0\\) - that certain random events of similar nature occur; for example, arrival time of buses in a bus-stop, or calls in a telephone exchange, or perhaps decay of a particle (we shall stick to the second analogy for its relative simplicity and antiquity). In such an experiment we have various arrival times \\(0 = S_0 \\leq S_1 \\leq S_2 \\leq S_3 \\leq \\cdots\\) for the phone calls. Let us denote the consecutive differences \\(X_i = S_i - S_{i-1}\\), \\(i \\in \\Bbb N\\) to be the interarrival times between the \\((i-1)\\)-th and the \\(i\\)-th phonecalls. Motivated from statistical and physical models, we shall assume that the interarrival times are identically and independently distributed exponential variables, i.e., \\(X_1, X_2, \\cdots \\stackrel{\\mathrm{iid}}{\\sim} \\mathrm{Exp}(\\alpha)\\). This describes our point process completely; it is a random configuration of countably many points in \\([0, \\infty)\\) including \\(0\\) such that the spacing between two consecutive points is exponential with parameter \\(\\alpha\\). We call this the homogeneous Poisson point process \\(\\wp_\\alpha\\) on \\([0, \\infty)\\) with intensity \\(\\alpha\\). But we would like to put this in the context of our discussion earlier involving the kernel of a point process. So let us start off by denoting \\(N_t = \\max\\{n \\geq 0 : S_n \\leq t\\}\\) to be the number of phonecalls that arrive upto time \\(t\\). This is the number of points of \\(\\wp_\\alpha\\) in \\([0, t]\\) in our language from earlier. Note that \\(N_t\\) is apriori a \\(\\Bbb N_0 \\cup \\{\\infty\\}\\)-valued random variable for every \\(t \\geq 0\\). Observe: \\[\\displaystyle \\Bbb P(N_t = n) = \\Bbb P(S_n \\leq t &lt; S_{n+1}) = \\Bbb P(S_n \\leq t) - \\Bbb P(S_{n+1} \\leq t)\\] Remember that \\(S_m = X_1 + \\cdots + X_m\\) where \\(X_i\\) are i.i.d. exponential with parameter \\(\\alpha\\). Thus, \\(S_m \\sim \\mathrm{Gamma}(m, \\alpha)\\). Plugging the cdf of the Gamma distribution in the expression above, we obtain for any \\(n \\in \\Bbb N_0\\), \\[\\displaystyle \\begin{aligned}\\Bbb P(N_t = n) &amp;= \\int_{0}^t \\frac{\\alpha^n}{(n-1)!} s^{n-1} e^{-\\alpha s} ds - \\int_{0}^t \\frac{\\alpha^{n+1}}{n!} s^n e^{-\\alpha s} ds \\\\ &amp;= \\frac{\\alpha^n}{n!} e^{-\\alpha t} t^n = \\frac{(\\alpha t)^n}{n!} e^{-\\alpha t}\\end{aligned}\\] Using a simple application of integration by parts on the first integral, writing \\(s^{n-1} ds = d(s^n)/n\\). Thus, we obtain \\(\\Bbb P(N_t &lt; \\infty) = \\sum_{n \\in \\Bbb N_0} \\Bbb P(N_t = n) = 1\\), hence \\(N_t\\) can be treated as a \\(\\Bbb N_0\\)-valued random variable, in which case \\(N_t \\sim \\mathrm{Poi}(\\alpha t)\\) for all \\(t &gt; 0\\) by comparing pmf’s. In the case \\(t = 0\\), we simply have \\(N_0 \\equiv 0\\). Next, we would like to compute more generally the number of phone calls that arrive in a specific time-interval \\(I \\subset [0, \\infty)\\), that is to say, the number of points of the point process \\(\\wp_\\alpha\\) in \\(I\\). To proceed, fix \\(t_0 &gt; 0\\) and consider the interval \\(I = [t_0, t_0 + t]\\). Then the number of interest is \\(\\widetilde{N}_t := N_{t_0 + t} - N_{t_0}\\). Taking cue from the telephone exchange analogy, we set up the whole process again, but starting our clock at time \\(t_0\\). That is to say, suppose the telephone operator slept through their alarm and arrives at the telephone exchange office late. They hurriedly start jotting down the arrival times of the calls after time \\(t_0\\), which would then be \\[t_0 \\leq S_{N_{t_0}+1} \\leq S_{N_{t_0}+2} \\leq \\cdots\\] The relevant interarrival times are then given by \\(\\widetilde{X}_i = S_{N_{t_0} + i} - S_{N_{t_0} + i-1} = X_{N_{t_0} + i}\\) for all \\(i \\geq 2\\) and \\(\\widetilde{X}_1 = S_{N_{t_0} + 1} - t_0\\). Define \\(\\widetilde{S}_n = \\widetilde{X}_1 + \\cdots + \\widetilde{X}_n\\) and \\(\\widetilde{S}_0 \\equiv 0\\). What we have done is simply the following: we have chopped off the original Poisson process on \\([0, \\infty)\\) at time \\(t_0\\) and translated \\([t_0, \\infty)\\) back to \\([0, \\infty)\\) to define a new point process, by using the random configuration of countably many points that appear after \\(t_0\\). It turns out that this is also a Poisson process with intensity \\(\\alpha\\)! To see this, all we have to do is to prove \\(\\widetilde{X}_1, \\widetilde{X}_2, \\widetilde{X}_3, \\cdots \\stackrel{\\mathrm{iid}}{\\sim} \\mathrm{Exp}(\\alpha)\\). Observe, \\[\\displaystyle \\begin{aligned}&amp; \\Bbb P(\\widetilde{X}_1 &gt; x_1, \\cdots, \\widetilde{X}_k &gt; x_k, N_{t_0} = n) \\\\ &amp;= \\Bbb P(S_{n+1} &gt; t_0 + x_1, X_{n+2} &gt; x_2, \\cdots, X_{n+k} &gt; x_k, S_n \\leq t_0 &lt; S_{n+1}) \\\\ &amp;= \\Bbb P(S_n \\leq t_0, S_{n+1} &gt; t_0 + x_1, X_{n+2} &gt; x_2, \\cdots, X_{n+k} &gt; x_k) \\\\ &amp;= \\Bbb P(S_n \\leq t_0, S_{n+1} &gt; t_0 + x_1) \\Bbb P(X_{n+2} &gt; x_2, \\cdots, X_{n+k} &gt; x_k) \\end{aligned}\\] where in the last equality we used \\((S_n, S_{n+1}) \\perp \\!\\!\\! \\perp (X_{n+2}, \\cdots, X_{n+k})\\). A long calculation involving the law of conditional probability ensues: \\[\\displaystyle \\begin{aligned}\\Bbb P(S_n \\leq t_0, S_{n+1} &gt; t_0 + x_1) &amp;= \\Bbb P(S_n \\leq t_0, X_{n+1} &gt; t_0 + x_1 - S_n) \\\\ &amp;= \\int_0^{t_0} \\Bbb P(X_{n+1} &gt; t_0 + x_1 - u \\vert S_n = u) f_{S_n}(u) du \\\\ &amp;= \\int_0^{t_0} \\Bbb P(X_{n+1} &gt; t_0 + x_1 - u) f_{S_n}(u) du \\\\ &amp;= \\int_0^{t_0} e^{-\\alpha(t_0 + x_1 - u)} f_{S_n}(u) du \\\\ &amp; = e^{-\\alpha x_1} \\int_0^{t_0} e^{-\\alpha(t_0 - u)} f_{S_n}(u) du \\\\ &amp;= \\Bbb P(X_{n+1}&gt; x_1) \\int_0^{t_0} \\Bbb P(X_{n+1} &gt; t_0 - u) f_{S_n}(u) du \\\\ &amp;= \\Bbb P(X_{n+1} &gt; x_1) \\int_0^{t_0} \\Bbb P(X_{n+1} &gt; t_0 - u\\vert S_n = u) f_{S_n}(u) du \\\\ &amp;= \\Bbb P(X_{n+1} &gt; x_1) \\Bbb P(S_n \\leq t_0, X_{n+1} &gt; t_0 - S_n) \\\\ &amp;= \\Bbb P(X_{n+1} &gt; x_1) \\Bbb P(S_n \\leq t_0, S_{n+1} &gt; t_0) \\\\ &amp;= \\Bbb P(X_{n+1} &gt; x_1) \\Bbb P(N_{t_0} = n)\\end{aligned}\\] Substituting this back in the earlier equation, we obtain: \\[\\displaystyle \\Bbb P(\\widetilde{X}_1 \\!&gt;\\! x_1, \\cdots, \\widetilde{X}_k\\! &gt;\\! x_k, N_{t_0} \\!=\\! n) = \\Bbb P(X_{n+1}\\! &gt;\\! x_1) \\cdots \\Bbb P(X_{n+k}\\! &gt;\\! x_k) \\Bbb P(N_{t_0} \\!=\\! n)\\] This is of course expected, because the identity here expresses the fact that in probability the new Poisson process is obtained from shifting the old Poisson process back by time \\(t_0\\). Note that this not only proves that the variables \\(\\widetilde{X}_i\\) are i.i.d. exponential with parameter \\(\\alpha\\) (replace the variables \\(X_{n+i}\\) on the right hand side of the identity by the equally distributed exponential variables \\(X_i\\), and sum over \\(n\\)), but also that \\((\\widetilde{X}_1, \\widetilde{X}_2, \\cdots) \\perp \\!\\!\\!\\perp N_{t_0}\\). The new Poisson process has forgotten how many calls arrived before time \\(t_0\\). This is the most rudimentary form of Markov property of stochastic processes. Observe now that \\(\\widetilde{N}_t = \\max\\{n \\geq 0 : \\widetilde{S}_n \\leq t\\}\\) is just the number of phonecalls which arrived before time \\(t\\) in the new chopped off Poisson process with intensity \\(\\alpha\\), so of course, \\(\\widetilde{N}_t \\sim \\mathrm{Poi}(\\alpha t)\\) as well. This proves that the number of points of \\(\\wp_\\alpha\\) in \\(I \\subset [0, \\infty)\\) follows the Poisson distribution with parameter \\(\\alpha \\vert I\\vert\\), i.e., \\(\\wp_\\alpha(I) \\sim \\mathrm{Poi}(\\alpha \\vert I\\vert )\\). Therefore, we also have that the intensity measure induced by \\(\\rho_\\alpha\\) on \\([0, \\infty)\\) is the Lebesgue measure scaled by \\(\\alpha\\). The fact that \\(N_t \\perp \\!\\!\\! \\perp N_{t + s} - N_t\\) for any \\(t, s \\geq 0\\) indicates in general that if \\(0 \\leq t_1 \\leq t_2 \\leq \\cdots \\leq t_k\\) then \\(N_{t_1}, N_{t_2 - t_1}, \\cdots, N_{t_k - t_{k-1}}\\) are independent random variables, which is to say, if \\(I_1, I_2, \\cdots, I_k \\subset \\Bbb R\\) are pairwise disjoint intervals then \\(\\wp_\\alpha(I_1), \\cdots, \\wp_\\alpha(I_k)\\) are independent random variables. In general let \\((\\Bbb{X}, \\mathcal{X})\\) be a measurable space and \\(\\lambda\\) be a \\(\\sigma\\)-finite measure on \\(\\Bbb{X}\\). We define a (inhomogeneous) Poisson point process \\(\\wp_\\lambda\\) with intensity measure \\(\\lambda\\) to be a point process such that \\(B \\in \\mathcal{X}\\), \\(\\wp_\\lambda(B) \\sim \\mathrm{Poi}(\\lambda(B))\\) and for every collection \\(B_1, \\cdots, B_n \\in \\mathcal{X}\\) of pairwise disjoint sets, \\(\\wp_\\lambda(B_1), \\cdots, \\wp_\\lambda(B_n)\\) are independent random variables. We have constructed such a process on \\([0, \\infty)\\). It is worthwhile to note that in this case the full package of the Poisson process can be presented as just the stochastic process \\(\\{N_t\\}_{t \\in [0, \\infty)}\\) given by the number of phonecalls upto time \\(t\\), because of linearity of the underlying space; namely, \\(\\wp_\\alpha([a, b]) = N_b - N_a\\) for any interval \\([a, b] \\subset \\Bbb R\\), so it suffices to specify the variables \\(N_t\\) for all \\(t \\geq 0\\) to recover the whole point process. \\(\\{N_t\\}_{t \\in [0, \\infty)}\\) is a continuous-time stochastic process with independent Poisson increments, which are precisely what the two properties in the definition of a general Poisson process above are trying to capture. In the next post we shall construct a Poisson process on any measurable space with a given \\(\\sigma\\)-finite measure. Finally, let us close this conversation with a few words on the Markov property. We view the homogeneous Poisson process with intensity \\(\\alpha\\) on \\([0, \\infty)\\) as a random collection of countably many points on \\([0, \\infty)\\) as before in the telephone exchange model. We claim that for any fixed \\(n \\geq 1\\), the joint distribution \\((S_1, \\cdots, S_n)\\vert S_{n+1} = s\\) of the first \\(n\\) points given the knowledge of the \\((n+1)\\)-th point has the same distribution as the order statistics vector \\((U_{(1)}, \\cdots, U_{(n)})\\) of a sample \\(U_1, \\cdots, U_n \\stackrel{\\mathrm{iid}}{\\sim} \\mathrm{Unif}(0, s)\\) of \\(n\\) uniform points. To prove this, define a linear transformation \\(T(x_1, \\cdots, x_{n+1}) = (x_1, x_1+x_2, \\cdots, x_1+\\cdots+x_{n+1})\\) for all \\(\\mathbf{x} \\in (0, \\infty)^{n+1}\\). This has range \\(\\{\\mathbf{s} \\in \\Bbb R^n : 0 &lt; s_1 &lt; \\cdots &lt; s_{n+1}\\}\\) and is invertible on the range, with inverse given by \\(T^{-1}(s_1, \\cdots, s_{n+1}) = (s_1, s_2 - s_1, \\cdots, s_{n+1} - s_n)\\). Clearly \\(\\det(T) = 1\\) as the matrix of \\(T\\) is upper triangular with \\(1\\)’s along the diagonal. By the change of density formula, \\[\\displaystyle \\begin{aligned}f_{S_1, \\cdots, S_{n+1}}(s_1, s_2, \\cdots, s_{n+1}) &amp; = f_{X_1, \\cdots, X_{n+1}}(s_1, s_2 - s_1, \\cdots, s_{n+1} - s_n) \\\\ &amp;= \\lambda e^{-\\lambda s_1} \\lambda e^{-\\lambda (s_2 - s_1)} \\cdots \\lambda e^{-\\lambda (s_{n+1} - s_n)} \\mathbf{1}_{(0 &lt; s_1 &lt; \\cdots &lt; s_{n+1})} \\\\ &amp;= \\lambda^{n+1}e^{-\\lambda s_{n+1}} \\mathbf{1}_{(0 &lt; s_1 &lt; \\cdots &lt; s_{n+1})} \\end{aligned}\\] \\(S_{n+1}\\) is distributed as \\(\\text{Gamma}(n+1, \\lambda)\\), hence \\(f_{S_{n+1}}(s) = \\lambda^{n+1} s^n e^{-\\lambda s}/n! \\cdot \\mathbf{1}_{(s &gt; 0)}\\), so the conditional pdf of the conditional distribution \\((S_1, \\cdots, S_n)\\vert S_{n+1} = s\\) is given by \\[\\displaystyle \\begin{aligned} f_{S_1 \\cdots S_n \\vert S_{n+1}}(s_1, \\cdots, s_n \\vert s) = \\frac{f_{S_1, \\cdots, S_{n+1}}(s_1, \\cdots, s_n, s)}{f_{S_{n+1}}(s)} &amp; = \\frac{\\lambda^{n+1} e^{-\\lambda s}}{\\lambda^{n+1}s^ne^{-\\lambda s}/n!} \\mathbf{1}_{(0&lt;s_1&lt;\\cdots&lt;s_n&lt;s)} \\\\ &amp;= n! \\left (\\frac{1}{s}\\right )^n \\mathbf{1}_{0&lt;s_1&lt;\\cdots&lt;s_n&lt;s} \\end{aligned}\\] which is precisely the pdf of \\((U_{(1)}, \\cdots, U_{(n)})\\), as promised. One way to interpret this is to say that the knowledge of the position of the \\((n+1)\\)-th point in the configuration gives no insight into the position of the points before, except their relative order, and we have already seen before that restarting the clock at time \\(S_{n+1}\\) completely reboots the Poisson process.",
      "categories": [],
      "tags": ["measure-theory","poisson-process"]
    },
  
    {
      "title": "Brownian Motions: I",
      "url": "/2020/06/19/brownian-motions-i/",
      "date": "2020-06-19",
      "content": "This will be part of (hopefully) a series of notes I will write down whilst preparing for some informal talks in a study group, in the process of understanding Brownian motions. I am reading mainly from Robert Haslhofer’s course notes available here, although I might occasionally use other resources, most notably perhaps Durrett’s “Probability: Theory and Examples”. Be warned that I have a less than adequate understanding of probability and I might make many mistakes and have fundamental misunderstandings; these notes are written mostly for personal bookkeeping purposes. Acknowledgement goes to Ritvik Radhakrishnan and Bhaswar Bhattacharya for going through this with me and pointing out several errors and typos. A real-valued continuous time stochastic process is a measurable function \\(X : \\Omega \\times [0, \\infty) \\to \\Bbb R\\) for some probability space \\((\\Omega, \\mathcal{A}, \\Bbb {P})\\), which we think of as a family of random variables \\(\\{X_t\\}_{t \\geq 0}\\) defined on this probability space. Such a process \\(B : \\Omega \\times [0, \\infty) \\to \\Bbb R\\) is a Brownian motion starting at \\(x_0 \\in \\Bbb R\\) if \\(B_0 = x_0\\), the process has independent increments, i.e., for \\(0 \\leq t_1 &lt; \\cdots &lt; t_k\\) the increments \\(B_{t_2} - B_{t_1}, \\cdots, B_{t_k} - B_{t_{k-1}}\\) are independent random variables and moreover the increments have a Gaussian law: \\(B_{t + h} - B_t \\sim N(0, h)\\) for any \\(t \\geq 0\\), \\(h &gt; 0\\). Finally, we demand that the process is sample-continuous, that is, the event \\(\\{\\omega \\in \\Omega : t \\mapsto B_t(\\omega) \\text{ is continuous}\\} \\subset \\Omega\\) contains an \\(\\mathcal{A}\\)-measurable subset of probability \\(1\\). I will devote the post to establishing existence of Brownian motions. A particularly appealing approach is to try to construct a Brownian motion as a random ray on \\(\\Bbb R\\). To set it up, let us denote \\(C[0, \\infty)\\) as the space of continuous maps \\(\\gamma : [0, \\infty) \\to \\Bbb R\\), and \\(C_0\\) be the subspace of all such maps \\(\\gamma\\) such that \\(\\gamma(0) = 0\\). We equip this space with the compact-open topology, and let \\(\\mathcal{B}(C_0)\\) denote the Borel \\(\\sigma\\)-algebra. We would like the Brownian motion to be a random variable \\(B : (\\Omega, \\mathcal{A}, \\Bbb P) \\to (C_0, \\mathcal{B}(C_0))\\) valued in this space. We can switch perspectives by trying to construct the pushforward measure \\(\\mu_B := B_* \\Bbb P\\) instead, at which point the Brownian motion will be the random variable defined on the probability space \\((C_0, \\mathcal{B}(C_0), \\mu_B)\\) tautologically by \\(B : (C_0, \\mathcal{B}(C_0), \\mu_B) \\to (C_0, \\mathcal{B}(C_0))\\) with \\(B(\\gamma) = \\gamma\\). We start by considering open subsets of \\(C_0\\) of the following form: Let \\(0 &lt; t_1 &lt; \\cdots &lt; t_k\\) be a finite sequence of times and \\(U_1, \\cdots, U_k \\subset \\Bbb R\\) be open subsets. Define \\[V(t_1, \\cdots, t_k, U_1, \\cdots, U_k) = \\{\\gamma \\in C_0 : \\gamma(t_i) \\in U_i \\; \\forall\\, 1 \\leq i \\leq k\\}\\] Let \\(p_t(x, y) := \\exp(-(x-y)^2/2t)/\\sqrt{2\\pi t}\\) denote the density of the normal distribution \\(N(x, t)\\) at \\(y\\). We define: \\[\\displaystyle \\mu_B(V(t_1, \\cdots, t_k, U_1, \\cdots, U_k)) = \\int_{U_1 \\times \\cdots \\times U_k} p_{t_1}(0, x_1) \\cdots p_{t_k - t_{k-1}}(x_{k-1}, x_k) dx_1 \\cdots dx_k\\] One would expect this to be sufficient information to define a probability measure \\(\\mu_B\\) on the full measure space \\((C_0, \\mathcal{B}(C_0))\\). We shall quote the following theorem in order to proceed: Theorem. (Kolmogorov extension theorem) Let \\((X_i, \\mathcal{B}_i)\\) be a family of Borel measure spaces on Polish spaces indexed by \\(i \\in I\\) an arbitrary indexing set. For any subset \\(J \\subseteq I\\) let us denote \\(X_J = \\prod_{j \\in J} X_j\\) and \\(\\mathcal{B}_J = \\bigotimes_{j \\in J} \\mathcal{B}_j\\) be the corresponding product \\(\\sigma\\)-algebra. Let \\(\\mu_J\\) be a family of probability measures on the measure spaces \\((X_J, \\mathcal{B}_J)\\) for every finite subset \\(J \\subset I\\) which are Kolmogorov consistent, i.e., for any pair of finite subsets \\(J_1 \\subset J_2\\) of \\(I\\), and any measurable set \\(A \\in \\mathcal{B}_{J_1}\\), \\(\\mu_{J_2}(\\pi_{J_2, J_1}^{-1}(A)) = \\mu_{J_1}(A)\\). Then there exists a unique probability measure on \\((X_I, \\mathcal{B}_I)\\) which is consistent with the family of measures \\(\\{\\mu_J\\}_{J \\subset I}\\), i.e., for any finite subset \\(J \\subset I\\), and any measurable set \\(A \\in \\mathcal{B}_I\\), \\(\\mu(\\pi_J^{-1}(A)) = \\mu_J(A)\\). Let us thus enlarge our probability space to \\(\\Bbb R^{[0, \\infty)}\\) equipped with the product \\(\\sigma\\)-algebra \\(\\mathcal{B}_{\\Bbb R}^{[0, \\infty)}\\). For any finite subset \\(J = \\{t_1 &lt; t_2 &lt; \\cdots &lt; t_k\\} \\subset [0, \\infty)\\), our definition for \\(\\mu_B\\) provides us with a Kolmogorov consistent family of measures \\(\\mu_J\\) on \\((\\Bbb R^J, \\mathcal{B}^{\\otimes J})\\). Thus, we obtain a measure \\(\\mu_B\\) on \\((\\Bbb R^{[0, \\infty)}, \\mathcal{B}_{\\Bbb R}^{[0, \\infty)})\\). Unfortunately, we run into a problem. \\(C_0 \\subset \\Bbb R^{[0, \\infty)}\\) does not happen to be a measurable set in the product \\(\\sigma\\)-algebra. This is simple enough to see: the product \\(\\sigma\\)-algebra \\(\\mathcal{B}_{\\Bbb R}^{[0, \\infty)}\\) is generated by finite cylinder events \\[\\prod_{f \\in F} U_f \\times \\prod_{i \\notin F} \\Bbb R \\subset \\Bbb R^{[0, \\infty)}\\] where \\(F \\subset [0, \\infty)\\) is finite and \\(U_F \\subset \\Bbb R\\) are Borel. Under countable union of such events, we can form the countable cylinder events \\(\\prod_{d \\in D} U_d \\times \\prod_{i \\notin D} \\Bbb R\\) where \\(D \\subset [0, \\infty)\\) is countable. These are clearly closed under further countable unions and complementation, and thus generates a \\(\\sigma\\)-algebra. Hence, these must be all the possible events appearing in the \\(\\sigma\\)-algebra \\(\\mathcal{B}_{\\Bbb R}^{[0, \\infty)}\\). Thus, such events must depend only on countably many time coordinates, which \\(C_0\\) clearly does not — if continuity of a path was definable by simply looking at countably many points on the path, we would be in trouble! There is a fairly straightforward analytic fix for this. We switch our point of view to random variables instead of measures once again: So far we have successfully defined a stochastic process \\[\\begin{gather*}B : (\\Bbb R^{[0, \\infty)}, \\mathcal{B}_{\\Bbb R}^{[0, \\infty)}, \\mu_B) \\times [0, \\infty) \\to \\Bbb R \\\\ B(\\gamma, t) = \\gamma(t)\\end{gather*}\\] It is moreover clear from construction that \\(B\\) satisfies all the axioms of a Brownian motion except sample-continuity, by the fact that \\(\\mu_B\\) agrees with an independent vector of normal distributions with variance equal to time-increment on finite cylinder events, which is equivalent to the finite-dimensional distributions of \\(B\\) to be equal in distribution to the Gaussian distribution: \\[(B_{t_1}, \\cdots, B_{t_k}) \\sim N(\\mathbf{0}_k, \\text{diag}(t_1, t_2 - t_1, \\cdots, t_k - t_{k-1}))\\] We shall modify this process to be sample-continuous by appealing once again to Kolmogorov: Theorem. (Kolmogorov continuity theorem) Let \\(X : (\\Omega, \\mathcal{A}, \\Bbb P) \\times [0, \\infty) \\to \\Bbb R\\) be a stochastic process. Assume there exists constant \\(\\alpha, \\beta, C &gt; 0\\) such that \\[\\displaystyle \\Bbb E\\vert X_s - X_t\\vert ^\\beta \\leq C \\vert s - t\\vert ^{1 + \\alpha}\\;\\; \\forall \\; s, t &gt; 0\\] Then there exists a stochastic process \\(Y : (\\Omega, \\mathcal{A}, \\Bbb P) \\times [0, \\infty) \\to \\Bbb R\\) such that \\(\\Bbb P(X_t = Y_t) = 1\\) for all \\(t \\geq 0\\) such that for any \\(\\gamma &lt; \\alpha/\\beta\\), the sample paths of \\(Y\\) are locally \\(\\gamma\\)-Holder continuous with probability \\(1\\). In particular, \\(Y\\) is sample-continuous. Proof. Let us define the sets \\(A_n = \\{\\vert X_{i/2^n} - X_{(i-1)/2^n}\\vert \\leq 1/2^{n \\gamma} \\; \\forall\\; 0 &lt; i \\leq 2^n \\}\\). Further, define \\(B_N = \\bigcap_{n \\geq N} A_n\\); it is an easy exercise to check that for any pair of diadic rationals \\(s, t\\) such that \\(\\vert s - t\\vert \\leq 1/2^N\\), there exists a constant \\(K = K(\\gamma)\\) depending only on \\(\\gamma\\) such that on $B_N$, \\[\\vert X_s - X_t\\vert \\leq K \\vert s - t\\vert ^\\gamma\\] Notice that \\(\\Bbb P(\\vert X_{i/2^n} - X_{(i-1)/2^n}\\vert &gt; 1/2^{n\\gamma}) \\leq \\Bbb E \\vert X_{i/2^n} - X_{(i-1)}/2^n\\vert ^{\\beta} \\cdot 2^{n \\beta \\gamma}\\) by Markov inequality applied to \\(\\beta\\)-th exponent. Thus, \\[\\displaystyle \\begin{aligned}\\Bbb P(A_n^c) \\leq \\sum_{1 \\leq i \\leq 2^n} P(\\vert X_{i/2^n} - X_{(i-1)/2^n}\\vert &gt; 1/2^{n\\gamma}) &amp; \\leq 2^{n(1+\\beta\\gamma)} \\Bbb E\\vert X_{i/2^n} - X_{(i-1)/2^n}\\vert ^\\beta \\\\ &amp;\\leq C 2^{n(1+\\beta \\gamma)} 2^{-n(1+\\alpha)} = C 2^{-n\\lambda}\\end{aligned}\\] where \\(\\lambda = \\alpha - \\beta \\gamma &gt; 0\\), using the hypothesis on the \\(\\beta\\)-th moments of \\(X\\) and choice of \\(\\gamma &lt; \\alpha/\\beta\\). Thus, \\(\\Bbb P(B_N^c) \\leq \\sum_{n \\geq N} P(A_n^c) = C 2^{-N \\gamma}/(1 - 2^{-\\gamma})\\). Since \\(\\sum_{N \\geq 1} \\Bbb P(B_N^c) &lt; \\infty\\), by the Borel-Cantelli lemma the probability that infinitely many events \\(B_N^c, N = N(\\omega) \\geq 1\\) occur is zero. In particular, for almost every \\(\\omega \\in \\Omega\\), there exists \\(N = N(\\omega) \\geq 1\\) such that \\(\\omega \\in B_N\\). Thus, for almost every sample path of \\(X\\), there exists \\(\\delta = \\delta(\\omega) &gt; 0\\) such that \\(\\vert X_t - X_s\\vert \\leq C \\vert t - s\\vert ^\\gamma\\) holds true whenever \\(s, t\\) are diadic rationals such that \\(\\vert s - t\\vert \\leq \\delta\\): take \\(\\delta = 2^{-N}\\). Finally define the modification \\(Y\\) of \\(X\\) by setting \\(Y_t = X_t\\) if \\(t &gt; 0\\) is a diadic rational, otherwise find a sequence \\(\\{t_n\\}\\) of diadic rationals and define \\(Y_t = \\lim_n X_{t_n}\\) pointwise. This is well-defined since the sample paths \\(t \\mapsto X_t\\) are almost surely continuous on the diadic rationals, which is a dense subset of \\([0, \\infty)\\), hence has a continuous extension to \\([0, \\infty)\\). It remains to be seen that \\(\\Bbb P(X_t = Y_t) = 1\\) for a non-diadic rational \\(t &gt; 0\\). For any \\(\\varepsilon &gt; 0\\), observe \\[\\Bbb P(\\vert X_t - X_{t_n}\\vert &gt; \\varepsilon) \\leq \\Bbb E\\vert X_t - X_{t_n}\\vert ^\\beta/\\varepsilon^\\beta \\leq C/\\varepsilon^\\beta \\cdot \\vert t - t_n\\vert ^{1+\\alpha}\\] Thus, \\(\\{X_{t_n}\\}\\) converges in probability to \\(X_t\\). Since the pointwise limit of this sequence in \\(Y_t\\), we are forced to have \\(X_t = Y_t\\) almost everywhere. This fully establishes the theorem. Finally, observe that the process \\(B : \\Omega \\times [0, \\infty) \\to \\Bbb R\\) we constructed earlier has the property in the hypothesis with \\(\\alpha = 1, \\beta = 4\\) since \\(B_t - B_s \\sim N(0, \\vert t - s\\vert )\\) for all \\(t, s &gt; 0\\), hence has fourth moment proportional to \\(\\vert t - s\\vert ^2\\). Thus, using Kolmogorov’s continuity theorem, we can modify \\(B\\) to be a sample-continuous process. This concludes the construction of a 1-dimensional Brownian motion.",
      "categories": [],
      "tags": ["brownian-motion","measure-theory","random-walk"]
    },
  
    {
      "title": "Jacobi fields: Part II",
      "url": "/2020/05/05/jacobi-fields-part-ii/",
      "date": "2020-05-05",
      "content": "In the previous post we solved the Jacobi equation explicitly for Riemannian 2-manifolds of constant curvature and saw how the norm of the Jacobi field behaves over time depending on the curvature. We also understood what our results say about the deviation of geodesics on the manifold. Here we shall do some general estimations to unearth the precise relation between these quantities. Let \\((M, g)\\) be a Riemannian manifold and \\(\\gamma : [0, c] \\to M\\) a geodesic starting at \\(\\gamma(0) = p\\) with \\(\\gamma'(0) = v\\). Let \\(J\\) be a Jacobi field along \\(\\gamma\\) with initial conditions \\(J(0) = 0\\), \\(J'(0) = w\\) for some vector \\(w \\in T_v T_p M\\). Define \\(f : [0, c] \\to \\Bbb R\\) to be \\[f(t) = g(J(t), J(t)) = \\|J(t)\\|^2\\] We shall compute the Taylor expansion of \\(f\\) near \\(0\\). Let us use the shorthand \\(J' = \\nabla_{\\gamma'} J\\) for ease of notation. Clearly, we have \\(f(0) = 0\\), \\(f'(0) = 2 g(J(0), J'(0)) = 0\\), and since \\(J(0) = 0\\), we have \\[f''(0) = 2 g(J'(0), J'(0)) + 2 g(J(0), J''(0)) = 2 \\|w\\|^2\\] For the higher order terms we recall the Jacobi equation: \\[J'' + R(J, \\gamma')\\gamma' = 0\\] We find \\(f'''(0) = 6g(J''(0), J'(0)) + 2g(J(0), J'''(0))\\). By the above, \\(J''(0) = -R(J(0), v)v = 0\\). So, we obtain \\(f'''(0) = 0\\) as well. Finally, \\[f^{\\mathrm{IV}}(0) = 8 g(J'''(0), J'(0)) + 6 g(J''(0), J''(0)) + 2 g(J(0), J^{\\mathrm{IV}}(0))\\] Note that \\(J''' = - \\nabla_{\\gamma'} R(J, \\gamma')\\gamma'\\). Recall the following symmetry of the Riemann curvature tensor: \\[g(R(U, V)Z, W) = g(R(Z, W)U, V) = -g(R(V, U)Z, W)\\] Let $X$ be an auxiliary vector field. Then we get: \\[\\displaystyle \\begin{aligned} g(\\nabla_{\\gamma'} R(J, \\gamma') \\gamma', X) &amp; = \\gamma' g(R(J, \\gamma') \\gamma', X) - g(R(J, \\gamma') \\gamma', \\nabla_{\\gamma'} X) \\\\ &amp; = -\\gamma' g(R(\\gamma', X) \\gamma', J) - g(R(J, \\gamma') \\gamma', \\nabla_{\\gamma'} X) \\\\ &amp; = - g(\\nabla_{\\gamma'} R(\\gamma', X)\\gamma', J) - g(R(\\gamma', X)\\gamma', J') - g(R(J, \\gamma') \\gamma', \\nabla_{\\gamma'} X)\\end{aligned}\\] Evaluating this expression at \\(t = 0\\), we see using \\(J(0) = 0\\) that the first and third term vanishes. Thus, \\[g(\\nabla_{\\gamma'} R(J, \\gamma') \\gamma', X) = g(-R(\\gamma', J') \\gamma', X)\\] for all \\(X\\). In particular, pluggin \\(X = \\gamma'\\), we obtain \\[\\nabla_{\\gamma'} R(J, \\gamma') \\gamma' = -R(\\gamma', J')\\gamma'\\] So we get \\(J'''(0) = R(v, w)v\\), and plugging this in we therefore obtain \\(f^{\\mathrm{IV}}(0) = 8 g(R(v, w)v, w)\\). Now, the sectional curvature of the 2-plane \\(\\sigma \\subset T_p M\\) spanned by \\(v\\) and \\(w\\) is \\[K_p(\\sigma) = \\frac{g(R(v, w)w, v)}{\\|v\\|^2 \\|w\\|^2 - g_p(v, w)},\\] and \\(\\|v\\|^2 \\|w\\|^2 - g_p(v, w) = \\mathrm{Area}(\\sigma)^2\\) so \\(f^{\\mathrm{IV}}(0) = - 8 K_p(\\sigma) \\mathrm{Area}(\\sigma)^2\\). With all the derivatives at hand, we do a fourth order Taylor expansion of \\(f\\) around the origin to obtain: \\[\\displaystyle \\begin{aligned} &amp; f(t) = f(0) + f'(0) t + f''(0) \\frac{t^2}{2!} + f'''(0) \\frac{t^3}{3!} + f^{\\mathrm{IV}}(0) \\frac{t^4}{4!} + o(t^5) \\\\ \\implies &amp; \\|J(t)\\|^2 = \\|w\\|^2 t^2 - \\frac{K_p(\\sigma) \\mathrm{Area}(\\sigma)^2}{3} t^4 + O(t^5) \\\\ \\implies &amp; \\|J(t)\\| = \\|w\\| t - \\frac{K_p(\\sigma) \\mathrm{Area}(\\sigma)^2}{6 \\|w\\|} t^3 + O(t^4) \\end{aligned}\\] We can interpret the linear term as the growth of the Jacobi field along the ray passing through \\(0\\) in the direction of \\(v\\) in the tangent space \\(T_p M\\), and the formula tells us that there’s a cubic error between the deviation of geodesics on \\(T_p M\\) and on \\(M\\) which depends on the sectional curvature \\(K_p(\\sigma)\\). A quick application of the ideas above gives a relatively deep result: Suppose \\(M\\) is a complete Riemannian manifold which is everywhere non-positively curved, i.e., for any point \\(p \\in M\\) and a 2-plane \\(\\sigma \\subset T_p M\\), \\(K_p(\\sigma) \\leq 0\\). If \\(\\gamma : [0, \\infty) \\to M\\) is a geodesic and \\(J\\) is a nontrivial Jacobi field along \\(\\gamma\\) with \\(J(0) = 0\\), the function \\(f(t) = \\|J(t)\\|^2\\) is convex: \\[\\begin{aligned} \\displaystyle f''(t) &amp;= 2 g(J', J') + 2 g(J'', J) \\\\ &amp;= 2\\|J'\\|^2 - 2g(R(J, \\gamma')\\gamma', J) \\\\ &amp;= 2\\|J'\\|^2 - 2 K_p(\\sigma) \\mathrm{Area}(\\sigma)^2 \\geq 0 \\end{aligned}\\] where \\(\\sigma\\) is the 2-plane spanned by \\(\\gamma'(t)\\) and \\(J(t)\\). Since sectional curvatures are nonpositive, this implies \\(f''(t) \\geq 0\\), hence \\(f\\) is convex, as required. Moreover as \\(J'(0) \\neq 0\\), \\(J' \\neq 0\\) in a neighborhood of \\(0\\), thus \\(f\\) is strictly convex in a neighborhood of \\(0\\). Since \\(f(0) = 0\\) and a convex non-negative function can never “climb down” to \\(0\\), we conclude \\(f(t) &gt; 0\\) for all \\(t \\in [0, \\infty)\\). Thus \\(J \\neq 0\\) throughout \\((0, \\infty)\\). This says there are no pairs of conjugate points in \\(M\\), which implies the exponential map \\(\\exp_p : T_p M \\to M\\) has no critical points, i.e., it’s a local diffeomorphism. If \\(K \\subset M\\) is a compact subset, then as \\(d_M(p, -)\\) is a continuous function on \\(M\\), it restricts to a continuous function on \\(K\\) hence attains a maximum value \\(m\\) on \\(K\\). Thus \\(K \\subseteq \\exp_p(B(0; m))\\), hence \\(\\exp_p^{-1}(K)\\) is a bounded closed subset of \\(T_p M\\). Thus, \\(\\exp_p\\) is a proper local diffeomorphism, hence a covering map. So we just proved every complete nonpositively curved Riemannian manifold \\(M\\) has universal cover diffeomorphic to \\(\\Bbb R^n\\). This fact, known as the Cartan-Hadamard theorem, is remarkable, because since \\(\\Bbb R^n\\) is contractible this means \\(M\\) is a \\(K(\\pi_1 M, 1)\\)-space, i.e., all the higher homotopy groups are trivial. Curvature constraints thus pose nontrivial restrictions on the topology! We shall prove a positive curvature analogue, but we would need to introduce a new quantity to state the theorem: Define for any two vector fields \\(X, Y\\) on \\(M\\) the bundle endomorphism \\[\\begin{gather*}R : TM \\to TM \\\\ R(Z) := R(Z, X)Y\\end{gather*}\\] The trace of \\(R\\) is defined to be the Ricci curvature which we denote as \\(\\mathrm{Ric}_p(X, Y) = \\text{tr}~ R_p\\). This is a pointwise defined quantity in the sense that \\(\\mathrm{Ric}_p(X, Y)\\) only depends on \\(X(p), Y(p)\\), which follows from the analogous property of the Riemann curvature tensor. If we choose an orthonormal basis \\(\\mathbf{e}_1, \\cdots, \\mathbf{e}_n\\) of \\(T_p M\\), then the matrix of \\(R\\) with respect to this basis is \\((g(R(X, \\mathbf{e}_i)Y, \\mathbf{e}_j))_{ij}\\). Therefore, \\[\\displaystyle \\begin{align*} \\mathrm{Ric}_p(X, Y) &amp;= \\sum_{i = 1}^n g(R(\\mathbf{e}_i, X)Y, \\mathbf{e}_i) \\\\ \\implies \\mathrm{Ric}_p(\\mathbf{e}_n, \\mathbf{e}_n) &amp;= \\sum_{i = 1}^{n-1} K_p(\\mathbf{e}_i, \\mathbf{e}_n) \\end{align*}\\] Here, \\(K_p(\\mathbf{e}_i, \\mathbf{e}_n)\\) is the sectional curvature corresponding to the 2-plane spanned by \\(\\mathbf{e}_i, \\mathbf{e}_n\\) in \\(T_p M\\), for \\(1 \\leq i \\leq n-1\\). Note there is one less term in the expression as the last term vanishes. Here is some motivation for the Ricci curvature. Choose normal coordinates \\((x^1, \\cdots, x^n)\\) around the point \\(p \\in M\\) by pushing forward Euclidean coordinates by the exponential map \\(\\exp_p : T_p M \\dashrightarrow M\\). Let \\((\\partial_1, \\cdots, \\partial_n)\\) be the induced frame on the normal neighborhood. We envision the metric \\(g\\) as a smoothly-varying assignment of symmetric matrices at every point on the normal neighborhood, with entries \\(g_{ij}(x) = g_x(\\partial_i, \\partial_j)\\). Let \\(\\mathbf{x} = (x_1, \\cdots, x_n)\\) be a point in the normal neighborhood and consider the radial geodesic \\(\\gamma : [0, 1] \\to M\\) defined by \\(\\gamma(t) = t \\mathbf{x}\\), and let \\(J\\) be a Jacobi field along \\(\\gamma\\). Along $\\gamma$, we write \\(J(t) = \\sum t J_i \\partial_i\\). Therefore, \\[\\|J(t)\\|^2 = t^2 \\sum_{i, j = 1}^n g_{ij}(t\\mathbf{x}) J_i J_j\\] We plug all of these in the Taylor’s expansion formula for norm of the Jacobi field derived above: \\[\\displaystyle \\sum_{i, j} g_{ij}(t\\mathbf{x}) J_i J_j t^2 = \\sum_{i, j} g_{ij}(0) J_i J_j t^2 - \\frac{g(R(\\gamma'(0), J'(0))J'(0), \\gamma'(0))}{3} t^4 + O(t^5)\\] Note that \\(\\gamma'(0) =\\sum_i \\partial_i\\) and \\(J'(0) =\\sum_i J_i \\partial_i\\). By multilinearity of the Riemann curvature tensor, we calculate: \\[\\displaystyle \\begin{aligned} g(R(\\gamma'(0), J'(0))J'(0), \\gamma'(0)) &amp;= g \\left ( R \\left ( \\sum_i \\partial_i, \\sum_j J_j \\partial_j \\right ) \\sum_k J_k \\partial_k, \\sum_l \\partial_l \\right ) \\\\ &amp;= \\sum_{i, j, k, l} g(R(\\partial_i, \\partial_j)\\partial_k, \\partial_l) J_j J_k \\end{aligned}\\] Let us denote \\(R_{ijkl} := g(R(\\partial_i, \\partial_j)\\partial_k, \\partial_l)\\), the coordinate form of the full curvature 4-tensor given by \\(R(X, Y, Z, W) = g(R(X, Y)Z, W)\\). We also note that \\(g_{ij}(0) = \\delta_{ij}\\) since we are working with normal coordinates. Plugging everything above, \\[\\displaystyle \\sum_{i, j} g_{ij}(t\\mathbf{x}) J_i J_j = \\sum_{i, j} \\delta_{ij} J_i J_j - \\frac{t^2}{3} \\sum_{i, j, k, l} R_{ijkl} J_j J_k + O(t^3)\\] Therefore the Taylor expansion for the metric \\(g\\) in the normal coordinates must be of the form (carefully note that we switched around some indices) \\[\\displaystyle g_{ij}(\\mathbf{x}) = \\delta_{ij} - \\frac{1}{3} \\sum_{k, l} R_{iklj} x_k x_l + O(\\|\\mathbf{x}\\|^3)\\] Recall the Riemannian volume form is given by \\(d\\mathrm{vol}_g = \\sqrt{\\det(g)} dx_1 \\wedge \\cdots \\wedge dx_n\\). The above also gives a Taylor expansion formula for the Riemannian volume form: \\[\\displaystyle \\begin{aligned} &amp; \\det(g(\\mathbf{x})) = 1 - \\frac13 \\sum_{k, l} \\mathrm{Ric}_p(\\partial_k, \\partial_l) x_k x_l + O(\\|\\mathbf{x}\\|^3) \\\\ \\implies &amp; d\\mathrm{vol}_g = \\left (1 - \\frac16 \\sum_{k, l} \\mathrm{Ric}_p(\\partial_k, \\partial_l) x_k x_l+ O(\\|\\mathbf{x}\\|^3) \\right ) dx_1 \\wedge \\cdots \\wedge dx_n\\end{aligned}\\] Where we used \\(\\mathrm{Ric}_p(\\partial_k, \\partial_l) = \\sum_i R_{ikli}\\). Thus the Ricci curvature measures the the quadratic defect in the volume form on \\(M\\) from the Euclidean volume form on the flat tangent space \\(T_p M\\). Suppose \\(M\\) is a complete Riemannian \\(n\\)-manifold and \\(\\gamma : [0, \\ell] \\to M\\) be an arclength parametrized minimizing geodesic with \\(\\gamma(0) = p\\) and \\(\\gamma(\\ell) = q\\). Let \\(\\mathbf{e}_1, \\cdots, \\mathbf{e}_n\\) be an orthonormal basis of parallel vector fields along \\(\\gamma\\), such that \\(\\mathbf{e}_n = \\gamma'\\). Define \\(X_i = \\sin(\\pi t/\\ell) \\mathbf{e}_i\\). Let \\(\\mathcal{E}\\) be the energy functional we defined earlier; from the second variation formula we compute \\[\\displaystyle \\begin{aligned} h\\mathcal{E}(\\gamma)(X_i, X_i) &amp; = -2 \\int_\\gamma g(\\nabla^2_{\\gamma'} X_i + R(X_i, \\gamma')\\gamma', X_i) \\\\ &amp; = 2 \\int_\\gamma \\sin^2(\\pi t/\\ell) (\\pi^2/\\ell^2 - K(\\mathbf{e}_i, \\mathbf{e}_n)) \\\\ \\implies \\sum_{i = 1}^{n-1} h\\mathcal{E}(\\gamma)(X_i, X_i) &amp; = 2\\int_\\gamma \\sin^2(\\pi t/\\ell) ((n-1)\\pi^2/\\ell^2 - \\mathrm{Ric}(\\mathbf{e}_n, \\mathbf{e}_n)) \\end{aligned}\\] Suppose \\(\\mathrm{Ric}(\\mathbf{e}_n, \\mathbf{e}_n) &gt; (n-1)\\pi^2/\\ell^2\\). Then at least one of the terms \\(h\\mathcal{E}(\\gamma)(X_i, X_i)\\) must be negative. Observe that since \\(\\gamma\\) is arclength parametrized, the energy of the path \\(\\mathcal{E}(\\gamma) = \\int_\\gamma \\|\\gamma'\\|^2 = \\ell\\) is exactly the arclength. Since \\(\\gamma\\) is a minimizing geodesic, \\(\\ell &lt; \\mathrm{length}(\\sigma)\\) for any other path \\(\\sigma\\) with \\(\\sigma(0) = p\\) and \\(\\sigma(\\ell) = q\\), and by Cauchy-Schwarz inequality, \\(\\mathrm{length}(\\sigma)^2 \\leq \\ell \\cdot \\mathcal{E}(\\sigma)\\). Combining we get \\(\\mathcal{E}(\\gamma) \\leq \\mathcal{E}(\\sigma)\\), therefore \\(\\gamma\\) is also an energy minimizer. This forces \\(h\\mathcal{E}(\\gamma)\\) to be positive semi-definite on \\(T_\\gamma \\Omega_{p, q}\\) by the “second-derivative test” (it’s easy to convince yourself that this continues to hold in our infinite dimensional context), which leads to a contradiction. Thus, \\(\\mathrm{Ric}(\\mathbf{e}_n, \\mathbf{e}_n) \\leq (n-1)\\pi^2/\\ell^2\\). In summary we have proved that if \\(M\\) is a complete Riemannian manifold of dimension \\(n\\) such that \\(\\mathrm{Ric} \\geq (n-1)/R^2\\) for some \\(R &gt; 0\\), then every minimizing geodesic has length at most \\(\\pi R\\), hence \\(\\text{diam}(M) \\leq \\pi R\\) and in particular \\(M\\) is compact, since \\(M = \\exp_p(B(0; \\pi R))\\). This is known as the Bonnet-Myers theorem. A topological consequence is that if \\(M\\) is a complete Riemannian manifold with Ricci curvature bounded below by a positive constant then \\(\\pi_1(M)\\) is finite: this is because the universal cover \\(\\widetilde{M}\\) also has Ricci curvature bounded below by a positive constant as it is locally isometric to \\(M\\), and thus the fibers of the universal covering map \\(\\widetilde{M} \\to M\\), which is in bijection to \\(\\pi_1(M)\\), must be finite. It is worth noting that if the sectional curvature satisfies \\(K \\geq 1/R^2\\) then the hypothesis \\(\\mathrm{Ric} \\geq (n-1)/R^2\\) is automatically satisfied. We proceed to do some more Jacobi field estimates. Consider a geodesic hinge consisting of two geodesics \\(\\gamma_1\\) and \\(\\gamma_2\\) emerging from the fulcrum \\(\\gamma_1(0) = \\gamma_2(0) = p\\) with direction vectors \\(\\gamma_1'(0) = v\\) and \\(\\gamma_2'(0) = w\\). We shall improve the infinitisimal estimate regarding dispersion of geodesics above to a local estimate, by Taylor expanding the distance between \\(\\gamma_1(t)\\) and \\(\\gamma_2(t)\\); this is realized by length of a minimal geodesic joining them if \\(t\\) is small, and we call this the closing edge of the hinge. To set up the calculation, define a variation \\[\\begin{gather*}V : [0, \\varepsilon) \\times [0, 1] \\to M \\\\ V(s, t) = \\exp_{\\gamma_1(s)}(t \\exp_{\\gamma_1(s)}^{-1} \\gamma_2(s))\\end{gather*}\\] Here \\(V(s, \\cdot)\\) are the minimal geodesics joining \\(\\gamma_1(s)\\) and \\(\\gamma_2(s)\\), parametrized to unit time, therefore note in particular that \\(V\\) is not a variation in our earlier sense of the word, since it does not leave endpoints of the geodesics fixed, but nonetheless we can compute with it. Let \\(T := V_* \\partial_t\\) denote the tangent field along these geodesics and \\(J := V_* \\partial_s\\) denote the transverse vector field, which are Jacobi fields along these geodesics. Since \\(V(s, \\cdot)\\) is parametrized to run a unit time, the norm of \\(T(s, \\cdot)\\) computes the length of this geodesic which is the distance between \\(\\gamma_1(s)\\) and \\(\\gamma_2(s)\\). In particular, \\(T(0, \\cdot) \\equiv 0\\) is the zero vector field as the curve \\(V(0, \\cdot)\\) is the constant geodesic at the fulcrum \\(p\\). However, \\(J(0, \\cdot)\\) is the linear vector field \\(J(0, t) = v + t(w - v)\\) along this constant curve; more meaningfully this formula should be understood as a formula for the restriction of \\(V^* J\\) to the edge \\(\\{0\\} \\times [0, 1]\\) of the domain of \\(V\\) (alternatively, one can understand the region given by the image of \\(V\\) to be a submanifold with corners in \\(M\\) and set up an appropriate notion of vector fields on manifolds with corners). We define \\(f : [0, \\varepsilon) \\to M\\) by \\[\\displaystyle f(s) = \\mathrm{dist}^2(\\gamma_1(s), \\gamma_2(s)) = \\|T(s, 0)\\|^2\\] We follow the same routine as earlier. Denote \\(T(s) := T(s, 0)\\) and \\(T' := \\nabla_{\\partial_s} T\\). Observe \\(f(0) = 0\\), \\(f'(0) = 2 g(T(0), T'(0)) = 0\\) since \\(T(0) = 0\\). Note that \\(\\nabla_{\\partial_s} T = \\nabla_{\\partial_t} J\\) and \\[T'(0) = \\nabla_{\\partial_t} J(0, \\cdot) = w - v,\\] since \\(J(0, t) = v + t(w - v)\\). Hence we get \\[f''(0) = 2 g(T'(0), T'(0)) + 2 g(T''(0), T(0)) = 2\\|w - v\\|^2\\] Next, we have the formula \\[f'''(0) = 6 g(T''(0), T'(0)) + 2 g(T'''(0), T(0))\\] To compute \\(T''(0)\\) we involve the Riemann curvature tensor: \\[\\displaystyle \\nabla^2_{\\partial_s} T = \\nabla_{\\partial_s} \\nabla_{\\partial_t} J = \\nabla_{\\partial_t} \\nabla_{\\partial_s} J + R(J, T) J\\] As \\(T(0) = 0\\) the second term vanishes. Observe that \\(\\nabla_{\\partial_s} J\\) vanishes along the two edges of the hinge, as \\(J(\\cdot, 0)\\) and \\(J(\\cdot, 1)\\) are tangent to \\(\\gamma_1\\) and \\(\\gamma_2\\) respectively, since they are geodesics. Thus if we show \\(\\nabla_{\\partial_t} \\nabla_{\\partial_s} J\\) is parallel along the edge \\(\\{0\\} \\times [0, 1] \\subset [0, \\varepsilon) \\times [0, 1]\\), we will be through, since parallel vector fields along curves vanishing at endpoints must be zero throughout. We proceed to compute using the Jacobi equation: \\[\\begin{aligned} \\nabla_{\\partial_t} \\nabla_{\\partial_t} \\nabla_{\\partial_s} J &amp;= \\nabla_{\\partial_t} \\nabla_{\\partial_s} \\nabla_{\\partial_t} J + \\nabla_{\\partial_t} R(T, J)J \\\\ &amp;= \\nabla_{\\partial_s} \\nabla^2_{\\partial_t} J + R(T, J)\\nabla_{\\partial_t} J + \\nabla_{\\partial_t} R(T, J)J \\\\ &amp;= -\\nabla_{\\partial_s} R(J, T)T + R(T, J)\\nabla_{\\partial_t} J + \\nabla_{\\partial_t} (R(T, J)J) \\end{aligned}\\] To compute the covariant derivatives of the curvature terms we use the same trick as earlier. Let \\(X\\) be an auxiliary vector field and observe \\[\\displaystyle \\begin{aligned}g(\\nabla_{\\partial_s} R(J, T)T, X) &amp;= \\partial_s g(R(J, T)T, X) - g(R(J, T)T, \\nabla_{\\partial_s} X) \\\\ &amp;= \\partial_s g(R(T, X)J, T) - g(R(J, T)T, \\nabla_{\\partial_s} X) \\\\ &amp;= g(\\nabla_{\\partial_s} R(T, X)J, T) + g(R(T, X)J, \\nabla_{\\partial_s} T) - g(R(J, T)T, \\nabla_{\\partial_s} X)\\end{aligned}\\] \\[\\displaystyle \\begin{aligned}g(\\nabla_{\\partial_t} R(T, J)J, X) &amp;= \\partial_t g(R(T, J)J, X) - g(R(T, J)J, \\nabla_{\\partial_t} X) \\\\ &amp;= -\\partial_t g(R(J, X)J, T) - g(R(T, J)J, \\nabla_{\\partial_t} X) \\\\ &amp;= -g(\\nabla_{\\partial_t} R(J, X)J, T) - g(R(J, X)T, \\nabla_{\\partial_t} J) - g(R(T, J)J, \\nabla_{\\partial_t} X)\\end{aligned}\\] Since \\(T(0) = 0\\) and \\(\\nabla_{\\partial_s} T = \\nabla_{\\partial_t} J\\) vanishes along \\(\\{0\\} \\times [0, 1]\\), we conclude that both expressions above vanish. As $X$ was arbitrary, \\(\\nabla_{\\partial_s} R(J, T)T = \\nabla_{\\partial_t} R(T, J)J = 0\\) when evaluated along \\(V(0, \\cdot)\\). This concludes the proof of \\((\\nabla_{\\partial_t} \\nabla_{\\partial_t} \\nabla_{\\partial_s} T)(0, \\cdot) \\equiv 0\\) hence \\((\\nabla_{\\partial_t} \\nabla_{\\partial_s} T)(0, \\cdot) \\equiv 0\\) and thus \\(T''(0) = 0\\). Combining, we get \\(f''(0) = 0\\). Finally, observe \\(f^{\\mathrm{IV}}(0) = 8 g(T'''(0), T'(0)) + 6 g(T''(0), T''(0)) + 2 g(T(0), T^{\\mathrm{IV}}(0))\\). From prior calculations all but the first term vanishes since \\(T''(0) = T(0) = 0\\). \\[\\displaystyle \\nabla^3_{\\partial_s} T = \\nabla_{\\partial_s} \\nabla_{\\partial_s} \\nabla_{\\partial_t} J = \\nabla_{\\partial_s} R(J, T)J + \\nabla_{\\partial_s} \\nabla_{\\partial_t} \\nabla_{\\partial_s} J\\] To compute \\(g(\\nabla_{\\partial_s} R(J, T)J, \\nabla_{\\partial_s} T)\\) we use the earlier trick: \\[\\displaystyle \\begin{aligned} g(\\nabla_{\\partial_s} R(J, T)J, \\nabla_{\\partial_s} T) &amp;= \\partial_s g(R(J, T)J, \\nabla_{\\partial_s} T) + g(R(J, T)J, \\nabla_{\\partial_s}^2 T) \\\\ &amp;= \\partial_s g(R(J, \\nabla_{\\partial_s} T)J, T) + g(R(J, T)J, \\nabla_{\\partial_s}^2 T) \\\\ &amp;= g(\\nabla_{\\partial_s} R(J, \\nabla_{\\partial_s} T)J, T) + g(R(J, \\nabla_{\\partial_s} T)J, \\partial_s T) + g(R(J, T)J, \\nabla_{\\partial_s}^2 T) \\end{aligned}\\] Since \\(T(0) = 0\\), the first and last term vanishes evaluated at \\(\\{0\\} \\times [0, 1]\\). Moreover, \\(J(0) = v\\) and \\(\\nabla_{\\partial_s} T(0, \\cdot) = w - v\\). Thus, the final expression is \\[g(\\nabla_{\\partial_s} R(J, T)J, \\nabla_{\\partial_s} T) = g(R(v, w - v)v, w - v) = g(R(v, w)v, w)\\] Therefore, we have \\[\\displaystyle T'''(0) = g(R(v, w)v, w) + g(\\nabla_{\\partial_s} \\nabla_{\\partial_t} \\nabla_{\\partial_s} J, \\nabla_{\\partial_s} T)\\vert_{\\{0\\} \\times [0, 1]}\\] Thus, the last term must be independent of \\(t\\). Explicitly, we have \\[g(\\nabla_{\\partial_s} \\nabla_{\\partial_t} \\nabla_{\\partial_s} J, \\nabla_{\\partial_s} T)\\vert_{\\{0\\} \\times [0, 1]} = \\partial_t \\partial_s g(\\nabla_{\\partial_s} J, \\nabla_{\\partial_s} T)\\] which therefore implies \\(\\partial_s g(\\nabla_{\\partial_s} J, \\nabla_{\\partial_s} T)\\) is linear in \\(t\\). Remember that \\(\\nabla_{\\partial_s} J\\) vanishes at the top and bottom edges of the hinge, and therefore so does \\(\\nabla_{\\partial_s}^2 J\\). This implies \\[\\partial_s g(\\nabla_{\\partial_s} J, \\nabla_{\\partial_s} T) = g(\\nabla_{\\partial_s}^2 J, \\nabla_{\\partial_s} T) + g(\\nabla_{\\partial_s} J, \\nabla^2_{\\partial_s} T)\\] vanishes at \\((s, t) = (0, 0)\\) and \\((s, t) = (0, 1)\\) respectively. Since it is linear on \\(t\\), this forces the quantity to be identically zero! Thus, \\(f^{\\mathrm{IV}}(0) = 8 g(R(v, w)v, w)\\). By Taylor’s formula: \\[\\displaystyle \\begin{aligned}&amp; f(s) = \\|v - w\\|^2 s^2 + \\frac{1}{3} g(R(v, w)v, w) s^4 + O(s^5) \\\\ \\implies &amp; \\mathrm{dist}(\\gamma_1(s), \\gamma_2(s)) = \\|v - w\\| s - \\frac{K(v, w) \\mathrm{Area}(v, w)}{6 \\|v-w\\|} s^3 + O(s^4)\\end{aligned}\\] This is completely analogous to the estimates for the norm of a Jacobi field that we had made earlier. Thus, deviation of geodesics on Riemannian manifolds behave exactly like Jacobi fields predict it to be.",
      "categories": [],
      "tags": ["differential-geometry","cat(k)"]
    },
  
    {
      "title": "Hilbert&rsquo;s theorem and curiosities",
      "url": "/2020/04/20/hilberts-theorem/",
      "date": "2020-04-20",
      "content": "The contents of this post emerged in the process of preparing and presenting a mini-course titled “Curvature: Geometry, Topology and Combinatorics” in an online math camp for high school students called Monsoon Math Camp. I acknowledge the community and in particular the students for prompting me to think about these questions. It is a classical theorem of Hilbert that there is no smooth isometric immersion of the hyperbolic plane \\(\\Bbb H^2\\) in \\(\\Bbb R^3\\). I will begin with a proof of this fact, as outlined in do Carmo, “Differential Geometry of Curves and Surfaces”. Suppose \\(M \\subset \\Bbb R^3\\) is an everywhere negatively curved surface. Then for any point \\(x \\in M\\), \\(M\\) must “look like” a saddle around \\(x\\), with \\(x\\) being the saddle point, so one would imagine \\(T_x M\\) intersects \\(M\\) in a pair of lines, as in a saddle. These lines are called the asymptotic directions of \\(M\\) at \\(x\\). More precisely, observe that if \\(\\Bbb{II}\\) is the second fundamental form on \\(M\\), \\(\\Bbb{II}_x\\) is a nondegenerate indefinite symmetric bilinear form on \\(T_x M\\) since if \\(v, w \\in T_x M\\) is a pair of principal directions, \\(\\Bbb{II}_x(v, v) &gt; 0\\) and \\(\\Bbb{II}_x(w, w) &lt; 0\\). Thus \\(\\Bbb{II}_x\\) has nontrivial kernel on \\(T_x M\\), which is a 1-dimensional cone, i.e., a pair of lines on \\(T_x M\\). The pair of lines vary continuously with \\(x\\), so we can choose a local parametrization \\[\\begin{align*}\\mathbf{x} : U \\subset \\Bbb R^2 &amp;\\to M \\\\ (u, v) &amp;\\mapsto \\mathbf{x}(u, v) \\end{align*}\\] such that \\(\\mathbf{x}_u\\) and \\(\\mathbf{x}_v\\) are the asymptotic directions throughout the local patch \\(\\mathbf{x}(U) \\subset M\\), i.e., \\(\\Bbb{II}(\\mathbf{x}_u, \\mathbf{x}_u) = \\Bbb{II}(\\mathbf{x}_v, \\mathbf{x}_v) = 0\\). Denote the metric and the second fundamental form with respect to these coordinates as \\[\\begin{align*}ds^2 &amp;= E du^2 + 2F du dv + G dv^2 \\\\ \\Bbb{II} &amp;= e du^2 + 2f du dv + g dv^2, \\end{align*}\\] as is convention. Note that \\(e = f = 0\\) since the coordinate directions are asymptotic. Suppose moreover that \\(M\\) is constant curvature \\(K &lt; 0\\). Then the surface normal \\(\\mathbf{n}\\) is parallel to \\(\\mathbf{x}_{uv}\\) throughout \\(\\mathbf{x}(U) \\subset M\\). This can be seen by the following sequence of computations: By definition of Gaussian curvature, \\(\\mathbf{n}_u \\times \\mathbf{n}_v = K \\mathbf{x}_u \\times \\mathbf{x}_v\\). We write the area element as \\(A = \\|\\mathbf{x}_u \\times \\mathbf{x}_v\\|\\), so that \\(\\mathbf{x}_u \\times \\mathbf{x}_v = A \\mathbf{n}\\). Noting the identity \\((\\mathbf{n} \\times \\mathbf{n}_v)_u - (\\mathbf{n} \\times \\mathbf{n}_u)_v = 2 \\mathbf{n}_u \\times \\mathbf{n}_v\\) we proceed to calculate: \\[\\displaystyle \\begin{aligned} \\mathbf{n} \\times \\mathbf{n}_u = \\frac1{A} (\\mathbf{x}_u \\times \\mathbf{x}_v) \\times \\mathbf{n}_u &amp;= \\frac1{A} \\left ( (\\mathbf{x}_u \\cdot \\mathbf{n}_u) \\mathbf{x}_v - (\\mathbf{x}_v \\cdot \\mathbf{n}_u) \\mathbf{x}_u \\right ) \\\\&amp; = \\frac1{A} (e \\mathbf{x}_v - f \\mathbf{x}_u) = -\\frac{f}{A} \\mathbf{x}_u \\end{aligned}\\] \\[\\displaystyle \\begin{aligned} \\mathbf{n} \\times \\mathbf{n}_v = \\frac1{A} (\\mathbf{x}_u \\times \\mathbf{x}_v) \\times \\mathbf{n}_v &amp;= \\frac1{A} \\left ( (\\mathbf{x}_u \\cdot \\mathbf{n}_v) \\mathbf{x}_v - (\\mathbf{x}_v \\cdot \\mathbf{n}_v) \\mathbf{x}_u \\right ) \\\\&amp; = \\frac1{A} (f \\mathbf{x}_v - g \\mathbf{x}_u) = \\frac{f}{A} \\mathbf{x}_v \\end{aligned}\\] We know \\(K = \\det{\\Bbb{II}}/A^2 = -f^2/A^2\\), so that \\(f/A = \\sqrt{-K}\\). Plugging everything in, we get \\(\\displaystyle 2\\sqrt{-K} \\mathbf{x}_{uv} = 2\\mathbf{n}_u \\times \\mathbf{n}_v = 2K A \\mathbf{n}\\) which shows \\(\\mathbf{n} \\parallel \\mathbf{x}_{uv}\\) as desired. From the above we obtain \\(E_v = 2\\mathbf{x}_{uv} \\cdot \\mathbf{x}_u = 0\\) and \\(G_u = 2\\mathbf{x}_{uv} \\cdot \\mathbf{x}_v = 0\\). Thus, \\(E = E(u)\\) is a pure function of \\(u\\) and \\(G = G(v)\\) is a pure function of \\(v\\) respectively, and we can thus reparametrize the coordinates \\(u, v\\) separately so that \\(E = 1\\) and \\(G = 1\\), i.e., the coordinate curves are arclength parametrized. Thus in particular the rectangles formed by the coordinate curves \\(\\mathbf{x}(I) \\subset M\\), where \\(I = [s_1, s_2] \\times [t_1, t_2] \\subset U\\), be geometric parallelograms, i.e., have opposite sides of equal lengths. Moreover, \\(F = \\mathbf{x}_u \\cdot \\mathbf{x}_v = \\cos(\\theta)\\) where \\(\\theta \\in (0, \\pi)\\) is the angle between the coordinate directions. Thus the metric on the surface is: \\[ds^2 = du^2 + 2\\cos(\\theta) dudv + dv^2\\] We change coordinates by \\(u = x + y\\) and \\(v = x - y\\) to diagonalize the metric as \\[ds^2 = 4 \\cos^2(\\theta/2) dx^2 + 4 \\sin^2(\\theta/2) dy^2\\] For diagonalized metrics it is easy to compute curvature using the Gauss-Codazzi equations: \\[\\displaystyle K = -\\frac{1}{2\\sqrt{EG}} \\left ( \\left ( \\frac{E_y}{\\sqrt{EG}} \\right )_y + \\left ( \\frac{G_x}{\\sqrt{EG}} \\right )_x \\right )\\] Plugging \\(E_y = -2\\sin(\\theta)\\theta_y\\), \\(G_x = 2\\sin(\\theta)\\theta_x\\) and \\(\\sqrt{EG} = 2\\sin(\\theta)\\) in above, we get \\[\\displaystyle K = -\\frac{\\theta_{xx} - \\theta_{yy}}{4\\sin(\\theta)} = -\\frac{\\theta_{uv}}{\\sin(\\theta)}\\] So this special coordinate patch \\(\\mathbf{x} : U \\to \\mathbf{x}(U) \\subset M\\) on the constant negative curvature surface \\(M\\), known in literature as a Tchebyshef net, can be imagined as a fishnet pattern over the surface made by two sets of arclength parametrized coordinate curves, where each individual cell is a geometric parallelogram with internal angle \\(\\theta\\) varying cellwise according to the partial differential equation \\[\\theta_{uv} + K \\sin(\\theta) = 0\\] Intuitively, (I think) the formula for the curvature can be justified as follows: \\(K\\) is equal to the limit of the holonomy angle when parallel transporting over a loop divided by area bounded by the loop, as the loop shrinks to the constant loop. We start with a node of the Tchebyshef net, and an asymptotic direction, and parallel transport it over a cell of area \\(\\sin(\\theta) st\\) in the fishnet. The asymptotic curves in the saddle are geodesics as they are straightlines, and since \\(M\\) locally looks like the saddle we can assume upto first order that the asymptotic curves are geodesics. Then the holonomy upon parallel translating over the coordinate cube is \\(-\\theta_{uv} s t\\) upto second order, hence in the limit \\(K = -\\theta_{uv}/\\sin(\\theta)\\), as we computed. Assume now that \\(M\\) is complete, and extend this to a global parametrization \\(\\mathbf{x} : \\Bbb R^2 \\dashrightarrow M\\) by setting \\(\\mathbf{x}(0, 0) = p\\) and defining \\(\\mathbf{x}(s, t)\\) to be the point reached by running along the first coordinate asymptotic curve for time \\(s\\) and then the second coordinate asymptotic curve for time \\(t\\). Let the domain of the parametrization be \\(E = \\{(s, t) \\in \\Bbb R^2 : \\mathbf{x}(s, t) \\text{ is well-defined}\\}\\). If \\((s_0, t_0) \\in E\\) we can lay a Tchebyshef net at \\(\\mathbf{x}(s_0, t_0)\\) which would match \\(\\mathbf{x}\\) in the intersection of the domain of definition, essentially by uniqueness of solutions to ODEs. Thus \\(\\mathbf{x}\\) would be defined in a neighborhood of \\((s_0, t_0)\\) as well, hence \\((s_0, t_0) \\in E\\) is an interior point. If \\((s_\\infty, t_\\infty) \\in E\\) is a limit point, we can take a sequence \\(\\{(s_n, t_n)\\}\\) in \\(E\\) converging to \\((s_\\infty, t_\\infty)\\), so that \\(q_n = \\mathbf{x}(s_n, t_n)\\) is a Cauchy sequence on \\(M\\) since coordinate distances are Euclidean by arclength parametrization of the coordinate curves; hence by metric completeness of \\(M\\) converges to some point \\(q\\) and we define \\(\\mathbf{x}(s_\\infty, t_\\infty) = q\\). Thus, \\((s_\\infty, t_\\infty) \\in E\\). These show that \\(E \\subset \\Bbb R^2\\) is a nonempty clopen subset, hence \\(E = \\Bbb R^2\\) and thus \\(\\mathbf{x}\\) is globally well-defined. It is clear that \\(\\mathbf{x}\\) is a local diffeomorphism, since \\(\\mathbf{x}_u\\) and \\(\\mathbf{x}_v\\) are the two independent coordinate directions at every point. Let \\(\\Omega \\subset M\\) be the image of \\(\\mathbf{x}\\), which must be an open subset as \\(\\mathbf{x} : \\Bbb R^2 \\to M\\) is a local diffeomorphism. Choose a point \\(p \\in \\partial \\Omega\\) and lay a Tchebyshef net around \\(p\\). This will intersect \\(\\Omega\\) and thus we shall find a point \\(q \\in \\Omega\\) whose asymptotic curve intersects that of \\(p\\), which is impossible since asymptotic curves emanating from \\(\\Omega\\) stays inside \\(\\Omega\\). Thus \\(\\Omega = M\\) and \\(\\mathbf{x}\\) is therefore surjective. It’s a little more fidgety to argue \\(M\\) is simply connected, \\(\\mathbf{x}\\) is injective: do Carmo gives a fidgety argument for this, but let me attempt at a cleaner approach. The fiberwise nondegenerate symmetric indefinite billinear form \\(\\Bbb{II}\\) reduced the structure group of the tangent bundle \\(TM\\) to \\(O(1, 1)\\). Therefore we have a corresponding classifying map \\(M \\to BO(1, 1)\\); but since \\(\\pi_1(M) = 0\\), this map lifts to the universal cover \\(\\widetilde{BO(1, 1)} = BSO^+(1, 1)\\). This implies we can upgrade the “cone field” on \\(M\\) given by \\(\\ker \\Bbb{II}\\) to a pair of well-defined global null vector fields \\(X, Y\\) on \\(M\\). Since \\(\\mathbf{x}_u = X\\) and \\(\\mathbf{x}_v = Y\\), we obtain by existence and uniqueness of ODEs that two independent family of strands of the fishnet given by \\(\\mathbf{x}\\) do not self-intersect, and every pair of independent strands intersect at a unique point. This therefore implies \\(\\mathbf{x}\\) is injective. We needed simple connectedness of \\(M\\) crucially in the argument, because in general it is possible that an asymptotic curve intersects itself in a general surface of negative curvature immersed in \\(\\Bbb R^3\\). As a small detour at this point, observe that a Tchebyshef net is completely determined by the data of the fishnet angles, \\(\\theta : \\Omega \\subset \\Bbb R^2 \\to \\Bbb R\\) satisfying the PDE \\(\\theta_{uv} = - K \\sin(\\theta)\\) relative to the geometric restriction \\(0 &lt; \\theta &lt; \\pi\\). This PDE is known as the sine-Gordon equation, and Hilbert’s theorem is the statement that there are no regular global solutions to this equation with the restriction \\(0 &lt; \\theta &lt; \\pi\\). The name derives from the fact that if we write the equation in space-time coordinates \\(x = u + v\\), \\(t = u - v\\) it transforms into \\(\\square \\theta - K \\sin(\\theta) = 0\\) where \\(\\square \\theta = \\theta_{tt} - \\theta_{xx}\\) is the d’Alembert operator with speed of light assumed to be \\(1\\), which in the low-amplitude case has first order approximation to a linear wave equation-type PDE \\((\\square - K)\\theta = 0\\) known as the Klein-Gordon equation. This is of course all reminiscent of 1-dimensional story with the simple harmonic oscillator, although I am not sure of what the precise physical meaning of this is. The sine-Gordon equation belongs to a class of nonlinear PDEs arising from physics known as soliton equations whose solutions are solitary waves \\(u(x, t) = f(x - ct)\\) with \\(f\\) rapidly decaying at infinity, which are called the soliton solutions and there exists a nonlinear superposition law of waves which gives rise to solutions asymptotic to sum of solitary waves \\(\\sum_{i = 1}^n f_i(x - c_i t)\\) as \\(t \\to -\\infty\\) and \\(\\sum_{i = 1}^n f_i(x - c_i t + \\phi_i)\\) as \\(t \\to \\infty\\), which is to be interpreted as \\(n\\) solitary waves coming togather, interacting in a nonlinear fashion in a compact interval of time, and then dissipating off to infinity with no change in shape or velocities but individual phase shifts \\(\\phi_i\\). Let us try to exhibit this phenomenon for the sine-Gordon equations in space-time coordinates with curvature \\(K = -1\\): plug \\(\\theta(x, t) = f(x - ct)\\) as the soliton ansatz in \\(\\square \\theta + \\sin(\\theta) = 0\\) to obtain the ODE \\((1 - c^2) f'' = \\sin(f)\\) where the rapid decay condition of the soliton is to be interpreted as \\(\\vert f(u)\\vert, \\vert f'(u)\\vert \\to 0\\) as \\(u \\to \\pm \\infty\\). Using this, we solve \\(f(u) = 4 \\arctan \\exp(\\pm \\gamma (u - \\phi))\\) where \\(\\phi\\) is the “phase” of the soliton and \\(\\gamma = 1/\\sqrt{1 - c^2}\\) is the “Lorentz factor” of the soliton with velocity \\(c\\). The solution with the positive sign in the argument is called a kink and the one with the negative sign is called an antikink. The 1-parameter surfaces of constant curvature \\(-1\\) corresponding to these solutions is the Dini family of pseudospheres I used 3D-XplorMath to plot this image, and I really recommend downloading it and try to play with pseudospherical surfaces there. There is an animation option which can be used to see the family of surfaces as \\(c\\) varies. One can observe the “hump” along the curve of singularities on the surface to be propagating like a wave along the axis of the pseudospheres, reminiscent of a corkscrew. At some intermediate stage, the curve of singularities limit from a spiral to a circle, and at that moment the Dini surface is the plain vanilla pseudosphere that we all know and adore. I wanted to talk a bit more about how one obtains multisoliton solutions to the sine-Gordon equation using Bäcklund transforms but I realize I don’t understand it adequately enough myself to explain it in a concise manner. Instead, I will refer the reader to the excellent exposition “Geometry of Solitons” by Terng and Uhlenbeck for further information on soliton equations and how sine-Gordon is an example of such. Here is a picture of a surface of constant curvature -1 obtained from a 2-soliton formed by colliding a kink and an anti-kink: We now proceed to prove Hilbert’s theorem. Suppose \\(M \\subset \\Bbb R^3\\) is a smoothly isometrically immersed copy of \\(\\Bbb H^2\\), so by above we obtain a global Tchebyshef net \\(\\mathbf{x} : \\Bbb R^2 \\to M\\) which is a bijective local diffeomorphism, hence a diffeomorphism as \\(M\\) is simply connected, and since \\(K \\equiv -1\\), we have \\(\\theta_{uv} = \\sin(\\theta)\\). Choose any coordinate rectangle \\(I = [s_1, t_1] \\times [s_2, t_2] \\subset \\Bbb R^2\\). Then the area of \\(\\mathbf{x}(I) \\subset M\\) can be computed as: \\[\\displaystyle \\begin{aligned} \\int_I A du dv &amp;= \\int_I \\sin(\\theta) du dv = \\int_I \\theta_{uv} du dv \\\\ &amp; = \\theta_{11} - \\theta_{12} + \\theta_{22} - \\theta_{21} \\\\ &amp;= (\\alpha_{11} + \\alpha_{12} + \\alpha_{21} + \\alpha_{22}) - 2\\pi &lt; 2\\pi \\end{aligned}\\] Where \\(\\theta_{ij}\\) are the fishnet angles and \\(\\alpha_{ij}\\) are the interior angles at the vertices \\(\\mathbf{x}(s_i, t_j)\\) of the geometric rectangle \\(\\mathbf{x}(I)\\), where the last inequality is just a consequence of the fact that \\(\\alpha_{ij} &lt; \\pi\\). Taking the rectangles \\(I = [-n, n]^2\\) and letting \\(n \\to \\infty\\) shows that \\(M\\) has finite volume, bounded by \\(2\\pi\\), which is a contradiction since \\(\\Bbb H^2\\) is an infinite volume Riemannian surface. This also proves nonimmersability of any complete constant negative curvature surface in \\(\\Bbb R^3\\), since we can compose the immersion with the exponential map \\(\\exp_p : T_p M \\to M\\) to get an immersion of \\(T_p M\\) with a metric of constant negative curvature \\(K &lt; 0\\), and the metric can be scaled so that \\(K \\equiv -1\\), in which case by Cartan’s theorem (known as Minding’s theorem for surfaces) \\(T_p M\\) is isometric to \\(\\Bbb H^2\\), reducing it to Hilbert’s theorem. As a remark, observe that throughout we did not quite require smoothness of the immersion since to do these curvature arguments we just need \\(C^2\\)-regularity. Thus, Hilbert’s theorem in fact proves there is no \\(C^2\\)-regular immersion of \\(\\Bbb H^2\\) in \\(\\Bbb R^3\\). There are however many such \\(C^1\\)-regular embeddings. To construct one we shall use the Nash-Kuiper \\(h\\)-principle. Call a smooth map \\(f : (M, g) \\to (N, h)\\) of Riemannian manifolds a short map if \\(f^* g &lt; h\\) in the sense of quadratic forms, i.e, \\(\\|f_* v\\|_h &lt; \\|v\\|_g\\) for any \\(v \\in TM\\). Theorem (Nash-Kuiper): Let \\((M^m, g)\\) be a Riemannian manifold, and \\(g_{\\mathrm{Euc}}\\) be the Euclidean metric on \\(\\Bbb R^n\\) where \\(m &lt; n\\). For any short immersion \\(f : M \\to \\Bbb R^n\\) and any \\(\\varepsilon &gt; 0\\) there exists \\(C^1\\)-regular isometric immersion \\(f_1 : M \\to \\Bbb R^n\\) such that \\(\\|f_1 - f\\|_{C^0} &lt; \\varepsilon\\), and \\(f_1\\) can be chosen to be an embedding if \\(f\\) is an embedding. One model for the hyperbolic plane is the Beltrami-Klein disk model, which is the unit disk \\(\\Bbb D \\subset \\Bbb R^2\\) equipped with the metric \\[\\displaystyle ds^2 = \\frac{dx^2 + dy^2}{1 - x^2 - y^2} + \\frac{(xdx + ydy)^2}{(1 - x^2 - y^2)^2}\\] This can be obtained from the hyperboloid model discussed in the previous post, by stereographically projecting to a disk tangent to the vertex of the hyperboloid as opposed to an equatorial disk as in the Poincare disk model. Then the canonical inclusion \\(\\Bbb D \\to \\Bbb R^3\\) is a short embedding, hence can be \\(C^0\\)-perturbed to a \\(C^1\\)-regular isometric embedding of \\(\\Bbb H^2\\) in \\(\\Bbb R^3\\). One can in fact do better (thanks to Mike Miller for asking the question): in the hyperboloid model, we parametrize the hyperboloid \\[H = \\{(t, x, y) \\in \\Bbb R^{1, 2} : -t^2 + x^2 + y^2 = -1\\}\\] by \\(\\Psi : \\Bbb R^2 \\to H\\), \\(\\Psi(\\phi, \\theta) = (\\cosh(\\phi), \\sinh(\\phi)\\cos(\\theta), \\sinh(\\phi)\\sin(\\theta))\\). Recall the metric on \\(H\\) is simply the Minkowski metric \\(ds^2 = -dt^2 + dx^2 + dy^2\\), and we can verify that \\(\\Psi^*(ds^2) = d\\phi^2 + \\sinh^2(\\phi)d\\theta^2\\) which is a metric away from the line \\(\\phi = 0\\) along which it is degenerate because \\(\\Psi\\) has degenerate Jacobian along that line. We can fix this by setting \\(\\phi = x\\) and \\(\\theta = \\coth(x) y\\) so that we have a well-defined metric \\(g = dx^2 + \\cosh^2(x) dy^2\\) on \\(\\Bbb R^2\\) with constant negative curvature \\(-1\\) which models the hyperbolic plane. Let \\(f : (\\Bbb R^2, g) \\to (\\Bbb R^3, g_{\\text{Euc}})\\), \\(f(x, y, z) = (x/2, y/2)\\). Then \\[f^* g_{\\text{Euc}} = (dx^2 + dy^2)/4 &lt; dx^2 + \\cosh^2(x) dy^2 = g,\\] hence \\(f\\) is a short embedding. By the Nash-Kuiper h-principle we can find a \\(C^1\\)-regular isometric embedding \\(f_1 : (\\Bbb R^2, g) \\to \\Bbb R^3\\) which is \\(C^0\\)-close to \\(f\\), and thus as \\(f\\) is proper so is \\(f_1\\). We have found a proper \\(C^1\\)-regular isometric embedding of \\(\\Bbb H^2\\) in \\(\\Bbb R^3\\). The first embedding is a wild \\(C^0\\)-small perturbation of the Klein disk model, which essentially looks like a fractal-like ball of fuzz in space, almost like a hyperbolic crochet, with the ideal boundary \\(\\partial \\Bbb{H}^2\\) curled up into a wild continuum(?). On the other hand, the second example wrinkles more and more as we go towards infinity, to accommodate the exponential distance between points farther away from the origin. At least two students of the said camp asked me if \\(\\Bbb H^2\\) smoothly isometrically embeds in \\(\\Bbb R^n\\) for some \\(n &gt; 3\\). A non-explicit answer is given once again by Nash, which states that if \\((M, g)\\) is an arbitrary Riemannian \\(n\\)-manifold then there is a \\(C^\\infty\\)-regular isometric embedding in \\(\\Bbb R^{n(n+1)(3n+11)/2}\\). Plugging the numbers we find \\(\\Bbb H^2\\) admits a smooth isometric embedding in \\(\\Bbb R^{51}\\). This seems like a dauntingly high dimension, so an interesting question might be what the minimal dimension is. David Brander’s thesis, “Isometric Embeddings between Space Forms” includes a result of Danilo Blanuša which states \\(\\Bbb H^2\\) admits a smooth isometric embedding in \\(\\Bbb R^6\\). It’s a very clever construction which emphasizes a key idea in the easy half of Nash-Kuiper theorem (a topic for another day!), I think, so I will try to write down an expository of the proof. We model \\(\\Bbb H^2\\) by \\((\\Bbb R^2, g = dx^2 + \\cosh^2(x) dy^2)\\) as before. Our goal is to find an embedding \\(f : \\Bbb R^2 \\to \\Bbb R^6\\) such that \\(f^* g_{\\mathrm{Euc}} = g\\). Before stating the key lemma we go off on a tangent to make the following observation: Suppose \\(\\eta : \\Bbb R \\to \\Bbb R\\) is a \\(C^\\infty\\)-function with bounded derivative. Consider the function \\(F : \\Bbb R^2 \\to \\Bbb R^2\\), \\[\\displaystyle F(x, y) = \\left (\\eta(x) \\frac{\\cos(cy)}{c}, \\eta(x) \\frac{\\sin(cy)}{c} \\right )\\] The function \\(F\\) essentially wraps the plane about itself so that the lines \\(x = \\mathrm{const}\\) are mapped to circles of radius \\(\\eta(x)/c\\) traversed in speed \\(c\\). It is an easy computation that \\[\\displaystyle F^*(dx^2 + dy^2) = \\frac{\\eta'(x)^2}{c^2} dx^2 + \\eta(x)^2 dy^2\\] If we let \\(c \\to \\infty\\), the angular coordinate is traversed so fast the radial direction contributes very little to the metric, and \\(F^*(dx^2 + dy^2)\\) becomes an arbitrarily good approximation of the quadratic differential \\(\\eta(x)^2 dy^2\\). In fact, the bounded derivative hypothesis can be dealt away with by compromising more dimensions. Namely, let \\(\\psi = (\\psi_1, \\psi_2) : \\Bbb R \\to S^1\\) be a smooth function such that \\(\\psi_i^{(k)}\\) vanishes at the points congruent to \\(i \\pmod{2}\\) for all \\(k \\geq 0\\). Define \\(F : \\Bbb R^2 \\to \\Bbb R^4\\) by \\[\\displaystyle F(x, y) = \\left ( \\eta \\psi_1 \\frac{\\cos(c_1 y)}{c_1}, \\eta \\psi_1 \\frac{\\sin(c_1 y)}{c_1}, \\eta \\psi_2 \\frac{\\cos(c_2 y)}{c_2}, \\eta \\psi_2 \\frac{\\cos(c_2 y)}{c_2} \\right )\\] Where \\(c_i\\) are piecewise-constant functions, with jump discontinuities at the set of points congruent to \\(i \\pmod{2}\\). Using \\(\\psi_1^2 + \\psi_2^2 = 1\\), we compute that \\[\\displaystyle F^*(dx_1^2 + dx_2^2 + dx_3^2 + dx_4^2) = \\left [ \\left ( \\frac{(\\eta \\psi_1)'}{c_1} \\right )^2 + \\left ( \\frac{(\\eta \\psi_2)'}{c_2} \\right )^2 \\right ] dx^2 + \\eta(x)^2 dy^2\\] We can now choose \\(c_1, c_2\\) appropriately large on each interval of continuity so that \\(F^* g_{\\mathrm{Euc}}\\) is again an arbitrarily good approximation of \\(\\eta(x)^2 dy^2\\). More precisely, we have \\(F^* g_{\\mathrm{Euc}} = \\epsilon^2 dx^2 + \\eta^2 dy^2\\) where \\(\\epsilon = \\epsilon(x)\\) is small in \\(C^0\\)-norm. This trick crops up in the Nash-Kuiper theorem to “approximately immerse” a Riemannian manifold in a Euclidean space. I plan to discuss this in more detail elsewhere. Consider the map \\(f : \\Bbb R^2 \\to \\Bbb R^6\\), given by \\[f(x, y) = \\left (\\int_0^x \\sqrt{1 - \\epsilon(t)^2} dt, y, F(x, y) \\right)\\] Then \\(f\\) is \\(C^0\\)-close to the parametrization of the graph of \\(F\\) which is an embedding, and by stability of embedings, we conclude \\(f\\) must be an embedding as well. Observe \\[f^*(g_\\mathrm{Euc}) = (1 - \\epsilon(x)^2) dx^2 + dy^2 + F^*(g_\\mathrm{Euc}) = dx^2 + (1 + \\eta(x)^2) dy^2\\] Plugging \\(\\eta(x) = \\sinh(x)\\) gives the required \\(C^\\infty\\)-regular isometric embedding \\(f : \\Bbb H^2 \\to \\Bbb R^6\\). Note also since the graph of \\(F\\) is properly embedded in \\(\\Bbb R^6\\) and \\(f\\) is \\(C^0\\)-close to the graph, it is also a proper embedding. We can also use the approximation result on \\(\\eta(x) = \\cosh(x)\\) and let \\(f : \\Bbb R^2 \\to \\Bbb R^5\\), \\[f(x, y) = \\left (\\int_0^x \\sqrt{1 - \\epsilon(t)^2} dt, F(x, y) \\right),\\] forgetting the middle component. Then \\(f^*(g_\\mathrm{Euc}) = dx^2 + \\eta^2(x) dy^2 = g\\), so \\(f\\) is a \\(C^\\infty\\)-isometric immersion of \\(\\Bbb H^2\\) in \\(\\Bbb R^5\\). Whether the hyperbolic plane admits a \\(C^k\\)-isometric immersion in \\(\\Bbb R^4\\) for \\(k \\geq 2\\) is unknown, see Chapter 3.2 of Gromov, “Partial Differential Relations”.",
      "categories": [],
      "tags": ["differential-geometry","hyperbolic-geometry","h-principle","Nash-Kuiper","soliton"]
    },
  
    {
      "title": "Model geometries",
      "url": "/2020/04/02/model-geometries/",
      "date": "2020-04-02",
      "content": "I will use this post to record some properties and calculations in the model surface \\(M_K\\) of constant curvature \\(K\\). I have used Chapter 2 of Thurston’s “The Geometry and Topology of 3-Manifolds” as a reference while writing this. It is recommended for readers to skip all the junk I have written below and directly read that chapter. I found Chapter 4.5 of Christian Bär’s lecture notes on differential geometry to be helpful while studying hyperbolic trigonometry, and I have tried to emulate the exposition at the end. The model surface of constant curvature \\(K\\) is the sphere \\(S^2_R\\) of radius \\(R = 1/\\sqrt{K}\\) if \\(K &gt; 0\\), the Euclidean plane \\(\\Bbb R^2\\) if \\(K = 0\\), and the hyperbolic plane \\(\\Bbb H^2_R\\) of “imaginary radius” \\(R = 1/\\sqrt{-K}\\) if \\(K &lt; 0\\). We can define these spaces in a unified manner as follows: Let \\(\\epsilon_K\\) denote the sign of \\(K\\), which is \\(1\\) if \\(K &gt; 0\\), \\(-1\\) if \\(K &lt; 0\\) and \\(0\\) if \\(K = 0\\). We shall equip the Euclidean space \\(\\Bbb R^3\\) with the following bilinear form: \\[\\displaystyle \\langle \\mathbf{x}, \\mathbf{y} \\rangle_K = \\epsilon_K x_1 y_1 + x_2 y_2 + x_3 y_3\\] This is of course not an inner product space if \\(K \\leq 0\\). Such a pair of vector space and simply a bilinear form is often called a quadratic space. The corresponding quadratic form will be denoted by \\(Q_K(\\mathbf{x}) = \\epsilon_K x_1^2 + x_2^2 + x_3^2\\); we can recover the bilinear form from the quadratic form using the polarization identity, so these really carry the same information about the quadratic space. Note that our quadratic space \\((\\Bbb R^3, \\langle \\cdot, \\cdot \\rangle_K)\\) is the usual inner product space \\(\\Bbb R^3\\) if \\(K &gt; 0\\), a degenerate quadratic space \\(\\Bbb R \\times \\Bbb R^2\\) degenerate along the first coordinate and usual Euclidean inner product space on the second coordinate if \\(K = 0\\) and the (1+2)-dimensional Minkowski spacetime \\(\\Bbb R^{1, 2}\\) if \\(K &lt; 0\\), where \\(x_1\\) is the timelike coordinate and \\(x_2, x_3\\) are the spacelike coordinates. If \\(K &gt; 0\\), we consider the sphere of radius \\(R = 1/\\sqrt{K}\\) inside this quadratic space, given by \\[\\displaystyle S_R(K) = \\{\\mathbf{x} \\in \\Bbb R^3 : Q_K(\\mathbf{x}) = R^2\\} = \\{\\mathbf{x} \\in \\Bbb R^3 : x_1^2 + x_2^2 + x_3^2 = 1/K\\}\\] We equip the tangent spaces of \\(S_R(K)\\) with the metric \\(\\langle \\cdot, \\cdot \\rangle_K\\). Since in the case of \\(K &gt; 0\\) the bilinear form is positive definite, this is indeed a Riemannian metric without further thought. The resulting space is the sphere \\(S^2_R\\) of radius \\(R = 1/\\sqrt{K}\\). If \\(K &lt; 0\\), consider the sphere of radius \\(R = i/\\sqrt{-K}\\)(!) inside the quadratic space. The difference in notation will be explained below. \\[\\displaystyle S^{\\pm}_R(K) = \\{\\mathbf{x} \\in \\Bbb R^3 : Q_K(\\mathbf{x}) = R^2\\} = \\{\\mathbf{x} \\in \\Bbb R^3 : -x_1^2 + x_2^2 + x_3^2 = 1/K\\}\\] In the Euclidean world, \\(S^{\\pm}_R(K)\\) is a hyperboloid of two sheets in \\(\\Bbb R^3\\). We consider the sheet \\(S_R(K) = S^{\\pm}_R(K) \\cap \\{x_1 &gt; 0\\}\\) which lies in the “future” (interpreting \\(x_1\\) as the timelike coordinate) and equip the tangent spaces of \\(S_R(K)\\) with the bilinear form \\(\\langle \\cdot, \\cdot \\rangle_K\\). There is a precise way to talk about future and past in the Minkowski spacetime: the kernel of the bilinear form is given by \\[\\{Q_K(\\mathbf{x}) = 0\\} = \\{\\mathbf{x} \\in \\Bbb R^3 : x_2^2 + x_3^2 = x_1^2\\}\\] which is a cone in \\(\\Bbb R^3\\). This is called the light cone, which consists of all the vectors in the direction of light emanating from the event \\(\\mathbf{0} = (0, 0, 0)\\) in the space \\(\\{0\\} \\times \\Bbb R^2\\) at the time-slice \\(x_1 = 0\\). It was pointed out to me that the intuitive reason that the direction of light should be orthogonal to itself is because such directions are the only things which are coordinate-invariant (which, if there is any truth to the world, light trajectories must be); under any linear change of coordinates of spacetime, the light cone remains invariant. The future and past of the event \\(\\mathbf{0}\\) is everything on and in the light cone, given by \\(Q_K(\\mathbf{x}) &lt; 0\\); intuitively this is because any point \\(\\mathbf{p}\\) in the future or past of \\(\\mathbf{0}\\) in the spacetime must be able to causally affect \\(\\mathbf{0}\\), in the sense that, if it is in the past, one must be able to send a signal at most at the speed of light from \\(\\mathbf{p}\\) that will reach \\(\\mathbf{0}\\) eventually as time evolves in the positive direction, or if it is in the future, one must be able to send a signal at most at the speed of light from \\(\\mathbf{0}\\) which will reach \\(\\mathbf{p}\\) eventually, vice versa. Such trajectories must be trapped inside the light cone, essentially because their speed is bounded by the speed of light. Thus we declare future of \\(\\mathbf{0}\\) to be anything in or on the positive half of the light cone and the past to be anything in or on the negative half of the light cone. It is worth mentioning on the side that vectors \\(\\mathbf{x}\\) for which \\(Q_K(\\mathbf{x}) &gt; 0\\) are called spacelike, essentially because restricted to the space at time-slice \\(x_0 = 0\\), \\(\\langle \\cdot, \\cdot \\rangle_K\\) is the completely familiar Euclidean inner product, which is positive definite. Therefore whenever a vector has a spacelike coordinates dominating the timelike coordinate, the bilinear form will be positive definite on it, and thus it is called spacelike. The spacelike vectors consists of the exterior component of the light cone. But this was a long digression. The point I wanted to make was that the hyperboloid \\(S_R^{\\pm}(K)\\) is defined by the equation \\(Q_K(\\mathbf{x}) = R^2 = -1/K\\), which is negative, therefore is contained in the light cone. The surface \\(S_R(K)\\) is the future half of this hyperboloid. Note that the restrictions of the bilinear form \\(\\langle \\cdot, \\cdot \\rangle_K\\) to the tangent spaces of \\(S_R(K)\\) are nondegenerate, since the tangent vectors to the future sheet of the hyperboloid are spacelike! It is possible to see this by observing that the light cone is asymptotic to the hyperboloid. Therefore in particular \\(\\langle \\cdot, \\cdot \\rangle_K\\) is positive definite on the tangent spaces of \\(S_R(K)\\), making it a Riemannian 2-manifold. It is possible to describe an isometry \\(S_R(K) \\to \\Bbb H^2_R\\) to the Poincare disk model by projecting \\(S_R(K)\\) to the disk \\(\\Bbb D_R \\subset \\{0\\} \\times \\Bbb R^2\\) of radius \\(R = 1/\\sqrt{-K}\\), radially along lines through \\((-1/\\sqrt{-K}, 0, 0)\\). A formula as such is \\[\\displaystyle (x_1, x_2, x_3) \\mapsto \\left (\\frac{x_2}{1 + \\sqrt{1 - K(x_2^2+x_3^2)}}, \\frac{x_3}{1+\\sqrt{1 - K(x_2^2+x_3^2)}} \\right )\\] Note how this is completely analogous to the the formula for the stereographic projection of \\(S^2 \\setminus \\{\\mathbf{N}\\}\\) to \\(\\Bbb R^2\\). We shall chase the metric on \\(S_R(K)\\) to a metric on \\(\\Bbb D_R\\) and show that it is indeed the Poincare metric. Let us write coordinates on \\(\\mathbb{R}^{1, 2}\\) as \\((t, \\mathbf{x})\\) for readability and suggestiveness, where \\(t\\) denotes the timelike coordinate and \\(\\mathbf{x} = (x_1, x_2)\\) are the spacelike coordinates. We write the map above as \\(\\phi : S_R(K) \\to \\Bbb H^2\\), \\(\\phi(t, \\mathbf{x}) = \\mathbf{x}/(1 + t \\sqrt{-K})\\). Then the Jacobian matrix of this map evaluated at \\(p = (t, \\mathbf{x})\\) is given by \\[\\displaystyle D\\phi(p) = \\begin{pmatrix} -x_1\\sqrt{-K}/(1 + t\\sqrt{-K})^2 &amp; 1/(1+t\\sqrt{-K}) &amp; 0 \\\\ -x_2\\sqrt{-K}/(1 + t\\sqrt{-K})^2 &amp; 0 &amp; 1/(1 + t\\sqrt{-K}) \\end{pmatrix}\\] Let \\(v = (s_1, \\mathbf{v}), w = (s_2, \\mathbf{w}) \\in T_p S_R(K)\\) be two tangent vectors on \\(S_R(K)\\) at \\(p\\). From the Jacobian formula, we see \\[\\displaystyle \\begin{aligned} D\\phi(p)(v) &amp;= - \\sqrt{-K} \\frac{s_1 \\mathbf{x} }{(1 + t \\sqrt{-K})^2} + \\frac{\\mathbf{v}}{1 + t\\sqrt{-K}} \\\\ D\\phi(p)(w) &amp;= - \\sqrt{-K} \\frac{s_2 \\mathbf{x}}{(1 + t\\sqrt{-K})^2} + \\frac{\\mathbf{w}}{1 + t\\sqrt{-K}} \\end{aligned}\\] We can relate our bilinear form with the spacelike Euclidean dot product as: \\[\\langle (t, \\mathbf{a}), (s, \\mathbf{b}) \\rangle_K = - ts + \\mathbf{a} \\cdot \\mathbf{b}\\] So using the fact that \\(p = (t, \\mathbf{x})\\) is a norm \\(i/\\sqrt{-K}\\) vector, and \\(v, w\\) are tangential to \\(S_R(K)\\) at \\(p\\), we obtain \\(\\mathbf{x} \\cdot \\mathbf{x} = t^2 + K^{-1}\\), \\(\\mathbf{v} \\cdot \\mathbf{x} = s_1 t\\) and \\(\\mathbf{w} \\cdot \\mathbf{x} = s_2 t\\). With these identities in mind, we shall take the Euclidean dot product of the vectors \\(D\\phi(p)(v)\\) and \\(D\\phi(p)(w)\\) in \\(\\Bbb R^2\\): \\[\\displaystyle \\begin{aligned}D\\phi(p)(v) \\cdot D\\phi(p)(w) &amp;= -K \\frac{s_1 s_2 \\mathbf{x} \\cdot \\mathbf{x}}{(1 + t\\sqrt{-K})^4} - \\sqrt{-K} \\frac{s_1 \\mathbf{x} \\cdot \\mathbf{w} + s_2 \\mathbf{x} \\cdot \\mathbf{v}}{(1 + t\\sqrt{-K})^3} + \\frac{\\mathbf{v} \\cdot \\mathbf{w}}{(1 + t\\sqrt{-K})^2} \\\\ &amp;= -K \\frac{s_1 s_2 (t^2 + K^{-1}) }{(1 + t\\sqrt{-K})^4} - \\sqrt{-K} \\frac{2 s_1 s_2 t}{(1 + t\\sqrt{-K})^3} + \\frac{\\mathbf{v} \\cdot \\mathbf{w}}{(1 + t\\sqrt{-K})^2} \\\\ &amp;= \\frac{-s_1 s_2 + \\mathbf{v} \\cdot \\mathbf{w}}{(1 + t\\sqrt{-K})^2} = \\frac{\\langle v, w \\rangle_K}{(1 + t\\sqrt{-K})^2}\\end{aligned}\\] Now note that \\[\\displaystyle \\|\\phi(p)\\|^2 = \\frac{\\|\\mathbf{x}\\|^2}{(1 + \\sqrt{-K} t)^2} = \\frac{t^2 + K^{-1}}{(1 + t\\sqrt{-K})^2} = -\\frac{1}{K} \\frac{t \\sqrt{-K} - 1}{t \\sqrt{-K} + 1}\\] So \\(1 + K \\|\\phi(p)\\|^2 = 2/(1 + t \\sqrt{-K})\\), and we therefore we can replace the factor of \\((1 + t \\sqrt{-K})^2\\) appearing above by \\(4/(1 + K\\|\\phi(p)\\|)^2\\). Putting it all together, \\[\\displaystyle \\langle v, w \\rangle_K = 4 \\frac{D\\phi(p)(v) \\cdot D\\phi(p)(w)}{(1 + K\\|\\phi(p)\\|)^2} = \\phi^* \\left ( 4 \\frac{dx^2 + dy^2}{(1 + K(x^2 + y^2))^2} \\right ) = \\phi^* \\omega_{P}\\] Where \\(\\omega_P\\) is exactly the Poincare metric on \\(\\Bbb D_R\\) in the disk model of \\(\\Bbb H^2_K\\). It is worth noting that \\(\\omega_P\\) is a pointwise multiple of the Euclidean metric on the disk, therefore hyperbolic angles drawn on the disk are the same as Euclidean angles, since scaling in the metric does not change measurements of angles. Such equivalences of metrics are called conformal equivalences; we just proved that the stereographic projection of the hyperboloid model to the disk is conformal, much like the stereographic projection of the sphere to the plane. In fact, if one computes the pullback of the spherical metric on \\(S^2_K\\) to \\(\\Bbb R^2\\) under the stereographic projection, one would obtain a metric identical to \\(\\omega_P\\) except with \\(K\\) positive (Compute it!). This implies for a flat creature who does not have access to the third dimension, spherical geometry is as unnatural as hyperbolic geometry! The isometry group of the Riemannian manifold \\(S_R(K)\\) is the isotropy group \\(O_K\\) of the quadratic form \\(Q_K\\), consisting of all matrices in \\(\\mathrm{GL}_3(\\Bbb R)\\) preserving the bilinear form \\(\\langle \\cdot, \\cdot \\rangle_K\\), with a mild modification for \\(K &lt; 0\\) to throw away the isometries which switch the two sheets of the hyperboloid \\(S_R^{\\pm}(K)\\), i.e, only consider the causal orientation preserving isometries. In case of \\(K &gt; 0\\), this is the orthogonal group \\(O(3)\\) and for \\(K &lt; 0\\), this is the orthochronous Lorentz group \\(O^+(1, 2)\\). The spatial orientation preserving subgroup is denoted as \\(SO(1, 2)\\), and the elements of this group are Lorentz transformations of the (1+2)-dimensional spacetime. These are generated by spatial rotations, given by \\[\\displaystyle R_\\theta = \\begin{pmatrix} 1 &amp; 0 &amp; 0 \\\\ 0 &amp; \\cos(\\theta) &amp; \\sin(\\theta) \\\\ 0 &amp; -\\sin(\\theta) &amp; \\cos(\\theta) \\end{pmatrix}\\] and the so-called Lorentz boosts along various axis. For example, a Lorentz boost along the respective two spatial axes are given by \\[\\displaystyle L^1_\\zeta = \\begin{pmatrix} \\cosh(\\zeta) &amp; \\sinh(\\zeta) &amp; 0 \\\\ \\sinh(\\zeta) &amp; \\cosh(\\zeta) &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{pmatrix}, \\;\\;\\; L^2_\\zeta = \\begin{pmatrix}\\cosh(\\zeta) &amp; 0 &amp; \\sinh(\\zeta) \\\\ 0 &amp; 1 &amp; 0 \\\\ \\sinh(\\zeta) &amp; 0 &amp; \\cosh(\\zeta) \\end{pmatrix}\\] It can be easily checked that the isometry group of \\(S_K(R)\\) acts transitively on \\(S_K(R)\\), and the stabilizer subroup of a point is isomorphic to \\(O(2)\\) regardless of \\(K\\) (to see this in \\(\\Bbb H^2_K\\), find a convenient point, eg, the vertex of the hyperboloid and observe that all the stabilizing elements are spatial rotations). This proves that the model geometries \\(M_K\\) are symmetric spaces: if \\(K &gt; 0\\) it is \\(O(3)/O(2)\\), if \\(K &lt; 0\\) it is \\(O^+(1, 2)/O(2)\\). Let us try to understand the geodesics of \\(\\Bbb H^2_K\\) using this information. For any 2-dimensional subspace \\(H \\subset \\Bbb R^2\\) such that \\(H\\) intersects the positive sheet of the hyperboloid \\(S_R^{\\pm}(K)\\), the bilinear form \\(\\langle \\cdot, \\cdot \\rangle_K\\) restricts to a nondegenerate form on \\(H\\) that makes it a hyperbolic quadratic plane, as pictorially evident by seeing that the kernel of the restricted form is union of two lines in \\(H\\), obtained from intersecting \\(H\\) with the light cone. Choose an orthonormal basis \\(\\{v_1, v_2\\}\\) in \\(H\\) with respect to this form, and extend it to an orthonormal basis \\(\\{v_1, v_2, v_3\\}\\) of \\(\\Bbb R^{1, 2}\\). Let \\(A = (v_1, v_2, v_3)\\); then \\(A \\in O^+(1, 2)\\) such that \\(A\\mathbf{e}_i = v_i\\) for \\(1 \\leq i \\leq 3\\). Therefore \\(A\\) takes the span of \\(\\mathbf{e}_1, \\mathbf{e}_2\\), i.e., the plane \\(x_3 = 0\\) to the plane \\(H\\). Observe that the the matrix \\(B = \\mathrm{diag}(1, 1, -1)\\) is an element of \\(O^+(1, 2)\\) which reflects along the plane \\(x_3 = 0\\); the timelike direction is not affected in this process so it is safely an orthochronous Lorentz transformation. Finally consider the element \\(ABA^{-1} \\in O^+(1, 2)\\), and observe that this fixes \\(H\\) since \\(B\\) fixes \\(x_3 = 0\\). Thus, \\(ABA^{-1}\\) is an isometric involution of \\(S_R(K)\\) fixing the curve \\(H \\cap S_R(K)\\). Hence, it must be a geodesic of \\(S_R(K)\\). Moreover these are all the geodesics of \\(S_R(K)\\), since through any point with a given tangent vector, one can draw a 2-dimensional section of the hyperboloid passing through that point, tangential to the vector. This is analogous to the situation for \\(K &gt; 0\\) where the geodesics on the sphere \\(S^2_R\\) are given by slicing it by a plane through the origin, which traces out a great circle on the sphere. We can write down explicit formulas for geodesics on \\(S_R(K)\\). Namely, if \\(\\gamma : \\Bbb R \\to S_R(K)\\) is an arclength parametrized geodesic passing through \\(\\gamma(0) = (1/\\sqrt{-K}, 0, 0)\\), it must be of the form \\[\\displaystyle \\gamma(t) = \\frac{1}{\\sqrt{-K}} \\left ( \\cosh(t \\sqrt{-K}), \\sinh(t \\sqrt{-K}) \\cos(\\theta), \\sinh(t \\sqrt{-K}) \\sin(\\theta) \\right )\\] To see this, observe \\(\\langle \\gamma, \\gamma \\rangle_K = R^2\\), so \\(\\gamma\\) lies on \\(S_R(K)\\), and \\(\\langle \\gamma', \\gamma' \\rangle_K = 1\\) which implies \\(\\gamma\\) is arclength parametrized. \\(\\gamma\\) clearly lies on the plane spanned by \\((1/\\sqrt{-K}, 0, 0)\\) and \\((0, \\cos(\\theta), \\sin(\\theta))\\), so it must be a geodesic, as required. Note the similarity with formulas for arclength parametrized geodesics on \\(S_R(K) \\cong S^2_R\\) for \\(K &gt; 0\\) passing through \\((1/\\sqrt{K}, 0, 0)\\), which can be written down by simply replacing the hyperbolic trigonometric functions with usual trigonometric functions: \\[\\displaystyle \\gamma(t) = \\frac{1}{\\sqrt{K}} \\left ( \\cos(t \\sqrt{K}), \\sin(t \\sqrt{K}) \\cos(\\theta), \\sin(t \\sqrt{K}) \\sin(\\theta) \\right )\\] This describes the geodesics of \\(\\Bbb H_K^2\\) in the hyperboloid model completely. If we project to the unit disk conformally, we obtain that the geodesics in the disk model are exactly diameters as well as semicircular arcs which hit the boundary circle perpendicularly, as illustrated in the following picture: Here on the left we have an illustration of a geodesic tessellation of \\(\\Bbb H_K^2\\) in Poincare disk model, and on the right is “Circle Limit III” by Escher, who mistakenly thought that the white lines are geodesics, but in fact they meet the boundary circle in somewhere close to 80 degrees, as Coxeter found out: Earlier we found that if \\(M\\) is a Riemannian 2-manifold of constant Gaussian curvature \\(K\\), then for any geodesic \\(\\gamma : [0, c] \\to M\\) with initial point \\(\\gamma(0) = p\\) and a normal Jacobi field \\(J\\) along \\(\\gamma\\), its length \\(f(t) = \\|J(t)\\|\\) must satisfy the second order linear differential equation \\(f'' + K f = 0\\). Solving with initial conditions \\(J(0) = 0\\) and \\(J'(0) = \\mathbf{e}_p\\) we obtain \\[\\displaystyle \\begin{aligned} J(t) &amp;= \\frac{\\sin(t \\sqrt{K})}{\\sqrt{K}} \\mathbf{e} \\;\\; \\text{if} \\;\\; K &gt; 0 \\\\ J(t) &amp;= t \\mathbf{e} \\;\\; \\text{if} \\;\\; K = 0 \\\\ J(t) &amp;= \\frac{\\sinh(t \\sqrt{-K})}{\\sqrt{-K}} \\mathbf{e} \\;\\; \\text{if} \\;\\; K &lt; 0\\end{aligned}\\] Thus, in positive curvature, nearby geodesics starting at a common point “tend to” behave periodically, by diverging off, then coming back and converging to a point, and so forth. Similarly, in negative curvature, nearby geodesics starting at a common point “tend to” diverge from each other at an exponential rate. In zero curvature, nearby geodesics starting at a common point “tend to” grow linearly far apart. But the Jacobi field computation can only tell us about these tendencies as such; whether or not these actually happen is unclear. We shall show by some spherical and hyperbolic trigonometry that these do in fact happen in case of the model surface \\(M_K\\) of constant curvature \\(K\\). Suppose we have a geodesic triangle \\(\\Delta = [P,Q,R]\\) in \\(M_K\\) with vertices \\(P, Q, R\\), geodesic \\(PQ, PR, QR\\) of length \\(a, b, c\\) and angles opposite to the sides \\(\\alpha, \\beta, \\gamma\\) respectively. For \\(K = 0\\), we have a convenient formula for \\(c\\) in terms of \\(a, b\\) and \\(\\gamma\\), obtained using familiar trigonomentry, \\(c^2 = a^2 + b^2 + 2ab\\cos(\\gamma)\\). Imagine changing the triangle \\(\\Delta\\) by fixing the vertex \\(P\\), but varying the sides \\(a, b\\) and the angle \\(\\gamma\\). The formula gives an understanding on the change in \\(c\\) that comes from such maneuvers. Importantly, if \\(a = b = T\\), then \\(c\\) is proportional to \\(T\\), with the proportionality constant depending on the angle \\(\\gamma\\) between the sides. This implies that in the flat plane, two geodesics starting at a point and run until time \\(T\\) will be a constant multiple of \\(T\\) apart. We would like to do similar calculations for \\(K \\neq 0\\), but we would need to develop a theory of trigonometry in non-planar geometries to accomplish this, which we do in the next paragraph. Motivated from the mysterious apparitions in earlier computations, define trigonometric functions in the model geometry of constant curvature \\(K \\neq 0\\) by \\[\\displaystyle \\begin{gather*} \\sin_K(x) = \\frac{\\sin(x\\sqrt{K})}{\\sqrt{K}} \\;\\; \\text{if} \\; K &gt; 0 \\;\\; \\text{and} \\;\\; \\frac{\\sinh(x \\sqrt{-K})}{\\sqrt{-K}} \\;\\; \\text{if} \\;\\; K &lt; 0 \\\\ \\cos_K(x) = \\frac{\\cos(x\\sqrt{K})}{\\sqrt{K}} \\;\\; \\text{if} \\;\\; K &gt; 0 \\;\\; \\text{and} \\;\\; \\frac{\\cosh(x \\sqrt{-K})}{\\sqrt{-K}} \\;\\; \\text{if} \\;\\; K &lt; 0\\end{gather*}\\] Observe the trigonometric identity \\(\\cos_K^2(x) + \\epsilon_K \\sin_K^2(x) = 1/\\vert K\\vert\\). In the earlier setup of the triangle \\(\\Delta = [P, Q, R]\\) in \\(M_K\\), we can arrange \\(P = (1/\\sqrt{\\vert K \\vert}, 0, 0)\\) by applying an isometry, and moreover we can do a (spatial, in case of \\(K &lt; 0\\)) rotation so that \\(Q\\) is in the \\(xy\\)-plane. Then the whole geodesic \\(PQ\\) must lie in the \\(xy\\)-plane, implying \\(Q = (\\cos_K(a), \\sin_K(a), 0)\\). Define \\[\\displaystyle \\mathbf{M} = \\begin{pmatrix} \\sqrt{\\vert K \\vert} \\cos_K(a) &amp; \\epsilon_K \\sqrt{|K|} \\sin_K(a) &amp; 0 \\\\ \\sqrt{|K|} \\sin_K(a) &amp; - \\sqrt{|K|} \\cos_K(a) &amp; 0 \\\\ 0 &amp; 0 &amp; 1 \\end{pmatrix}\\] \\(\\mathbf{M}\\) is an orthogonal transformation if \\(K &gt; 0\\) and composition of a Lorentz boost with a reflection along the \\(xz\\)-plane if \\(K &lt; 0\\). Then we obtain a new geodesic triangle \\(\\mathbf{M} (\\Delta) = [\\mathbf{M}P, \\mathbf{M}Q, \\mathbf{M}R]\\); but observe that \\(\\mathbf{M} P = Q\\) and \\(\\mathbf{M} Q = P\\). Let \\(R' = \\mathbf{M} R\\) Since \\(PR\\) makes an angle of \\(\\gamma\\) with \\(PQ\\) in \\(\\Delta\\), the plane that cuts out \\(PR\\) from \\(M_K\\) must make an angle of \\(\\gamma\\) with the \\(xz\\)-plane. Therefore \\(R = (\\cos_K(b), \\sin_K(b) \\cos(\\gamma), \\sin_K(b) \\sin(\\gamma))\\). On the other hand, \\(PR'\\) makes the same angle with \\(PQ\\) in \\(\\mathbf{M}(\\Delta)\\) as \\(QR\\) and \\(QP\\) in \\(\\Delta\\), which is \\(\\beta\\). Thus, \\(R' = (\\cos_K(c), \\sin_K(c) \\cos(\\beta), \\sin_K(c) \\sin(\\beta))\\). Writing \\(\\mathbf{M} R = R'\\) in coordinates, \\[\\displaystyle \\begin{pmatrix} \\sqrt{|K|} \\cos_K(a) &amp; \\epsilon_K \\sqrt{|K|} \\sin_K(a) &amp; 0 \\\\ \\sqrt{|K|} \\sin_K(a) &amp; - \\sqrt{|K|} \\cos_K(a) &amp; 0 \\\\ 0 &amp; 0 &amp; 1\\end{pmatrix} \\begin{pmatrix} \\cos_K(b) \\\\ \\sin_K(b) \\cos(\\gamma) \\\\ \\sin_K(b) \\sin(\\gamma) \\end{pmatrix} = \\begin{pmatrix}\\cos_K(c) \\\\ \\cos_K(c) \\sin(\\beta) \\\\ \\sin_K(c) \\sin(\\beta)\\end{pmatrix}\\] Computing out the identity obtained from the first entry, we get: \\[\\displaystyle \\cos_K(c) = \\sqrt{|K|} \\cos_K(a) \\cos_K(b) + \\epsilon_K \\sqrt{|K|} \\sin_K(a) \\sin_K(b) \\cos(\\gamma)\\] This is the cosine formula for sides of a triangle. Written explicitly, \\[\\displaystyle \\begin{aligned}\\cos(c\\sqrt{K}) &amp;= \\cos(a\\sqrt{K}) \\cos(b\\sqrt{K}) + \\sin(a\\sqrt{K}) \\sin(b\\sqrt{K}) \\cos(\\gamma) \\;\\; \\text{if} \\;\\; K &gt; 0 \\\\ \\cosh(c\\sqrt{-K}) &amp;= \\cosh(a\\sqrt{-K}) \\cosh(b\\sqrt{-K}) - \\sinh(a\\sqrt{-K}) \\sinh(b\\sqrt{-K}) \\cos(\\gamma) \\;\\; \\text{if} \\;\\; K &lt; 0\\end{aligned}\\] Set \\(a = b = T\\) and \\(\\gamma\\) be constant. We get \\[\\begin{aligned}\\cos(c \\sqrt{K}) &amp;= 1 - \\sin^2(T \\sqrt{K}) (1 - \\cos \\gamma) \\;\\; \\text{if} \\;\\; K &gt; 0 \\\\ \\cosh(c\\sqrt{-K}) &amp;= 1 + \\sinh^2(T\\sqrt{-K})(1 - \\cos \\gamma) \\;\\; \\text{if}\\;\\; K &lt; 0\\end{aligned}\\] We inspect the cases \\(K = 1\\) (red curve) and \\(K = -1\\) (blue curve) in this Desmos snippet. Use the slider to change the value of \\(0 \\leq \\gamma \\leq \\pi\\). We see the value of \\(c\\) behaves periodically with respect to time \\(T\\) if curvature is positive, and exponentially grows with respect to time \\(T\\) if curvature is negative. This is the desired global result that we wanted to see. I shall stop here for now but I might keep adding new stuff as I stumble across them later on. I’ll make a note of them whenever I do. Up next, more Jacobi fields.",
      "categories": [],
      "tags": ["cat(k)","hyperbolic-geometry","jacobi-fields","model-geometry","special-relativity"]
    },
  
    {
      "title": "Jacobi fields: Part I",
      "url": "/2020/03/27/jacobi-fields-part-i/",
      "date": "2020-03-27",
      "content": "In the subsequent series of posts I would like to talk about certain comparison theorems in Riemannian geometry while learning them. I have a very rough sketch of what I would like to do, but it seemed like an enticing idea to start writing my thoughts down somewhere. I will start by introducing Jacobi fields in this post, which will be used crucially when discussing comparison theorems and what they are. While writing this I have used do Carmo, “Riemannian Geometry” and Milnor, “Morse Theory” as references and inspiration, and strongly recommend looking through both for more detail and perspective. Let \\((M, g)\\) be a Riemannian manifold and \\(\\nabla\\) the unique torsion-free metric connection on the manifold. Given a path \\(\\gamma : [a, b] \\to M\\) starting at \\(\\gamma(a) = p\\), a variation of \\(\\gamma\\) is defined to be a smooth map \\(V : (-\\varepsilon, \\varepsilon) \\times [a, b] \\to M\\) such that \\(V(0, t) = \\gamma(t)\\) and \\(V(s, a) = p\\) for all \\(t \\in [a, b]\\) and \\(s \\in (-\\varepsilon, \\varepsilon)\\). We shall define \\(\\gamma_s : [a, b] \\to M\\) by \\(\\gamma_s(t) = V(s, t)\\), and think of the variation as a smooth family \\(\\{\\gamma_s\\}_{s \\in (-\\varepsilon, \\varepsilon)}\\) of curves starting at \\(p\\), passing through \\(\\gamma\\). To any variation \\(V\\) of \\(\\gamma\\) we can associate a vector field \\(X\\) defined along \\(\\gamma\\) by \\(X(t) = \\partial_s \\gamma_s(t) \\vert_{s = 0}\\); observe that \\(X(a) = 0\\). Conversely, given a vector field \\(X\\) defined along \\(\\gamma\\) such that \\(X(a) = 0\\), the map \\(V : (-\\varepsilon, \\varepsilon) \\times [a, b] \\to M\\) defined by \\(V(s, t) = \\exp_{\\gamma(t)}(s X(t))\\) defines a variation of \\(\\gamma\\). Therefore such vector fields effectively carry informations about infinitisimal variations of \\(\\gamma\\) and we shall call them variation fields along \\(\\gamma\\). We will be particularly interested in variations of geodesics on \\((M, g)\\). To wit, suppose \\(\\gamma\\) is a geodesic on the manifold with \\(\\gamma'(0) = v\\), and \\(V\\) is a variation of \\(\\gamma\\) through geodesics, i.e., \\(\\gamma_s\\) are geodesics for all \\(s \\in (-\\varepsilon, \\varepsilon)\\). Let \\(X\\) be the variation field corresponding to \\(V\\). Then we observe that \\[\\displaystyle 0 = \\nabla_X \\nabla_{\\gamma'} \\gamma' = \\nabla_{\\gamma'} \\nabla_X \\gamma' + \\nabla_{[X, \\gamma']} \\gamma' + R(X, \\gamma') \\gamma'\\] But \\(X = V_* \\partial_s \\vert_{s = 0}\\), and \\(\\gamma' = V_* \\partial_t \\vert_{s = 0}\\), therefore \\([X, \\gamma'] = V_* [\\partial_s, \\partial_t]\\vert_{s = 0} = 0\\). Also observe that \\(\\nabla_X \\gamma' = \\nabla_{\\gamma'} X + [X, \\gamma'] = \\nabla_{\\gamma'} X\\) by previous line. Plugging these in above, we obtain \\[\\displaystyle \\nabla_{\\gamma'}^2 X + R(X, \\gamma') \\gamma' = 0\\] This is known as the Jacobi equation, and is a second order linear ordinary differential equation. Suppose \\(X\\) is an arbitrary solution to the above equation with \\(X(0) = 0\\) and \\((\\nabla_{\\gamma'} X)(0) = w\\) for some \\(w \\in T_p M\\). Observe that the variation field \\(J(t) = (d\\exp_p)_{tv}(tw)\\) along \\(\\gamma\\) satisfies \\(J(0) = 0\\) and \\[\\displaystyle \\nabla_{\\gamma'} J = \\nabla_{\\gamma'} t (d\\exp_p)_{tv}(w) = (d\\exp_p)_{tv}(w) + t \\nabla_{\\gamma'} (d\\exp_p)_{tv}(w)\\] hence at \\(t= 0\\), we obtain \\((\\nabla_{\\gamma'} J)(0) = (d\\exp_p)_0(w) = w\\) since \\((d\\exp_p)_0 = \\text{Id}\\). Consider now the variation \\(V : (-\\varepsilon, \\varepsilon) \\times [a, b] \\to M\\), defined by \\(V(s, t) = \\exp_p(t(v + sw))\\). Then observe that \\(J(t) = \\partial_s V(s, t)\\vert_{s = 0} = (d\\exp_p)_{tv}(tv)\\) for all \\(t \\in [a, b]\\) and \\(J(0) = 0\\), hence \\(J\\) is the variation field for \\(V\\). Since \\(V(s, \\cdot)\\) is a geodesic for all \\(s \\in (-\\varepsilon, \\varepsilon)\\), we conclude \\(V\\) is a variation of \\(\\gamma\\) through geodesics hence \\(J\\) is a solution to the Jacobi equation with the same initial conditions as \\(X\\), and thus \\(X = J\\) by uniqueness of solutions to ODEs. This proves that solutions of the Jacobi equation \\(\\nabla_{\\gamma'}^2 X + R(X, \\gamma')\\gamma' = 0\\) are exactly variation fields along \\(\\gamma\\) corresponding to variations through geodesics. Such variation fields are thus called Jacobi fields. By uniqueness and existence theorem of ODEs, there is a unique Jacobi field \\(J\\) along \\(\\gamma\\) with initial conditions \\(J(0)\\) and \\((\\nabla_{\\gamma'} J)(0)\\) specified, and moreover since the ODE in question is linear, we conclude that there are \\(2n\\) linearly independent Jacobi fields along \\(\\gamma\\), where \\(n = \\dim M\\), corresponding to the \\(n\\) independent degrees of freedom for both the initial conditions. In particular the space of Jacobi fields along \\(\\gamma\\) is finite-dimensional. There is a trivial Jacobi field along \\(\\gamma\\) given simply by scaling the tangent field: \\(t \\gamma'\\). We usually consider the Jacobi fields normal to \\(\\gamma\\) thereof. Here is a way to put the variational perspective to context. Consider two points \\(p, q \\in M\\) and denote by \\(\\Omega_{p, q}\\) to be the space of all \\(C^\\infty\\)-paths between \\(p\\) and \\(q\\) in \\(M\\). We equip it with the Whitney topology, but we can keep that detail in the background for now. From the variational perspective we saw earlier, for any \\(\\gamma \\in \\Omega_{p, q}\\), a path in \\(\\Omega_{p, q}\\) through \\(\\gamma\\) is a variation \\(V : (-\\varepsilon, \\varepsilon) \\times [a, b] \\to M\\) such that \\(V(0, \\cdot) = \\gamma\\), \\(V(s, a) = p\\) and \\(V(s, b) = q\\) for all \\(s \\in (-\\varepsilon, \\varepsilon)\\); note that here we fix both endpoints during the variation. To be precise, if we define \\(\\gamma_s(.) = V(s, .)\\) as earlier, then \\(s \\mapsto \\gamma_s\\) is the desired path through \\(\\gamma_0 = \\gamma\\). If there is any truth to the world, the tangent vector at time \\(s = 0\\) of this path will be the variation field \\(X = \\partial_s \\gamma_s \\vert_{s = 0}\\). By completely analogous arguments as earlier, we will see such variation fields \\(X\\) along \\(\\gamma\\) are exactly the ones for which \\(X(p) = X(q) = 0\\). Thus we imagine \\(\\Omega_{p, q}\\) as an “infinite-dimensional manifold” and define \\(T_{\\gamma} \\Omega_{p, q}\\) to be the space of all variation fields along \\(\\gamma\\) vanishing at the endpoints. There is a completely variational definition of geodesics using the energy functional, defined as a function \\(\\mathcal{E} : \\Omega_{p, q} \\to \\Bbb{R}\\) by \\[\\displaystyle \\mathcal{E}(\\gamma) = \\int_{\\gamma} \\vert\\gamma'\\vert^2 = \\int_a^b \\vert\\gamma'(t)\\vert^2 dt\\] Note that we can take directional derivative of \\(\\mathcal{E}\\) on \\(\\Omega_{p, q}\\) using our dictionary now; for any variation \\(X \\in T_{\\gamma} \\Omega_{p, q}\\), define \\(d\\mathcal{E}(\\gamma)(X) = \\partial_s \\mathcal{E}(\\gamma_s)\\) where \\(\\{\\gamma_s\\}\\) is a variation of \\(\\gamma\\) with tangent vector \\(X\\) at \\(\\gamma\\). Of course, one would have to check if this is a well-defined notion, which follows from the following calculations. I will abuse notation and denote \\(V_* \\partial_s\\), \\(V_* \\partial_t\\) as simply \\(\\partial_s\\), \\(\\partial_t\\). \\[\\displaystyle \\begin{aligned}d\\mathcal{E}(\\gamma)(X) &amp;= 2 \\int_a^b g(\\nabla_{\\partial_s} \\partial_t \\gamma_s, \\partial_t\\gamma_s) dt \\\\&amp;= 2 \\int_a^b g(\\nabla_{\\partial_t} \\partial_s \\gamma_s, \\partial_t \\gamma_s) dt \\\\ &amp;= 2\\int_a^b \\partial_t g(\\partial_s \\gamma_s, \\partial_t \\gamma_s) dt - 2\\int_a^b g(\\partial_s \\gamma_s, \\nabla_{\\partial_t} \\partial_t \\gamma_s) dt \\\\ &amp;= - 2\\int_\\gamma g(X, \\nabla_{\\gamma'} \\gamma')\\end{aligned}\\] The last equation following because we evaluate the expression at \\(s = 0\\). The last expression does not depend on the choice of the variation \\(\\{\\gamma_s\\}\\) but only on the tangent vector at \\(s = 0\\) given by the variation field \\(X\\). This is known as the first variation formula. Immediate consequence of this formula is that \\(d\\mathcal{E}(\\gamma)(X) = 0\\) for all \\(X \\in T_\\gamma \\Omega_{p, q}\\) if and only if \\(\\gamma\\) is a geodesic. Therefore, geodesics in \\(\\Omega_{p, q}\\) are critical points of the energy functional. This is already a very attractive result, but we can do better. We can also try to define the Hessian of \\(\\mathcal{E}\\) in the obvious way: Suppose \\(X, Y \\in T_{\\gamma} \\Omega_{p, q}\\) are two variation fields, and define \\[\\displaystyle V : (-\\varepsilon, \\varepsilon) \\times (-\\varepsilon, \\varepsilon) \\times [a, b] \\to M\\] to be a two-parameter variation of \\(\\gamma\\) such that \\(\\partial_r V \\vert_{(u, s) = (0, 0)} = X\\) and \\(\\partial_s V\\vert_{(u, s) = (0, 0)} = Y\\). We would visualize \\(V\\) as small patch of a surface on \\(\\Omega_{p, q} M\\) passing through \\(\\gamma\\) with tangent vectors \\(X\\) and \\(Y\\) at \\(\\gamma\\). Then define \\(h \\mathcal{E}(\\gamma)(X, Y) = \\partial_u \\partial_s \\mathcal{E}(\\gamma_{u, s})\\) where \\(\\gamma_{u, s}(\\cdot) = V(u, s, \\cdot)\\). We do some nasty calculations, remembering the formula for the Riemann curvature tensor \\[R(U, V)W = \\nabla_U \\nabla_V W - \\nabla_V \\nabla_U W - \\nabla_{[U, V]} W,\\] repeatedly using symmetry and fundamental theorem of calculus whenever possible: \\[\\displaystyle \\begin{aligned} h \\mathcal{E}(\\gamma)(X, Y) &amp;= 2\\int_a^b g(\\nabla_{\\partial_u} \\nabla_{\\partial_s} \\partial_t \\gamma_{u, s}(t), \\partial_t \\gamma_{u, s}(t)) dt + 2\\int_a^b g(\\nabla_{\\partial_s} \\partial_t \\gamma_{u, s}(t), \\nabla_{\\partial_u} \\partial_t \\gamma_{u, s}(t)) dt \\\\ &amp;= 2\\int_a^b g(\\nabla_{\\partial_u} \\nabla_{\\partial_t} \\partial_s \\gamma_{u, s}(t), \\partial_t \\gamma_{u, s}(t)) dt + 2\\int_a^b g(\\nabla_{\\partial_s} \\partial_t \\gamma_{u, s}(t), \\nabla_{\\partial_u} \\partial_t \\gamma_{u, s}(t)) dt \\\\ &amp;=2\\int_a^b g(\\nabla_{\\partial_t} \\nabla_{\\partial_u} \\partial_s \\gamma_{u, s}(t), \\partial_t \\gamma_{u, s}(t)) dt + 2\\int_a^b g(R(\\partial_u, \\partial_t) \\partial_s \\gamma_{u, s}(t), \\partial_t \\gamma_{u,s}(t)) dt + 2\\int_a^b g(\\nabla_{\\partial_s} \\partial_t \\gamma_{u, s}(t), \\nabla_{\\partial_u} \\partial_t \\gamma_{u, s}(t)) dt \\\\ &amp;= -2\\int_a^b g(\\nabla_{\\partial_u} \\partial_s \\gamma_{u, s}(t), \\nabla_{\\partial_t} \\partial_t \\gamma_{u, s}(t)) dt + 2\\int_a^b g(R(\\partial_u, \\partial_t) \\partial_s \\gamma_{u, s}(t), \\partial_t \\gamma_{u,s}(t)) dt + 2\\int_a^b g(\\nabla_{\\partial_t} \\partial_s \\gamma_{u, s}(t), \\nabla_{\\partial_t} \\partial_u \\gamma_{u, s}(t)) dt\\end{aligned}\\] If \\(\\gamma\\) is a geodesic, the first integral vanishes since \\(\\nabla_{\\partial_t} \\partial_t = 0\\). As we are evaluating the expressions at \\((u, s) = (0, 0)\\), we obtain the final formula as: \\[\\displaystyle h\\mathcal{E}(\\gamma)(X, Y) = 2\\int_\\gamma \\left (g(R(X, \\gamma')Y, \\gamma') + g(\\nabla_{\\gamma'} X, \\nabla_{\\gamma'} Y)\\right )\\] This is known as the second variation formula, and we get independence of \\(h\\mathcal{E}(\\gamma)(X, Y)\\) on the choice of the two-parameter variation \\(V\\) with tangents \\(X, Y \\in T_\\gamma \\Omega_{p, q}\\) from here. Using the identity \\(g(R(U, V)Z, W) = g(R(Z, W), U, V)\\), we obtain symmetry \\(h\\mathcal{E}(\\gamma)(X, Y) = h\\mathcal{E}(\\gamma)(Y, X)\\) of the Hessian, which is also clear from the definition by commutativity of partials. Observe that \\(h\\mathcal{E}(\\gamma)\\) only has these nice properties if \\(\\gamma\\) is a geodesic, i.e., a critical point of \\(\\mathcal{E}\\), which is of course not unexpected since that is how the Hessian behaves in the finite dimensional case as well. We can rewrite the above formula by an application of the fundamental theorem of calculus and the identity \\(g(R(U, V)W, Z) = -g(R(U, V)Z, W)\\) as follows: \\[\\displaystyle \\begin{aligned}h\\mathcal{E}(\\gamma)(X, Y) &amp;= - 2 \\int_\\gamma \\left ( g(R(X, \\gamma')\\gamma', Y) + g(\\nabla_{\\gamma'}^2 X, Y) \\right ) \\\\ &amp;= -2 \\int_\\gamma g(\\nabla_{\\gamma'}^2 X+ R(X, \\gamma')\\gamma', Y)\\end{aligned}\\] And therefore we obtain that \\(X \\in T_{\\gamma}\\Omega_{p, q}\\) is a Jacobi field along \\(\\gamma\\) if and only if \\(h\\mathcal{E}(\\gamma)(X, Y) = 0\\) for all variation fields \\(Y \\in T_{\\gamma}\\Omega_{p, q}\\). Thus the subspace of Jacobi fields on \\(\\gamma\\) vanishing at the endpoints is the kernel \\(\\ker h\\mathcal{E}(\\gamma)\\) of the Hessian of the energy functional. Actually occurrences of such Jacobi fields are rather rare, and can only be seen for some very special pair of points \\(p, q\\) on \\(M\\), called conjugate points, and they are usually said to be conjugate to each other with reference to the geodesic \\(\\gamma \\in \\Omega_{p, q}\\) along which a Jacobi field vanishing at the endpoints exist. If \\(p, q\\) are a pair of points conjugate along \\(\\gamma\\), we define multiplicity of the conjugate pair (or that of \\(p\\) with respect to \\(q\\), or vice versa) to be the dimension of \\(\\ker h\\mathcal{E}(\\gamma)\\). Recall from earlier computations that there are \\(n\\) linearly independent Jacobi fields along \\(\\gamma\\) which vanish at \\(p\\), and one of them is the redundant scaled tangent vector field \\(t \\gamma'(t)\\) since it does not vanish for \\(t = b\\). Thus, we have the bound on multiplicity of any pair of conjugate points \\[\\displaystyle \\dim \\ker h\\mathcal{E}(\\gamma) \\leq n-1\\] (The equality is achieved, for example, in case of \\(M = S^n\\).) So the variations of the geodesic \\(\\gamma\\) through geodesics inside \\(\\Omega_{p, q}\\) “trace out” a finite-dimensional critical submanifold of \\(\\mathcal{E}\\) the tangent space of which witnesses the degeneracy of the Hessian of \\(\\mathcal{E}\\). This essentially describes \\(\\mathcal{E} : \\Omega_{p, q} \\to \\Bbb{R}\\) as a Morse function on an infinite-dimensional manifold, where since the domain is so huge we cannot expect to have isolated nondegenerate critical points, but our best bet is to have finite dimensional critical submanifolds and Hessian to have finite nullity. This is explored in detail in Milnor, and maybe we’ll discuss this in a future post. As a final note on this, observe that if \\(\\gamma : [0, c] \\to M\\) is a geodesic passing through \\(\\gamma(0) = p\\), then \\(q = \\gamma(t_0)\\) is conjugate to \\(p\\) along \\(\\gamma\\) if and only if \\(t_0 \\gamma'(0)\\) is a critical point of the exponential map \\(\\exp_p : T_p M \\dashrightarrow M\\). This follows directly from the definitions, since the Jacobi field \\(J\\) witnessing the conjugacy can be written as \\(J(t) = d(\\exp_p)_{tv}(tw)\\) where \\(v = \\gamma'(0)\\) and \\(w \\in T_p M = T_0 T_p M\\) is some vector. Since \\(J(t_0) = 0\\), we obtain that \\(w \\in \\ker d(\\exp_p)_{t_0v}\\). Therefore in fact \\(\\dim \\ker d(\\exp_p)_{t_0 v}\\) is the multiplicity of the conjugate point \\(q\\) of \\(p\\). This proves that for any point \\(p\\), the set of points on \\(M\\) conjugate to \\(p\\) along some geodesic is the set of critical values of \\(\\exp_p\\) which is a measure zero subset of \\(M\\) by Sard’s theorem; this justifies our rareness comment from earlier. This subset is called the conjugate locus of \\(p\\) in \\(M\\); it is closely related to an even more complicated subset of \\(M\\) known as the cut locus of \\(p\\), both of which, to my understanding, are witnesses of how badly the collection of geodesics emanating from \\(p\\) fails to be a foliation. As a closing remark, let’s try to sketch where to go from here. The Jacobi equation is useful in describing how far nearby geodesics starting at the same point diverge with respect to time. For example, let \\(M\\) be a Riemannian \\(2\\)-manifold with constant Gaussian curvature \\(K\\), and suppose \\(J\\) is a normal Jacobi field along an arclength-parametrized geodesic \\(\\gamma: [0, c] \\to M\\). Let \\(\\mathbf{e}\\) be a parallel unit normal field along \\(\\gamma\\). Then \\(J(t) = f(t) \\mathbf{e}(t)\\) for all \\(t \\in [0, c]\\) where \\(f(t)\\) is the length of the Jacobi field at time \\(t\\). From the Jacobi equations we obtain \\[\\displaystyle \\begin{aligned} 0 = g(\\nabla_{\\gamma'}^2 J + R(J, \\gamma')\\gamma', \\mathbf{e}) &amp;= g(\\nabla_{\\gamma'}^2 f \\mathbf{e}, \\mathbf{e}) + g(R(f \\mathbf{e}, \\gamma')\\gamma', \\mathbf{e}) \\\\ &amp;= f'' + K f \\end{aligned}\\] Where \\(K = g(R(\\mathbf{e}, \\gamma')\\gamma', \\mathbf{e})\\) is the sectional curvature along \\(\\gamma\\). Thus, we obtain the familiar second order differential equation \\(f'' + K f = 0\\) whose solutions are trigonometric if \\(K &gt; 0\\), linear if \\(K = 0\\) and exponential if \\(K &lt; 0\\). Since length of the Jacobi field controls deviations of nearby geodesics, we obtain from this that geodesics starting at a common point tend to converge if \\(K &gt; 0\\), diverge linearly if \\(K = 0\\) and diverge exponentially if \\(K &lt; 0\\). Contrast these to the model spaces of constant curvature \\(+1\\) (\\(S^2\\)), \\(0\\) (\\(\\Bbb R^2\\)) and \\(-1\\) (\\(\\Bbb H^2\\)), where we know this occurs. This is the “comparison philosophy”; to understand how curvature controls rate of divergence of geodesics, and to compare this rate in spaces of different curvatures. We shall talk about this in detail in the next few posts.",
      "categories": [],
      "tags": ["cat(k)","morse-theory"]
    }
  
]